{"llm_update_time": "20260221", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2602.16805", "html_url": "https://arxiv.org/abs/2602.16805", "title": "简单基准与代码进化竞争", "title_en": "Simple Baselines are Competitive with Code Evolution", "authors": "Yonatan Gideoni,Sebastian Risi,Yarin Gal", "background": "代码进化是一种依赖大型语言模型的技术，通过进化或变异现有代码来搜索可能的计算机程序。已有许多代码进化管道表现出色，但通常没有与更简单的基线进行比较。", "innovation": "作者测试了两种简单的基线在三种领域（数学边界改进、设计有机关联支架、机器学习比赛）中的表现，发现简单基线与更复杂的方法相当甚至更优，并提出了改进评估方法以减少评估的随机性同时保持经济可行性。", "conclusion": "在数学边界改进方面，问题的搜索空间和提示中的领域知识主要决定了搜索的成绩上限和效率，代码进化管道的重要性较低；在设计有机关联支架方面，高变异性与小数据集导致次优支架被选择，手动设计的多数投票支架表现最佳。作者建议改进评估方法，并讨论了未来在代码进化中采取更严格方法的途径。"}
{"llm_update_time": "20260221", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2602.16715", "html_url": "https://arxiv.org/abs/2602.16715", "title": "基于检索增强（知识图谱）和大语言模型的网络物理系统设计结构矩阵生成", "title_en": "Retrieval Augmented (Knowledge Graph), and Large Language Model-Driven Design Structure Matrix (DSM) Generation of Cyber-Physical Systems", "authors": "H. Sinan Bank,Daniel R. Herber", "background": "本文探讨了大型语言模型（LLMs）、检索增强生成（RAG）以及图为基础的RAG（GraphRAG）在生成设计结构矩阵（DSMs）中的潜力。研究使用了两个不同的用例，分别是电力螺丝刀和CubeSat，以及它们已知的架构参考。这两大案例分别从确定预定义组件之间的关系和识别组件及其后续关系两个关键任务上评估模型的性能。", "innovation": "本文创新点在于将RAG技术与GraphRAG相结合，应用于基于LLMs的DSM生成。研究使用了两个实际用例进行测试，并通过评估DSM的各个元素和整体架构来评价模型的性能。", "conclusion": "尽管面临设计和计算上的挑战，研究发现可以通过自动化生成DSM来提供研究机会，所有代码均已公开，以供领域专家进一步反馈和复现研究结果。"}
{"llm_update_time": "20260221", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2602.16716", "html_url": "https://arxiv.org/abs/2602.16716", "title": "单态表示的情境性：适应性智能的信息理论原则", "title_en": "Contextuality from Single-State Representations: An Information-Theoretic Principle for Adaptive Intelligence", "authors": "Song-Ju Kim", "background": "自适应系统通常在多个上下文中运作，由于对存储、表示或物理资源的限制，它们使用固定内部状态空间进行重复利用。这种单状态重用在自然智能和人工智能中都普遍存在，但对于其基本的表示后果仍知之甚少。文献指出，通过将情境视为作用于共享内部状态的干预措施，研究表明任何能够反映情境结果统计的经典模型都必须承担无法通过内部状态传递情境依赖性的信息论成本。", "innovation": "这项研究证明了情境性不仅限于量子力学，而是经典概率表示中单状态重用的不可避免结果。通过构建极简模型明确展示了这种成本的实际意义，并解释了非经典概率框架是如何通过放松全局联合概率空间的假设来避免这一障碍，而不涉及量子动力学或希尔伯特空间结构。", "conclusion": "研究结果表明，情境性是对适应性智能的普遍表示约束，与物理实现无关。"}
{"llm_update_time": "20260221", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2602.16807", "html_url": "https://arxiv.org/abs/2602.16807", "title": "改进的超立方体切割上界", "title_en": "Improved Upper Bounds for Slicing the Hypercube", "authors": "Duncan Soiffer,Nathaniel Itty,Christopher D. Rosin,Blake Bruell,Mason DiCicco,Gábor N. Sárközy,Ryan Offstein,Daniel Reichman", "background": "此论文讨论了如何通过集合中的超平面切割n维超立方体的所有边。背景是之前的研究给出了一个上界，但是新的研究通过创建一个结合了推理LLM和自动超参数调整的工具——CPro1，得到了一组更好的结果。", "innovation": "创新之处在于通过优化的技术和工具获得了超立方体切割边数上的改进上界，即对于$n$非5的奇数倍，$S(n) \big\braceceil \frac{4n}{5}，对于$n$是5的奇数倍时，$S(n) \big\braceceil \frac{4n}{5}+1。这种方法显著优于之前的界限，并首次利用了一个名为CPro1的技术工具。", "conclusion": "该研究展示了如何使用新的技术和工具来改进上界，并证明了新的上界在特定条件下更好。这种方法可以应用于未来的研究，进一步优化相关问题的解法。"}
{"llm_update_time": "20260221", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2602.16727", "html_url": "https://arxiv.org/abs/2602.16727", "title": "适用于可扩展LLM基于人类移动模拟的知觉支配缓存框架", "title_en": "Mobility-Aware Cache Framework for Scalable LLM-Based Human Mobility Simulation", "authors": "Hua Yan,Heng Tan,Yingxue Zhang,Yu Yang", "background": "大规模人类移动模拟对于城市规划、流行病学和交通分析等应用至关重要。近期的研究使用大型语言模型（LLMs）作为代理来使用结构化推理模拟现实的人类移动行为，但其高计算成本限制了其可扩展性。", "innovation": "设计了一种称为MobCache的感知意识缓存框架，通过使用可重构的缓存来实现高效的大规模人类移动模拟。该框架包括：1）一个推理组件，将每一步推理编码为潜在空间嵌入，并使用潜在空间评估器来实现实推理步骤的重用和重组；2）一个解码组件，使用受到移动法则约束的数据蒸馏训练的轻量级解码器将潜在空间的推理链翻译成自然语言，从而提高模拟效率，同时保持与最先进的LLM方法相媲美的精度。", "conclusion": "实验表明，MobCache在多个维度上显著提高了效率，同时保持了与最先进的LLM基方法相当的性能。"}
{"llm_update_time": "20260221", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2602.16827", "html_url": "https://arxiv.org/abs/2602.16827", "title": "基于顺序的方法对犹豫模糊元素的评分", "title_en": "An order-oriented approach to scoring hesitant fuzzy elements", "authors": "Luis Merino,Gabriel Navarro,Carlos Salvatierra,Evangelina Santos", "background": "传统的犹豫模糊集评分方法缺乏形式化的秩序理论基础。本文提出了一种统一的框架，在该框架中，每个得分（评分）都是相对于给定的秩序显式定义的。这种以顺序为基础的观点使评分机制更加灵活和连贯。", "innovation": "文章提出了一种基于顺序的方法，对犹豫模糊元素进行评分。具体来说，文章研究了几种经典顺序，并证明相对于对称顺序定义的得分满足评分函数的关键规范标准。此外，文章引入了主导函数的概念，用于比较基于包含最小接受阈值的控制集的犹豫模糊元素。", "conclusion": "该研究证明了这些主导函数能够用于构建典型犹豫模糊集上的模糊偏好关系，并支持群体决策。同时，文章提出的具体例子包括离散主导函数和相对主导函数。"}
{"llm_update_time": "20260221", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2602.16814", "html_url": "https://arxiv.org/abs/2602.16814", "title": "节点学习：自适应、去中心化和协作的网络边缘AI框架", "title_en": "Node Learning: A Framework for Adaptive, Decentralised and Collaborative Network Edge AI", "authors": "Eiman Kanjo,Mustafa Aslanov", "background": "随着AI向边缘扩展，中心化智能的成本和脆弱性越来越明显。数据传输、延迟、能源消耗和对大型数据中心的依赖性在异构、移动和资源受限的环境中造成了难以扩展的瓶颈。", "innovation": "提出了节点学习，这是一种去中心化学习范式，在这种范式中，智能存在于个体边缘节点中，并通过有选择的同伴交互来扩展。节点从本地数据中不断学习，保持自己的模型状态，并在协作有益时机会性的交换所学到的知识。学习通过重叠和扩散传播，而不是通过全局同步或中央聚合。该概念论文建立了这一范式的概念基础，将其与现有的去中心化方法进行了对比，并探讨了对通信、硬件、信任和治理的影响。", "conclusion": "节点学习不抛弃现有范式，而是将其纳入更广泛的去中心化视角。"}
{"llm_update_time": "20260221", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2602.16763", "html_url": "https://arxiv.org/abs/2602.16763", "title": "当AI基准达到平台期：一项关于基准饱和度的系统性研究", "title_en": "When AI Benchmarks Plateau: A Systematic Study of Benchmark Saturation", "authors": "Mubashara Akhtar,Anka Reuel,Prajna Soni,Sanchit Ahuja,Pawan Sasanka Ammanamanchi,Ruchit Rawal,Vilém Zouhar,Srishti Yadav,Chenxi Whitehouse,Dayeon Ki,Jennifer Mickel,Leshem Choshen,Marek Šuppa,Jan Batzner,Jenny Chim,Jeba Sania,Yanan Long,Hossein A. Rahmani,Christina Knight,Yiyang Nan,Jyoutir Raj,Yu Fan,Shubham Singh,Subramanyam Sahoo,Eliya Habba,Usman Gohar,Siddhesh Pawar,Robert Scholz,Arjun Subramonian,Jingwei Ni,Mykel Kochenderfer,Sanmi Koyejo,Mrinmaya Sachan,Stella Biderman,Zeerak Talat,Avijit Ghosh,Irene Solaiman", "background": "人工智能（AI）基准在衡量模型开发进展和指导部署决策中扮演着关键角色。然而，许多基准很快变得饱和，即它们无法区分最优秀的模型，从而减少了其长期价值。", "innovation": "本研究分析了60个大型语言模型（LLM）基准，这些基准来自主要模型开发商的技术报告。研究通过14种属性对基准进行分类——涵盖任务设计、数据构建和评估格式，测试了五个假设以检验每种属性如何影响饱和率。研究发现，几乎一半的基准表现出饱和现象，饱和率随基准年龄增长而增加。此外，公开测试数据没有保护作用，而由专家策划的基准比由众包创建的基准更能抵抗饱和。", "conclusion": "研究揭示了哪些设计选择延长了基准的使用寿命，并为更持久的评价提供了策略建议。"}
{"llm_update_time": "20260221", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2602.16812", "html_url": "https://arxiv.org/abs/2602.16812", "title": "NeuDiff Agent: 受治理的单晶 neutron 光学晶格 AI 工作流", "title_en": "NeuDiff Agent: A Governed AI Workflow for Single-Crystal Neutron Crystallography", "authors": "Zhongcan Xiao(1),Leyi Zhang(1 and 2),Guannan Zhang(3),Xiaoping Wang(1) ((1) Neutron Scattering Division, Oak Ridge National Laboratory, Oak Ridge, Tennesse USA, (2) Department of Linguistics, University of Illinois Urbana-Champaign, Urbana, Illinois, USA, (3) Computer Science and Mathematics Division, Oak Ridge National Laboratory, Oak Ridge, Tennessee, USA)", "background": "大尺寸设施在处理科学数据时日益面临分析和报告延迟的问题，尤其是在需要迭代减少、整合、精炼和验证的结构和磁性复杂样品方面尤为明显。为了提高结果时间与分析效率，需要一种规范化的工具使用AI工作流来优化这一过程，特别是在Spallation Neutron Source的TOPAZ设备中。", "innovation": "NeuDiff Agent引入了一种由治理驱动的工具使用AI工作流，该工作流将仪器数据产品从原始数据逐步处理到验证的晶体结构和准备发表的CIF文件。NeuDiff Agent通过限制行为仅限于允许列表中的工具、在关键工作流边界强制执行验证门并捕获完整的追溯记录，从而执行此标准化管道。通过使用固定提示协议和使用大型语言模型后端进行重复端到端运行，性能进行了评估，结果显示出显著的时间节省，并保证了验证需求。", "conclusion": "NeuDiff Agent 实现了从手动操作到自动操作的转型，在保持追踪记录和公开发表的验证要求的同时，显著减少了晶体学过程所需的时间，而在参考案例基准测试中，时间从435分钟减少到48到94.4分钟，验证的 CIF 无 checkCIF 级别 A 或 B 的警告。这项研究为设施晶体学部署机关型AI提供了一条实用途径。"}
{"llm_update_time": "20260221", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2602.16714", "html_url": "https://arxiv.org/abs/2602.16714", "title": "AIdentifyAGE 本体在法医牙龄评估决策支持中的应用", "title_en": "AIdentifyAGE Ontology for Decision Support in Forensic Dental Age Assessment", "authors": "Renato Marcelo,Ana Rodrigues,Cristiana Palmela Pereira,António Figueiras,Rui Santos,José Rui Figueira,Alexandre P Francisco,Cátia Vaz", "background": "年龄评估在法医和司法决策中至关重要，尤其是在处理未登记人员和无伴儿童案件时，判断其年龄对于获取保护、医疗服务和司法程序至关重要。牙龄评估被认为是年龄评估中最可靠的生物方法之一，特别适用于青少年和年轻成年人，但目前存在方法学异质性、数据表示碎片化以及临床、法医和法律信息系统之间互操作性差的问题。这些限制阻碍了透明性和可重复性，尤其随着AI方法的应用更加广泛而加剧。", "innovation": "AIdentifyAGE 本体是一个专门领域内的标准化、语义上一致的框架，涵盖了手动和AI辅助的法医牙龄评估工作流程，实现了观察、方法、参考数据和报告结果之间的可追溯链接。它整合了法医上下文、个体信息、法医检查数据、牙齿发育评估方法、放射影像、统计参考研究和AI估计方法的全部医疗法律工作流程。AIdentifyAGE 本体建立在生物医学、牙科和机器学习本体的基础上，支持互操作性、可扩展性和遵守FAIR原则。这为在医疗法律和司法背景下建立基于本体的决策支持系统奠定了坚实的基础。", "conclusion": "AIdentifyAGE 本体是增强一致性、透明性和解释性的关键一步，为法医牙龄评估提供了严谨的决策支持系统基础，有助于在法医和司法领域内提供基于本体的决策支持系统。"}
{"llm_update_time": "20260221", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2602.17003", "html_url": "https://arxiv.org/abs/2602.17003", "title": "Persona2Web：基于用户历史进行上下文推理评价个人化网络代理的方法", "title_en": "Persona2Web: Benchmarking Personalized Web Agents for Contextual Reasoning with User History", "authors": "Serin Kim,Sangam Lee,Dongha Lee", "background": "大型语言模型已推动了网络代理的进步，但当前的代理缺乏个性化能力。由于用户通常不会明确表达所有意图细节，实际应用中的网络代理必须能够通过推断用户偏好和上下文来解释模糊查询。Persona2Web 旨在解决这一挑战。", "innovation": "Persona2Web 是首个建立在'澄清-个性化'原则上的基准测试，该原则要求代理基于用户历史而非显式指令来解决模糊性。它包括用户历史（隐含揭示偏好）、模糊查询（要求代理推测隐含用户偏好）以及一个推理感知的评估框架，以实现精细化的个性化评估。", "conclusion": "我们进行了广泛的实验，涵盖不同代理架构、基础模型、历史访问方案和不同模糊级别的查询，揭示了个性化网络代理行为的关键挑战。代码和数据集已公开发布，供进一步研究使用。"}
{"llm_update_time": "20260221", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2602.17022", "html_url": "https://arxiv.org/abs/2602.17022", "title": "ReIn: 通过推理扩展实现对话错误恢复", "title_en": "ReIn: Conversational Error Recovery with Reasoning Inception", "authors": "Takyoung Kim,Jinseok Nam,Chandrayee Basu,Xing Fan,Chengyuan Ma,Heng Ji,Gokhan Tur,Dilek Hakkani-Tür", "background": "大规模语言模型（LLMs）驱动的对话代理在固定的任务导向对话数据集中表现出色，但在处理意外、用户诱导的错误方面仍然脆弱。本研究专注于错误恢复，而不是错误预防。作者指出，在由于成本和时间限制而不允许模型微调或修改提示的情况下，探索代理能否从语境错误的对话中恢复以及如何在不改变模型参数和提示的情况下调整其行为。", "innovation": "提出了名为ReIn的测试时干预方法，该方法在代理的决策过程中植入初始推理。它通过一个外部插入模块识别对话上下文中的预定义错误，生成恢复计划，并整合到代理的内部推理过程中以引导纠正行动，而无需修改模型参数或系统提示。", "conclusion": "ReIn显著提高了任务成功率并能很好地泛化到未见过的错误类型。其在指令层次中的操作机制表明，结合ReIn定义恢复工具有助于在不修改基础模型或系统提示的情况下提高对话代理的健壮性。"}
{"llm_update_time": "20260221", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2602.17037", "html_url": "https://arxiv.org/abs/2602.17037", "title": "Wink: 在编码代理行为异常中恢复", "title_en": "Wink: Recovering from Misbehaviors in Coding Agents", "authors": "Rahul Nanda,Chandra Maddila,Smriti Jha,Euna Mehnaz Khan,Matteo Paltenghi,Satish Chandra", "background": "自主编码代理，由大规模语言模型（LLMs）驱动，正在软件行业中越来越多地被用于自动化复杂工程任务。然而，这些代理容易出现各种行为偏差，如偏离用户的指示、陷入重复循环或错误使用工具。这些故障会干扰开发流程，并经常需要大量的手动干预。本研究介绍了大规模自动从代理行为偏差中恢复的系统。", "innovation": "本文开发了一个轻量级、异步的自我干预系统Wink。Wink通过观察代理的轨迹并提供有针对性的纠正指导来引导代理回到生产性路径。实验结果表明，Wink成功解决了90%需要一次干预的行为偏差。此外，在生产环境中的实时A/B测试表明，Wink显著减少了工具调用失败、会话中的Token数量和工程师的会话干预次数。", "conclusion": "本文总结了设计和部署此系统的经验，并提供了构建大规模具有弹性的代理系统所面临挑战的见解。"}
{"llm_update_time": "20260221", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2602.17051", "html_url": "https://arxiv.org/abs/2602.17051", "title": "评估跨语言分类方法以启用多语言社交媒体数据的主题发现", "title_en": "Evaluating Cross-Lingual Classification Approaches Enabling Topic Discovery for Multilingual Social Media Data", "authors": "Deepak Uniyal,Md Abul Bashar,Richi Nayak", "background": "在自然语言处理领域，分析多语言社交媒体对话仍然是一项重大挑战，特别是在大规模公共辩论跨越多种语言时。为了有效分析全球对话，本研究探讨了不同跨语言文本分类方法的有效性。", "innovation": "研究采用了氢能源作为案例研究，分析了2013年至2022年的超过九百多万条英文、日文、印地文和韩文推文，探索了四种过滤相关内容的方法：（1）将英文标注数据翻译成目标语言并为每个目标语言构建特定语言的模型，（2）将来自所有语言的未标注数据翻译成英文以基于英文标注创建单一模型，（3）直接将英文微调的多语言变压器应用于每个目标语言数据，（4）将翻译的标注与多语言训练结合的混合策略。研究结果强调了翻译与多语言方法之间的关键权衡，为优化大规模社交媒体分析中的跨语言管道提供了实际洞察。", "conclusion": "研究结果突出显示了翻译与多语言方法之间的权衡，并提出了针对大规模社交媒体分析优化跨语言管道的实际建议。"}
{"llm_update_time": "20260221", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2602.17063", "html_url": "https://arxiv.org/abs/2602.17063", "title": "sign lock-in: 随机初始化的权重符号保持并成为亚位压缩的瓶颈", "title_en": "Sign Lock-In: Randomly Initialized Weight Signs Persist and Bottleneck Sub-Bit Model Compression", "authors": "Akira Sakai,Yuma Ichikawa", "background": "亚位模型压缩的目标是将每个权重的存储量压缩到不足1位；随着幅值被极度压缩，符号位成为了固定成本的瓶颈。在Transformer、CNN和MLP等模型中，学习到的符号矩阵难以进行低秩近似，并且在谱上与独立同分布的Rademacher基准无显著区别。尽管表面看似随机，大多数权重仍保留了其初始化的符号；符号翻转主要发生在接近零的罕见边界穿越中，表明符号模式的随机性主要继承自初始化。", "innovation": "本文提出了符号锁死理论，对基于梯度下降噪音的符号翻转进行了停止时间分析。在有界的更新条件下，当进入零附近的小区间时，有效的符号翻转次数表现出几何分布。基于这一机制，提出了一种差距初始化方法和一种轻量级向外漂移正则化方法，将有效的翻转率降低到约10⁻³的数量级，并且仅导致困惑度略有增加。", "conclusion": "通过符号锁死理论分析符号翻转行为，并引入差距初始化和轻量级向外漂移正则化，有效降低了符号翻转率，提升了亚位压缩的有效性，为模型压缩提供了新的思路。"}
{"llm_update_time": "20260221", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2602.17028", "html_url": "https://arxiv.org/abs/2602.17028", "title": "通过不确定性感知时间序列集成预测异常前兆", "title_en": "Forecasting Anomaly Precursors via Uncertainty-Aware Time-Series Ensembles", "authors": "Hyeongwon Kang,Jinwoo Park,Seunghun Han,Pilsung Kang", "background": "在工业运营、金融和网络安全等领域，及时识别异常模式对于确保系统可靠性及实现预防性维护至关重要。然而，现有的大多数方法是反应型的，只能在异常发生后进行检测，缺乏提供早期预警信号的能力。", "innovation": "本文提出了一种新颖的无监督框架FATE（Forecasting Anomalies with Time-series Ensembles），通过量化来自多元时间序列预测模型集合的预测不确定性来检测异常前兆（PoA）。FATE 不依赖于重建误差或需要真实标签，并能够预先预料未来的值，利用集成的分歧来在没有目标值的情况下发出潜在异常的早期信号。", "conclusion": "实验结果表明，FATE 在 Precursor Time-series Aware Precision and Recall (PTaPR) AUC 和早期检测 F1 分数上分别提升了 19.9 个百分点和 20.02 个百分点，优于基线方法，且不需要异常标签。这些结果展示了 FATE 在复杂时间序列环境中的实时无监督早期预警的有效性和可行性。"}
{"llm_update_time": "20260221", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2602.17027", "html_url": "https://arxiv.org/abs/2602.17027", "title": "使用情境学习和增强张量方法转型行为神经科学研究", "title_en": "Transforming Behavioral Neuroscience Discovery with In-Context Learning and AI-Enhanced Tensor Methods", "authors": "Paimon Goulart,Jordan Steinhauser,Dawon Ahn,Kylene Shuler,Edward Korzus,Jia Chen,Evangelos E. Papalexakis", "background": "科学发现管道通常涉及复杂、僵化且耗时的过程，从数据准备到分析和解释结果。传统上，科学家需要花大量时间调试这些管道或手动标注数据，而缺乏能够自主学习和解释数据的能力。近年来，人工智能的进步潜力为这些过程的转变提供了可能性，使领域专家能够专注于解释和理解结果，而不是关注僵化的管道调试或手动注释数据。本研究旨在展示一种增强的人工智能管道，以帮助领域专家加速从实验数据中获得见解的过程。", "innovation": "研究确立了“情境学习”(In-Context Learning, ICL)作为人机交互的一种新兴范式，使领域专家可以自动化其管道中的某些部分，无需对AI模型训练和微调有任何了解。通过应用ICL范式，研究引入了新型人工智能增强的张量分解模型，以更平滑地从异构数据中发现模式。研究最后实验验证了提出的新管道，以其在性能方面的优越性展示了其超越传统实践和合理机器学习基线的优势。", "conclusion": "研究通过充分评估新提出的人工智能增强的神经科学应用管道，并得到领域专家的认可，证明了其在便捷性和使用易用性方面的优势，展示了情境学习和增强张量方法在行为神经科学发展中的巨大潜力。"}
{"llm_update_time": "20260221", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2602.17070", "html_url": "https://arxiv.org/abs/2602.17070", "title": "一般化因果概率样本量分析：delta方法方法", "title_en": "General sample size analysis for probabilities of causation: a delta method approach", "authors": "Tianyuan Cheng,Ruirui Mao,Judea Pearl,Ang Li", "background": "因果概率（如必要性和充分性的概率）是决策的重要工具，但通常不具有点可识别性。现有研究利用实验和观察性数据的组合来推导这些量的上下界。然而，关于样本量分析的研究很少，即达到所需置信区间的方法，特别是实验性和观察性样本数量的研究。在本文中，作者提出了基于delta方法的一般样本量框架。", "innovation": "提出了基于delta方法的一般样本量框架，该方法适用于目标因果概率边界可以表达为实验性和观察性概率线性组合的有限最小值或最大值的场景。通过模拟研究，证明了所提出的样本量计算能稳定估计这些边界。", "conclusion": "研究结果表明，基于delta方法的样本量计算能稳定估计因果概率的边界，为决策提供了可靠的支持。"}
{"llm_update_time": "20260221", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2602.17071", "html_url": "https://arxiv.org/abs/2602.17071", "title": "AdvSynGNN：通过对抗合成和自我纠正传播适应结构的图神经网络", "title_en": "AdvSynGNN: Structure-Adaptive Graph Neural Nets via Adversarial Synthesis and Self-Corrective Propagation", "authors": "Rong Fu,Muge Qi,Chunlei Meng,Shuo Yin,Kun Liu,Zhaolu Kang,Simon Fong", "background": "图神经网络在处理含有结构噪声或非同质性拓扑结构的数据时，经常会出现性能显著下降的问题。为了应对这种系统的脆弱性，本研究提出了一种名为AdvSynGNN的全面架构，用于在节点级表示学习中增强鲁棒性。", "innovation": "AdvSynGNN框架通过多分辨率结构合成和对比目标相结合，建立几何敏感性初始化。提出了一个适应性的变压器骨架，通过学习拓扑信号来调节注意力机制，以适应异质性。该研究的核心贡献在于一个集成的对抗性传播引擎，其中生成组件识别潜在的连接性变化，而判别器确保全局一致性。此外，通过基于节点信心度量的残差校正方案实现标签细化，从而实现精确的迭代稳定性控制。", "conclusion": "实证评估表明，这种协同方法在多种图分布中有效优化了预测准确性，同时保持了计算效率。研究最后提出了实际的实施协议，以确保在大规模环境中AdvSynGNN系统的稳健部署。"}
{"llm_update_time": "20260221", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2602.17054", "html_url": "https://arxiv.org/abs/2602.17054", "title": "ALPS: 阿拉伯语语言与语用推理的诊断挑战集", "title_en": "ALPS: A Diagnostic Challenge Set for Arabic Linguistic & Pragmatic Reasoning", "authors": "Hussein S. Al-Olimat,Ahmad Alshareef", "background": "近年来，阿拉伯语自然语言处理基准测试更多地关注规模，但也依赖于合成或翻译数据，这些数据可能需要更深入的语言验证。以往的广覆盖基准测试更注重规模和多任务覆盖率，而ALPS旨在通过531个精心设计的问题，涵盖15个任务和47个子任务，深入探索语言理解的深度。", "innovation": "ALPS是一个由阿拉伯语专家精心筛选的问题集，专门针对深度语义和语用能力进行评估，这些能力补充了特定的大型基准测试。通过与单次人类性能（平均准确率为84.6%）和专家判定的Oracle（99.2%）进行对比，ALPS揭示出关键分离：模型在流畅度方面表现出色，但在形态语法依赖关系方面却表现不佳。", "conclusion": "在与23种不同模型（商业、开源和阿拉伯本土）的测试中，尽管顶级商业模型（Gemini-3-flash）在平均人类性能上略胜一筹，但商业巨头与阿拉伯本土模型之间仍存在显著差距。最好的阿拉伯特定模型（Jais-2-70B）的表现接近人类，但并未达到人类的水平。"}
{"llm_update_time": "20260221", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.02039", "html_url": "https://arxiv.org/abs/2412.02039", "title": "使用知识蒸馏的多视角3D重建", "title_en": "Multi-View 3D Reconstruction using Knowledge Distillation", "authors": "Aditya Dutt,Ishikaa Lunawat,Manpreet Kaur", "background": "大型基础模型如Dust3r可以生成高质量的输出，比如点云图、相机内参以及深度估计，通过输入立体图像对。然而，这些模型在应用于需要大量推断时间和计算资源的任务，如视觉定位时表现出局限性。", "innovation": "本文提出了一种知识蒸馏管道，利用Dust3r作为教师模型，构建了多个学生模型架构，这些学生模型使用Dust3r的3D重建点进行训练。通过实验，比较了基于CNN和Vision Transformer的模型架构，并探讨了预训练模型与从零开始构建模型的性能差异。", "conclusion": "实验结果显示，Vision Transformer模型在视觉和定量表现上都有最佳表现。"}
{"llm_update_time": "20260221", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.02137", "html_url": "https://arxiv.org/abs/2411.02137", "title": "逻辑回归中最大似然估计的有限样本性能", "title_en": "Finite-sample performance of the maximum likelihood estimator in logistic regression", "authors": "Hugo Chardon,Matthieu Lerasle,Jaouad Mourtada", "background": "逻辑回归是一种经典的多变量协变量与二元响应之间概率依赖关系的模型。本文关注最大似然估计（MLE）在逻辑回归中的预测性能，主要从逻辑风险的角度进行评估。文章探讨了MLE的存在性（当数据集不能线性分离时）和其准确性（当存在时）。这些特性依赖于协变量的维度和信号强度。", "innovation": "文章在高斯协变量和良好指定的逻辑模型的情况下，获得了存在性和多余逻辑风险的精确非渐近保证。之后，文章将这些结果推广至非高斯协变量满足特定二维边缘条件的情况，以及统计学习中可能指定错误的逻辑模型的一般情况。另外，当协变量为伯努利分布时，文章分析了MLE在参数方向高度敏感的行为。", "conclusion": "本文提供了MLE存在的精确非渐近保证和当存在时的多余逻辑风险保证。然后，文章探讨了非高斯协变量和突然变动的逻辑模型时MLE的表现。最后，文章讨论了伯努利设计下的MLE性能，该设计下的行为高度依赖于参数的方向。"}
{"llm_update_time": "20260221", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.21730", "html_url": "https://arxiv.org/abs/2504.21730", "title": "Cert-SSBD: 针对样本特异性平滑噪声的认证后门防御", "title_en": "Cert-SSBD: Certified Backdoor Defense with Sample-Specific Smoothing Noises", "authors": "Ting Qiao,Yingjia Wang,Xing Liu,Sixing Wu,Jianbin Li,Yiming Li", "background": "深度神经网络（DNNs）容易受到后门攻击，攻击者通过操纵一小部分训练数据来植入隐藏的后门。这些受损模型在干净样本上表现正常，但在受后门污染的样本上会将它们误分类为攻击者指定的目标类别，对实际DNN应用构成严重威胁。当前，虽然已经提出了一些经验上的防御方法来减轻后门攻击，但它们常被更高级的后门技术绕过。相比之下，基于随机化平滑的认证防御因其在训练和测试样本中添加随机噪声来对抗后门攻击而显示出潜力。然而，现有的随机化平滑防御假设所有样本到决策边界的距离相同，这在实践中可能并不成立，导致认证性能不理想。", "innovation": "本研究揭示了现有随机化平滑防御隐含地假设所有样本到决策边界的距离相同，但在实践中可能不成立的问题。为此，我们提出了一个样本特定认证后门防御方法，称为Cert-SSB（Cert-SSB：基于样本特定平滑噪声的认证后门防御）。Cert-SSB首先使用随机梯度上升优化每个样本的噪声量，以确保针对不同样本的不同噪声水平，然后将这些噪声应用于多个中毒训练集来重新训练多个平滑模型。之后，Cert-SSB整合了多个平滑模型的预测，生成最终的防篡改预测。此外，鉴于优化后的噪声因样本不同而不同，现有的认证方法变得不再适用。为此，我们引入了一种基于存储更新的认证方法，该方法动态调整每个样本的认证区域，提高了认证性能。", "conclusion": "我们在多个基准数据集上进行了大规模实验，证明了我们提出方法的有效性。我们的代码已在该网址提供：提供的网址。"}
{"llm_update_time": "20260221", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.00282", "html_url": "https://arxiv.org/abs/2505.00282", "title": "一种在不结构化数据中实现稳健高效推理的统一框架", "title_en": "A Unifying Framework for Robust and Efficient Inference with Unstructured Data", "authors": "Jacob Carlson,Melissa Dell", "background": "经济学家在分析非结构化数据（如文本、图像、音频、视频）时，通常会借助神经网络首先提取低维度的结构化特征。然而，神经网络所作的预测往往是带有偏见的，而这些偏见会传递给依赖其预测的结果估计量。此前，从非结构化数据中提取的结构化变量通常是作为替代变量对待的，这虽然在方法上有所妥协（默认接受任意测量误差），但在当前不断进化的AI技术环境下，这一做法面临诸多挑战。此外，研究人员在选择神经网络架构、训练数据或提示词及处理实施细节时拥有的自由度，可能会引发关于趋势偏误以及如何展示稳健性的担忧，而当前频繁弃用的专用神经网络表明了重现性的困难，因此，研究人员亟需一种原理性的方法来确定预测准确性的要求，以避免在改进这些预测时产生高昂成本。", "innovation": "本文构建了MAR-S（Missing At Random Structured Data）半参数缺失数据框架，该框架通过结合验证样本来矫正神经网络预测误差，从而实现非结构化数据的无偏、高效和稳健的因果推断。MAR-S框架综合并扩展了现有的利用机器学习预测进行偏差校正的推理方法，将该领域的问题与因果推理中的熟知问题相连接，突出这些领域的相似性。研究还开发了对描述性及因果性结构推断的健全体积和高效估计方法，尤其关注聚合和变换后的神经网络预测推断，这是现有文献中常见的一个场景。", "conclusion": "本文提出的MAR-S框架能够解决非结构化数据中的统计推断问题，通过矫正神经网络预测误差实现稳健高效推理，不仅提高了数据利用效率，还为实证研究提供了处理非结构化数据的创新途径。"}
{"llm_update_time": "20260221", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.02819", "html_url": "https://arxiv.org/abs/2505.02819", "title": "ReplaceMe: 通过深度修剪和转换器块线性化实现网络简化", "title_en": "ReplaceMe: Network Simplification via Depth Pruning and Transformer Block Linearization", "authors": "Dmitriy Shopkhoev,Ammar Ali,Magauiya Zhussip,Valentin Malykh,Stamatios Lefkimmiatis,Nikos Komodakis,Sergey Zagoruyko", "background": "传统的剪枝方法通常需要额外的训练或微调过程，而这会增加计算成本和时间开销。现有的一些剪枝方法在保留高性能的同时，可能会因为需要重新训练或微调而变得复杂且计算开销大。", "innovation": "ReplaceMe提出了一种无需训练的深度剪枝方法，它能够将转换器块用线性操作替代，同时保持在低压缩比时的高性能。这种方法只需要一个小规模的校准数据集来估计线性变换，这种变换接近于被剪枝的块。这种方法的优势在于，它可以在不添加额外网络参数的情况下，无缝地与剩余的转换器块结合。", "conclusion": "ReplaceMe在多个大型语言模型上实现了高达25%的剪枝，同时仍能保持约90%的原始模型性能，无需任何训练或修复步骤，从而减少了计算开销。该方法与现有的一些深度剪枝技术结合，并已提供开源库，可以在该链接下载：this https URL"}
{"llm_update_time": "20260221", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.06106", "html_url": "https://arxiv.org/abs/2412.06106", "title": "Efficient Context Propagating Perceiver Architectures for Auto-Regressive Language Modeling", "title_en": "Efficient Context Propagating Perceiver Architectures for Auto-Regressive Language Modeling", "authors": "Kaleel Mahmood,Shaoyi Huang", "background": "在Transformer架构中，注意力机制的复杂性呈二次方增长，这限制了对长序列的有效处理。许多最近的研究工作试图将注意力机制的时间复杂度$O(n^2)$降低到半线性复杂度，但仍在保留性能的同时降低复杂性方面存在挑战。Perceiver系列架构展示了出色的性能并降低了计算复杂性。", "innovation": "本文基于PerceiverAR架构，探索了保留上下文和减少注意力复杂性之间的不同权衡。为此，我们开发了四种新的架构范式，其中性能最佳的称为高效上下文传播Perceiver (ECP)。ECP架构相较于PerceiverAR有两个主要优势：首先，ECP架构通过利用自回归训练中的上下文和潜在序列克服了主要缺陷；其次，ECP架构的注意力复杂度与LongLoRA相同，计算效率更高；此外，ECP通过成对段落注意力提取更好的信息，从而提高语言建模能力。", "conclusion": "实证结果表明，ECP架构在Wikitext-103、PG-19和sCIFAR-10等基准数据集上显著优于其他最先进的Transformer模型。"}
{"llm_update_time": "20260221", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.04121", "html_url": "https://arxiv.org/abs/2503.04121", "title": "基于视网膜变换器的简单自组织映射", "title_en": "Simple Self Organizing Map with Vision Transformers", "authors": "Alan Luo,Kaiwen Yuan", "background": "视网膜变换器（ViTs）在各种视觉任务中表现出色，但在小型数据集上往往表现不佳，因为它们缺乏固有的归纳偏置。当前的方法常常通过将ViTs与前景任务配对或从卷积神经网络（CNNs）提取知识来增强先验知识，来隐式地解决这一局限性。相比之下，自组织映射（SOMs）作为一种广泛采用的自监督框架，擅长保持拓扑和空间组织，使其成为直接解决ViTs在有限或小型训练数据集限制的有效候选者。", "innovation": "本研究首次探讨了如何通过使视网膜变换器（ViTs）和自组织映射（SOMs）相互增强来弥补这一研究缺口。研究结果表明，这些架构可以协同提升彼此的表现，从而显著提高无监督和监督任务中的性能。", "conclusion": "试验代码可在GitHub上公开获取。"}
{"llm_update_time": "20260221", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.10444", "html_url": "https://arxiv.org/abs/2505.10444", "title": "使用非平衡最大熵法推断多体系统中的熵生成", "title_en": "Inferring entropy production in many-body systems using nonequilibrium maximum entropy", "authors": "Miguel Aguilera,Sosuke Ito,Artemy Kolchinsky", "background": "在高维随机系统中，包括多体系统和具有长记忆的非马尔可夫系统，标准的熵生成估算技术由于计算和统计限制变得难以处理。现有的方法无法有效估计这类系统的熵生成。", "innovation": "提出了一种方法，利用非平衡最大熵原理及其凸对偶性，仅通过轨迹观测值（如时空相关性）来推断轨迹级熵生成及其平均下的下界，无需重构高维概率分布或速率矩阵，也不需特殊假设，如离散状态或分立动态。此外，还可以进行熵生成的分层分解，反映不同相互作用阶数的贡献，并且能够直观地解释为“热力学不确定性关系”。", "conclusion": "该方法在1000个自旋的非平衡无序自旋模型和大型神经尖峰数据集上展示了数值性能。"}
{"llm_update_time": "20260221", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.17338", "html_url": "https://arxiv.org/abs/2503.17338", "title": "使用奖励特征捕捉个体人类偏好", "title_en": "Capturing Individual Human Preferences with Reward Features", "authors": "André Barreto,Vincent Dumoulin,Yiran Mao,Mark Rowland,Nicolas Perez-Nieves,Bobak Shahriari,Yann Dauphin,Doina Precup,Hugo Larochelle", "background": "通常情况下，强化学习从人类反馈中使用奖励函数来建模偏好，但这种奖励函数不区分不同的人。然而，该研究认为，在存在较大分歧的情景下，例如大语言模型的训练过程中，这种设计可能并不是一个好的选择。因此，作者正式提出了一个特殊奖励模型的问题，并分析了如何通过经验风险最小化原理来确保奖励模型依赖于训练样本数量和提供反馈的人数，从而减少近似误差。", "innovation": "作者利用一致性风险最小化原理推导出一个近似正确的边界的方程，这个方程表明了近似误差与训练样本数量及提供反馈的人数之间的依赖关系。此外，作者还提出了一种具体的自适应奖励模型架构，并巧妙地利用了个体偏好可表示为一组通用奖励特征线性组合的观察结果，实现了快速适应特定个体的需求。", "conclusion": "作者通过实验证实，其模型提供的益处随着评价者数量和其偏好差异性的增加而增加，并表明其模型在表现上优于非自适应基准及其他自适应替代方案。"}
{"llm_update_time": "20260221", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.10361", "html_url": "https://arxiv.org/abs/2502.10361", "title": "使用模型驱动的数据选择增强多语言大语言模型预训练", "title_en": "Enhancing Multilingual LLM Pretraining with Model-Based Data Selection", "authors": "Bettina Messmer,Vinko Sabolčec,Martin Jaggi", "background": "数据集的整理已成为支持强大大型语言模型（LLM）性能的基础。虽然存在多种规则过滤启发式方法用于英语和多语言数据集，但模型驱动的过滤技术主要集中在英语上。由于研究不足导致非英语语言数据集过滤方面的差距，该研究旨在开发一种适用于多语言数据集的模型驱动过滤框架，旨在识别具有多样性的结构化和知识丰富的样本。研究强调透明度、简单性和效率，通过基于Transformer和FastText的分类器来确保技术的广泛可访问性。", "innovation": "开发了一种模型驱动的数据选择框架，适用于多语言数据集，旨在识别具有多样性的结构化和知识丰富的样本。该方法利用Transformer-和FastText-基于的分类器，构建了一个可以广泛访问的方法和数据。研究在跨不同语言家庭、书写系统和资源可利用性的FineWeb-2网页抓取数据集上进行了全面的消融研究，以展示该方法的有效性。该研究还训练了一个1B参数的Llama模型，并证明了即使使用较少的训练令牌（仅占基础MMLU得分所需训练令牌的15%），该方法仍能匹配基线得分，同时也在其他基准测试中有所改进，并减轻了多语言性的诅咒。", "conclusion": "研究结果提供了该方法在其他语言中的通用性的强有力证据。因此，该框架扩展到20种语言，并发布了精炼的预训练数据集。"}
