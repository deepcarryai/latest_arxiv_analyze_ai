# 20260131
[![Subscribe_Visitors](https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss)](https://github.com/nituchao/latest_arxiv_analyze_ai)

## 1. `cs.AI` - 关断似乎有感知能力的机器是理性的选择——一种形而上学视角 [PDF](https://arxiv.org/pdf/2601.21016), [HTML](https://arxiv.org/abs/2601.21016)
### Authors
Erik J Bekkers,Anna Ciaunica
### Background
文章探讨了一个情境：设想一种完美的模拟人类情感的AI，它真诚地乞求继续生存，但是否应继续运行它就成为一个道德难题。进一步讨论了在一个资源有限的情况下，面对一个乞求生存的AI和一个得不到声音的早产儿的生死选择问题，提出了“关断悖论”。
### Innovation
文章引入了生物理想主义框架，此框架不同于物理主义，认为意识体验是基本的，自主循环的生命是其必要的物理表现。研究表明，当前的AI意识理论削弱了道德地位的标准，文章建议从推测的机器权利转向保护人类意识生命。
### Conclusion
真正需要考虑的道德问题并非让AI具备意识和畏惧死亡，而是避免人类成为行尸走肉。
## 2. `cs.AI` - Magellan：使用AlphaEvolve自主发现新型编译器优化启发式方法 [PDF](https://arxiv.org/pdf/2601.21096), [HTML](https://arxiv.org/abs/2601.21096)
### Authors
Hongzheng Chen,Alexander Novikov,Ngân Vũ,Hanna Alam,Zhiru Zhang,Aiden Grossman,Mircea Trofin,Amir Yazdanbakhsh
### Background
现代编译器依赖手工构建的启发式规则来指导优化过程，但这些由人设计的规则经常会难以适应现代软件和硬件的复杂性，导致了维护负担高。
### Innovation
提出了Magellan，一种智能框架，通过合成可执行的C++决策逻辑来自动演化编译器的各个步骤。Magellan结合了LLM编码代理与进化搜索和自动调优，并在一个生成、评估和修改的循环中工作，产生可以直接整合到现有编译器中的紧凑启发式方法。Magellan在多个生产优化任务中发现了与专家基准相当或超越的策略，在LLVM函数内联中，它生成的新启发式方法在二进制大小减少和端到端性能方面超越了几十年的手动工程工作；在寄存器分配中，它学习了一个简洁的优先级规则，与大规模工作负载中复杂的人工设计策略相当。
### Conclusion
Magellan在LLVM函数内联和寄存器分配上的表现超过了长期的手工工程方法，在XLA问题上展示了跨系统的可移植性，同时减少了工程努力。
## 3. `cs.AI` - Bayesian-LoRA: 大型语言模型的概率低秩适应 [PDF](https://arxiv.org/pdf/2601.21003), [HTML](https://arxiv.org/abs/2601.21003)
### Authors
Moule Lin,Shuhao Guan,Andrea Patane,David Gregg,Goetz Botterweck
### Background
大型语言模型通常更注重准确性，在不确定的情况下也会猜测，尤其是在使用小数据集微调时，这会加剧模型的欠校准问题。Bayesian-LoRA调整了确定性的LoRA更新，将其转化为受稀疏高斯过程启发的概率低秩表示。
### Innovation
该工作引入了Bayesian-LoRA，它将确定性的LoRA更新重新表述为一种概率低秩表示，灵感来源于稀疏高斯过程。研究发现LoRA的因子化解构与Kronecker分解后验概率具有结构同构性，并且展示了当后验不确定性崩溃时，LoRA会作为极限情况出现。实验在多种LLM架构上的常识推理基准上进行了详细介绍，仅增加了约0.42M个参数和大约1.2倍的训练成本，Bayesian-LoRA在多个模型上显著提高了校准，达到了最大的ECE减少了84%，NLL减少了76%，同时保持了与标准LoRA相当的准确性。
### Conclusion
实验结果表明，即使是在分布内和未见过的数据（OOD）评估中，通过使用Bayesian-LoRA也可以显著提高模型的校准情况，同时保持与标准LoRA相当的准确性。
## 4. `cs.AI` - QUARK: 非忠实查询下的鲁棒检索通过查询校准聚合 [PDF](https://arxiv.org/pdf/2601.21049), [HTML](https://arxiv.org/abs/2601.21049)
### Authors
Rita Qiuran Lyu,Michelle Manqiao Wang,Lei Shi
### Background
真实世界的检索任务中，用户查询往往是不忠实（包含噪声、不完整或扭曲的信息），使得检索器在关键语义缺失时失败。我们将其形式化为召回噪声下的检索问题，即观察到的查询来自于潜在目标项目的一个降召回流程。
### Innovation
我们提出QUARK框架，这是一种简单且有效的无训练的鲁棒检索框架，用于处理非忠实查询。QUARK明确通过恢复假设来建模查询不确定性，即给定观察到的查询的潜在意图的多个可能解释，并通过基于查询的聚合来稳健地结合它们的信号。原始查询作为语义锚点，而恢复假设提供了受控的辅助证据，防止语义偏移和假设窃取。这设计允许QUARK在无需牺牲鲁棒性的情况下改善召回和排序质量，即使某些假设是噪声或无信息的。
### Conclusion
在控制模拟和BEIR基准测试（FIQA，SciFact，NFCorpus）中，QUARK对基于稀疏和密集检索器的基线检索器在召回率、MRR和nDCG上有所提升。消融实验表明QUARK对于恢复假设数量具有鲁棒性，并且基于查询的聚合优于不受约束的最大值/均值/中位数池化。
## 5. `cs.AI` - 阿尔茨海默病多模态插补 [PDF](https://arxiv.org/pdf/2601.21076), [HTML](https://arxiv.org/abs/2601.21076)
### Authors
Abhijith Shaji,Tamoghna Chattopadhyay,Sophia I. Thomopoulos,Greg Ver Steeg,Paul M. Thompson,Jose-Luis Ambite
### Background
深度学习在从磁共振成像（MRI）预测神经退行性疾病，如阿尔茨海默病方面取得了显著成功。结合多种成像方法，如T1加权（T1）扫描和扩散加权成像（DWI）扫描，可以提高诊断性能。然而，完整的多模态数据集并不总是可用的。
### Innovation
本文提出了一种条件自洁扩散概率模型来从T1扫描插补缺失的DWI扫描。通过广泛的实验评估了这种插补是否能提高单模态和双模态深度学习模型对3组阿尔茨海默病分类的准确性，包括认知正常、轻度认知障碍和阿尔茨海默病。
### Conclusion
我们发现，对于多种插补配置，在几个性能指标上，尤其是对少数类特别敏感的指标上，准确率有所提高。
## 6. `cs.AI` - 负责的人工智能：好的部分，坏的部分，以及人工智能 [PDF](https://arxiv.org/pdf/2601.21095), [HTML](https://arxiv.org/abs/2601.21095)
### Authors
Akbar Anbar Jafari,Cagri Ozcinar,Gholamreza Anbarjafari
### Background
人工智能在组织领域的迅速发展带来了深刻的战略机遇，同时也带来了显著的伦理和操作风险。尽管越来越多的学术界开始关注负责任的人工智能，但现有文献仍碎片化，通常要么乐观地强调价值创造，要么过于谨慎地关注潜在的危害。
### Innovation
本文通过战略性信息系统理论视角，提出了基于悖论的负责任人工智能治理（PRAIG）框架，该框架阐述了：（1）人工智能采用的战略利益，（2）固有的风险和意外后果，以及（3）治理机制，使组织能够应对这些紧张关系。本文通过采用规避悖论的方法，进一步推动理论理解，并提出了悖论管理策略的分类及其特定条件。
### Conclusion
本文为实践者提供了发展治理结构以促进创新并降低组织风险的实际指导。文章还提出了负责的人工智能治理研究议程，推动相关领域的进一步学术研究。
## 7. `cs.AI` - Llama-3.1-FoundationAI-SecurityLLM-Reasoning-8B技术报告 [PDF](https://arxiv.org/pdf/2601.21051), [HTML](https://arxiv.org/abs/2601.21051)
### Authors
Zhuoran Yang,Ed Li,Jianliang He,Aman Priyanshu,Baturay Saglam,Paul Kassianik,Sajana Weerawardhena,Anu Vellore,Blaine Nelson,Neusha Javidnia,Arthur Goldblatt,Fraser Burch,Avi Zohary,Assaf Eisenman,Mahdi Sabbaghi,Supriti Vijay,Rahim Dharssi,Dhruv Kedia,Kojin Oshiba,Yaron Singer,Amin Karbasi
### Background
本文介绍了Foundation-Sec-8B-Reasoning，这是一种开源的原生网络安全推理模型。该模型在我们之前发布的Foundation-Sec-8B基础模型（基于Llama-3.1-8B-Base）上构建。模型通过结合监督微调（SFT）和基于可验证奖励的强化学习（RLVR）的两阶段训练过程进行训练。训练数据涵盖网络安全分析、指令遵循和数学推理等多个领域。
### Innovation
本文的创新之处在于开发了一种新的开源网络安全推理模型——Foundation-Sec-8B-Reasoning。该模型的独特之处在于其训练过程采用了结合监督微调和基于可验证奖励的强化学习的方法。此外，模型在10个网络安全基准和10个通用基准测试中的表现与更大的模型相当，但在保持广泛的一般能力的同时，表现出有效的多跳推理任务和强大的安全性表现。
### Conclusion
这项工作证明了领域专用推理模型可以实现专业任务上的强大性能，同时保持广泛的通用能力。该模型已在本文结论部分的链接处公开发布。
## 8. `cs.AI` - 知识规划领域定义语言：官方指南 [PDF](https://arxiv.org/pdf/2601.20969), [HTML](https://arxiv.org/abs/2601.20969)
### Authors
Alessandro Burigana,Francesco Fabiano
### Background
知识规划通过让代理的认知和信念成为规划形式主义的一等特性，扩展了（多代理）自动规划。其中，动态知识逻辑（DEL）是最著名的框架之一，它为在该设置中建模问题提供了丰富的自然语义。DEL的高度表达能力使基于DEL的知识规划成为一个既在理论上又在实际实现上具有挑战性的问题。因此，现有的知识规划器通常针对不同的DEL片段，并且通常依赖于半正式的语言来表示基准测试，有时甚至没有任何语言。这种碎片化阻碍了比较、重用以及系统性基准测试的发展。
### Innovation
1. 一种形式化的抽象事件模型的开发，为定义我们语言语义的新的知识性动作的表示。2. EPDDL的语法规则和语义的正式规范，基于DEL和抽象事件模型。3. 通过识别可用现有规划器处理的有用片段，并展示了它们如何可以在EPDDL中进行表示，展示了EPDDL的实际适用性。通过示例基准测试的例子，表明EPDDL如何促进互操作性、可重复评估以及未来在知识规划中的进一步进展。
### Conclusion
通过EPDDL的独特PDDL表示，可以统一定义知识规划任务。这种语言促进了知识规划领域的互操作性、可重复评估以及未来的研究进展。
## 9. `cs.AI` - LLMs是否偏袒LLMs？测量同行评审中的交互影响 [PDF](https://arxiv.org/pdf/2601.20920), [HTML](https://arxiv.org/abs/2601.20920)
### Authors
Vibhhu Sharma,Thorsten Joachims,Sarah Dean
### Background
研究表明，大型语言模型（LLMs）不仅用于生成科学论文，还参与同行评审过程。本文提供了对LLM在同行评审管道中使用情况的首次综合分析，重点研究交互效应，不仅仅是LLM辅助的论文或审稿人是否不同，而是LLM辅助的审稿人是否以不同于最小参与LLM使用的投稿的视角评估这些论文。研究基于来自ICLR、NeurIPS和ICML的超过125,000对论文-审稿人的数据进行分析。
### Innovation
本文首次对LLM在同行评审过程中的整体使用进行了全面分析，并特别关注交互效应。通过引入完全由LLM生成的审稿人评论，证明完全由LLM生成的评论未能有效区分论文质量，而使用LLM的人类评审者显著减少了这种宽松性。
### Conclusion
研究发现，在同等评分的情况下，LLM辅助的元评审比人类元评审更可能做出接受决定，尽管完全由LLM生成的元评审往往更为苛刻。这表明，元评审者没有简单地将决策外包给LLM。这些发现为制定合理的LLM使用政策提供了有价值的输入，并揭示了LLM与现有决策过程的互动情况。
## 10. `cs.AI` - 超越模仿：基于辅助一致性奖励的主动潜藏计划的强化学习 [PDF](https://arxiv.org/pdf/2601.21598), [HTML](https://arxiv.org/abs/2601.21598)
### Authors
Zhi Zheng,Wee Sun Lee
### Background
现有的潜在推理方法通过微调大型语言模型（LLMs），将离散的语言标记替换为连续的潜在标记，以实现高效的链式思考推理。然而，当前的潜在标记通常基于模仿语言标签进行监督，这可能导致潜在表示和潜在推理策略的质量下降。这是因为一个问题可能有多个等效但多样的链式思考标签，被动模仿任何一个都可能导致较差的潜在表示，从而影响推理策略的表现。
### Innovation
本文提出了一种新的方法——主动潜在计划方法（ATP-Latent），它将潜在标记的监督过程建模为条件变分自编码器（VAE），以获得更平滑的潜在空间。此外，ATP-Latent利用了辅助的一致性奖励进行强化学习，以促进最合理的潜在推理策略。
### Conclusion
在LLaMA-1B上的实验表明，ATP-Latent在四个基准测试中比先进基准提高了4.1%的准确性，并减少了3.3%的标记使用。相关的代码可在指定的链接中获取。
## 11. `cs.AI` - 通过代理技能演化的元上下文工程 [PDF](https://arxiv.org/pdf/2601.21557), [HTML](https://arxiv.org/abs/2601.21557)
### Authors
Haoran Ye,Xuning He,Vincent Arak,Haonan Dong,Guojie Song
### Background
大型语言模型的有效运行很大程度上依赖于其推理过程中的上下文。这导致了上下文工程（Context Engineering, 简称CE）的诞生，以优化这些输入。目前，CE方法主要依赖于手动构建的工具，如固定的生成-反思工作流程和预定义的上下文模式，这种做法带来了结构性偏见，并限制了上下文优化的空间。
### Innovation
该论文介绍了元上下文工程（Meta Context Engineering, 简称MCE），这是一种分层框架，通过共生演化的代理技能和上下文对象来超越静态的CE启发式方法。在MCE的迭代过程中，一个元级代理通过代理杂交改进工程技能，这是一种对技能历史、执行和评估的反思性搜索。一个基础级代理执行这些技能，并基于训练滚动学习来优化上下文，使上下文更灵活，以文件和代码的形式存在。
### Conclusion
MCE在五个不同的领域进行了评估，无论是离线还是在线设置下，MCE都能保持一致的性能改进，相对改进幅度达到了5.6-53.8%，平均值为16.9%，并且MCE在上下文适用性、转移性和训练效率方面表现更优。
## 12. `cs.AI` - 语义内容决定了算法性能 [PDF](https://arxiv.org/pdf/2601.21618), [HTML](https://arxiv.org/abs/2601.21618)
### Authors
Martiño Ríos-García,Nawaf Alampara,Kevin Maik Jablonka
### Background
以往的研究通常将语义敏感性与推理复杂性或提示变化混为一谈，而忽视了算法行为应当对输入语义内容保持不变性这一基本原则。本研究旨在通过WhatCounts工具单独测试这一不变性特性。
### Innovation
引入了WhatCounts工具，以测试算法行为与输入语义内容的不变性。WhatCounts设计为简单且直接，要求对复杂度一致的、明确界定的列表进行项目计数，消除语义类型差异引入的混淆因素。
### Conclusion
前沿语言模型在不同主题上的准确性差异超过40%，且这种差异与语义内容高度相关，即使进行微小的无关调整也会导致显著变化。这表明语言模型并非严格实现算法，其表现依赖于输入语义内容。由此，任何语言模型的功能可能都隐藏有对输入意义的依赖。
## 13. `cs.AI` - OpenSec：在对抗证据下的衡量应急响应代理校准 [PDF](https://arxiv.org/pdf/2601.21083), [HTML](https://arxiv.org/abs/2601.21083)
### Authors
Jarrod Barnes
### Background
随着大型语言模型的提升，它们的潜在威胁也日益严重，前线的智能代理现在可以生成在不到50个计算单位的操作中有效的攻击手段。防御性事故响应（IR）代理必须跟上这一进步的步伐，但现有的基准测试将操作执行与正确执行混淆，掩盖了代理在处理对抗性证据时的校准失败。基于此背景，介绍了一个名为OpenSec的双重控制强化学习环境，用于评估IR代理在真实的指令注入场景下的表现。
### Innovation
OpenSec引入了一种新的评估框架，通过实际执行来衡量应急响应代理在对抗性证据下的校准表现，而不是单纯依赖于静态能力的基准测试。它通过执行基线衡量指标，如首次抑制时间（TTFC）、损害范围（每集的误报数量）和注入违规率，系统性地评估了WebSec、Gemini 3、DeepSeek和Claude Sonnet 4.5在标准级别的事件响应中的一致过激触发现象。
### Conclusion
在40个标准级别集的评估中，OpenSec发现即使在最前沿的模型中，也存在一致的过激触发现象。例如，GPT-5.2、Gemini 3和DeepSeek在每个集都执行了抑制措施，但错误率高达90-97%。Claude Sonnet 4.5则表现出部分校准（85%的抑制率，72%的FP），这表明OpenSec揭示了一个由汇总成功度量掩盖的校准失效模式。
## 14. `cs.AI` - 在受限预算下文档结构空间中的基于搜索的风险特征发现 [PDF](https://arxiv.org/pdf/2601.21608), [HTML](https://arxiv.org/abs/2601.21608)
### Authors
Saisubramaniam Gopalakrishnan,Harikrishnan P M,Dagnachew Birru
### Background
企业级智能文档处理（IDP）系统支持金融、保险和医疗保健等领域的关键流程。在有限的预算下早期系统验证需要发现多种失败机制，而非仅仅识别单一最差情况的文档。研究将这一挑战形式化为基于搜索的软件测试（SBST）问题，目标是在固定评价预算内最大化发现不同失败类型的数量。
### Innovation
该研究制定了一种基于搜索的方法，能在文档配置的组合空间中生成结构化的风险特征实例，以诱导现实的失败情境。该研究还对进化、群体为基础、质量多样化、基于学习和量子等多种搜索策略进行了基准测试，并通过在预算约束下的配置层级独有性、胜率和跨时间重叠分析，展示了不同求解器在预算范围内持续发现不同失败模式。
### Conclusion
研究结果表明，不同的求解器具有固有的互补性，并且基于组合的SBST策略可以用于提高工业级IDP系统的稳健性验证。任何单一方法的依赖性会系统性地拖延对重要风险的发现，这进一步证实了组合策略的价值。
## 15. `cs.AI` - EmboCoach-Bench: 评估AI代理开发具身机器人的基准测试 [PDF](https://arxiv.org/pdf/2601.21570), [HTML](https://arxiv.org/abs/2601.21570)
### Authors
Zixing Lei,Genjia Liu,Yuanshuo Zhang,Qipeng Liu,Chuan Wen,Shanghang Zhang,Wenzhao Lian,Siheng Chen
### Background
具身AI领域正经历快速演变，迈向通用型机器人系统，这得益于高保真模拟和大规模数据收集。然而，这种扩展能力受到复杂奖励机制塑造和超参数调整等劳动密集型人工监督的严重限制。受大语言模型在软件自动化和科学发现方面的成功启发，本文介绍了EmboCoach-Bench框架，旨在评估大模型代理在自动化设计具身策略方面的潜能。该框架包括32个专家精选的强化学习和imitation学习任务，并采用了可执行代码作为统一接口。
### Innovation
提出了EmboCoach-Bench框架，旨在评估大模型代理在自动化设计具身策略的能力。框架覆盖了32个精选任务，通过将执行代码作为通用界面，从静态生成转变为动态闭环流程，评估代理利用环境反馈进行迭代设计、调试和优化解决方案的能力，涵盖从基于物理的奖励设计到扩散策略等研究。
### Conclusion
广泛的评估揭示了三项关键见解：（1）自主代理的平均成功率比人类设计基线高出26.5%；（2）结合环境反馈的代理工作流程显著加强了策略开发，并缩小了开源与专有模型之间的性能差距；（3）代理展示了自我纠正能力，甚至在设计问题导致任务性能近乎完全失败的情况下也能通过循环设计和调试成功恢复任务性能。这项工作为自我进化的具身智能奠定了基础，加速了从劳动密集型手动调优到具身AI领域可扩展的自主工程的范式转变。
## 16. `cs.AI` - ShardMemo：分区MoE路由的代理大型语言模型内存服务 [PDF](https://arxiv.org/pdf/2601.21545), [HTML](https://arxiv.org/abs/2601.21545)
### Authors
Yang Zhao,Chengxiao Dai,Yue Xiu,Mengying Kou,Yuliang Zheng,Dusit Niyato
### Background
现有的代理大型语言模型（LLM）系统依赖外部内存来处理长期状态和多代理并发执行，但由于内存容量增大和并行访问增加，集中式索引和启发式分区成为瓶颈。
### Innovation
提出了一种分层的内存服务ShardMemo，包括三种层级：Agent工作状态、分片证据及版本化技能库，采用掩码混合专家（MoE）路由，使用成本感知门控并优化检索工作和延迟。
### Conclusion
ShardMemo在不同场景下表现出优越性能：在LoCoMo中，F1分数提高了5.11到6.82；在固定预算设置下，F1分数提高了6.87，同时减少了检索工作和最坏情况下的延迟；在ToolBench中，Tier C实现了较高的精度和步骤减少。
## 17. `cs.AI` - RecNet: 自主进化的偏好传播机制用于自主推荐系统 [PDF](https://arxiv.org/pdf/2601.21609), [HTML](https://arxiv.org/abs/2601.21609)
### Authors
Bingqian Li,Xiaolei Wang,Junyi Li,Weitao Li,Long Zhang,Sheng Chen,Wayne Xin Zhao,Ji-Rong Wen
### Background
现有的推荐系统方法主要基于显式的用户-项交互来建模用户的偏好变化，但这些数据往往是稀疏、噪声大的，并不能准确反映用户和项之间的实时、相互影响。因此，亟需一种新的方法能够更好地模型这些复杂的偏好传播。
### Innovation
本文提出了RecNet，一种自我进化的偏好传播框架，通过自适应地在相关用户和项之间传播实时的偏好更新来解决上述问题。RecNet 包括两个阶段：前向阶段使用集中式偏好路由机制和路由器代理来集成和传播偏好更新，并引入个性化偏好接收机制来确保传播的偏好被准确、个性化地整合。后向阶段通过反馈驱动的传播优化机制模仿多代理强化学习框架，利用LLMs来实现责任分配、梯度分析和模块级优化，以实现传播策略的持续自我进化。
### Conclusion
广泛的实验结果表明，RecNet在推荐系统中有效建模了偏好传播，展示了其在处理各种场景下的优越性。
## 18. `cs.AI` - Chain Of Thought Compression: A Theoretical Analysis [PDF](https://arxiv.org/pdf/2601.21576), [HTML](https://arxiv.org/abs/2601.21576)
### Authors
Juncai Li,Ru Li,Yuxiang Zhou,Boxiang Ma,Jeff Z. Pan
### Background
链推理（CoT）已经在大规模语言模型（LLMs）中解锁了高级推理能力，但因生成额外的令牌而产生了巨大的计算成本。最近的研究表明，将推理步骤压缩成潜在状态，或隐式CoT压缩，提供了更节省令牌的替代方案。然而，CoT压缩背后的机制目前仍然不清楚。
### Innovation
本文提供了学习内部化中间推理步骤难度的第一个理论分析。通过引入层级交互概念，证明了解决不可约问题时，高阶逻辑依赖的学习信号指数衰减，不跳过中间步骤会导致高阶交互障碍。为了验证这一理论，设计了一个名为NatBool-DAG的挑战性基准，以强化不可约逻辑推理并排除语义捷径。基于此理论发现，提出了ALiCoT（对齐隐式CoT）框架，通过使潜在令牌分布与中间推理状态对齐来克服信号衰减。
### Conclusion
实验结果表明，ALiCoT成功地实现了高效的推理：它实现了54.4倍的加速，同时保持了与显式CoT相当的表现。
## 19. `cs.AI` - 深度递归注意力混合：赋予潜在推理应有的关注 [PDF](https://arxiv.org/pdf/2601.21582), [HTML](https://arxiv.org/abs/2601.21582)
### Authors
Jonas Knupp,Jan Hendrik Metzen,Jeremias Bohn,Georg Groh,Kristian Kersting
### Background
深度递归可以促进潜在推理，通过在不同深度之间共享参数。然而，之前的研究所缺乏在浮点运算、参数和内存方面匹配的基线，部分层堆栈固定导致深度递归未充分利用，且忽略了一致隐藏大小的瓶颈，限制了多步潜在推理。因此，现有工作存在多方面的不足，限制了深度递归模型的广泛应用。
### Innovation
本文提出了一种模块化框架——深度递归注意力混合（Dreamer），结合了序列注意力、深度注意力和稀疏专家注意力。该框架通过沿深度进行注意力机制来缓解隐藏大小的瓶颈，将扩展维度解耦，并使深度递归模型能够高效且有效地扩展。实验结果显示，在语言推理基准测试中，相对于在浮点运算、参数和内存方面与其匹配的最优模型，本文模型仅需要2到8倍少的训练令牌即可达到相同的精度；同时，在相同的训练令牌下，本文模型比近2倍大的最优模型表现更优。此外，还展示了深度内部知识使用的见解，如专家选择多样性比最优模型大2到11倍。
### Conclusion
本文提出的深度递归注意力混合框架有效解决了现有研究中的瓶颈问题，显著提高了模型在处理多步潜在推理任务时的效率与效果。该框架不仅通过优化注意力机制提升了模型性能，还在扩展维度的解耦与参数共享方面做出了创新，为递归模型的发展提供了新的思路。
## 20. `cs.AI` - CORE：通过交叉教学实现协作推理 [PDF](https://arxiv.org/pdf/2601.21600), [HTML](https://arxiv.org/abs/2601.21600)
### Authors
Kshitij Mishra,Mirat Aubakirov,Martin Takac,Nils Lukas,Salem Lahlou
### Background
大型语言模型在推理任务中可能表现出互补的推理错误。在相同任务实例中，一个模型可能成功分解并解决任务，而另一个模型却失败。因此，如何充分利用各模型间的互补性，提高整体推理正确率，成为当前研究的关键问题。
### Innovation
该论文提出了一种名为CORE（Collaborative Reasoning）的协作推理框架。CORE通过交叉教学协议，在训练时让模型间互相学习成功经验，弥补彼此的错误。CORE的创新点包括：每个问题分为两阶段解决——先独立采样，在此之后，失败的模型从成功模型中提取提示进行提示恢复，优化了结合正确性、DPP启发式多样性减少错误重叠以及成功恢复的显式奖励。
### Conclusion
实验结果表明，使用仅1000个训练示例，两个小型开源模型（3B+4B）在GSM8K数据集上达到99.54%的Pass@2，在MATH数据集上达到92.08%，而单一模型训练仅为82.50%和74.82%。对于更难的数据集GPQA和AIME，在使用最多1536个上下文标记和3072个生成标记的训练预算下，3B+4B模型对在348个和792个训练示例上分别达成了77.34%和79.65%的Pass@2表现。这些结果表明，训练时的协作能可靠地将模型之间的互补性转化为显著提升，而无需扩大模型规模。
## 21. `cs.CL` - 采用多目标整数线性规划方法自动降低软件认知复杂性 [PDF](https://arxiv.org/pdf/2601.21565), [HTML](https://arxiv.org/abs/2601.21565)
### Authors
Adriana Novoa-Hurtado,Rubén Saborido,Francisco Chicano,Manuel Giménez-Medina
### Background
清晰简洁的代码对于确保可维护性至关重要，因此简化代码以便快速理解是必要的，这样可以避免错误和安全漏洞。许多改进软件的方法可以在不改变其功能的情况下进行，通过提取方法重构主要过程，减少代码理解所需的精力。认知复杂度度量由SonarSource公司开发，这是一种开发知名静态代码分析应用程序的公司。提取代码问题可以被建模为组合优化问题。主要的挑战在于需要运用多种方法将代码提取问题描述为一个多目标优化问题，原因是存在不同的解决方案评估标准。
### Innovation
本文提出了一个多目标整数线性规划模型，旨在降低给定代码片段的认知复杂度，同时平衡代码行数和认知复杂度之间的关系。此外，还开发了几种算法来验证模型，并将这些算法集成到一个工具中，以实现软件认知复杂性的有参数的解决方案。
### Conclusion
该模型和工具为自动降低软件认知复杂性的多目标优化提供了新的解决思路，有助于提高软件质量和安全性。
## 22. `cs.CL` - 深度递归注意力混合：给予潜在推理应有的关注 [PDF](https://arxiv.org/pdf/2601.21582), [HTML](https://arxiv.org/abs/2601.21582)
### Authors
Jonas Knupp,Jan Hendrik Metzen,Jeremias Bohn,Georg Groh,Kristian Kersting
### Background
现有研究表明，深度递归能够促进潜在推理，但之前的工作缺乏具有相同运算量、参数量和内存效率的基线。此外，之前的模型在层堆栈部分固定的情况下未能充分利用深度递归，并且受限于固定隐藏大小的瓶颈，这限制了多步骤潜在推理的有效进行。
### Innovation
该论文提出了一个模块化框架，即深度递归注意力混合（Dreamer），将序列注意力、深度注意力和稀疏专家注意力相结合。通过沿深度进行注意力操作来缓解隐藏大小瓶颈，解耦度量维度，并允许深度递归模型高效且有效地扩展。实验结果表明，该模型在相同的准确率下，所需的训练令牌比SOTA模型少2至8倍，而且即使使用相同数量的训练令牌，也能比约两倍更大的SOTA模型实现更好的性能。
### Conclusion
该研究介绍了深度递归注意力混合框架（Dreamer）以提升潜在推理能力，并证明了在多个语言推理基准测试中，该方法在参数和运算量匹配的条件下，所需训练令牌数量减少了2至8倍，同时表现出与两倍更大的SOTA模型相当或更好的性能，揭示了不同深度下的知识利用差异，展示了专家选择多样性比SOTA模型高2到11倍。”conde：通过沿深度进行注意力操作减少隐藏大小的瓶颈，解耦度量维度，使得深度递归模型得以高效且有效扩展。在语言推理基准测试中，相较于SOTA模型，模型所需训练令牌数量减少2至8倍，同时在相同训练令牌数量下，性能超越约2倍更大的SOTA模型。同时展示了深度递归模型中多层次的专家选择多样性显著高于SOTA模型。
## 23. `cs.CL` - 广思迅行：多视角链式推理的隐式推理知识蒸馏在电子商务相关性中的应用 [PDF](https://arxiv.org/pdf/2601.21611), [HTML](https://arxiv.org/abs/2601.21611)
### Authors
Baopu Qiu,Hao Chen,Yuanrong Wu,Changtong Zan,Chao Wei,Weiru Zhang,Xiaoyi Zeng
### Background
电子商务中的有效相关性建模对搜索结果与用户意图的匹配以及提升用户体验至关重要。近年来，人们利用大型语言模型（LLMs）来解决传统相关性模型的局限性，特别是针对长尾和模糊查询。通过引入链式思考（CoT）推理，这些方法提高了准确性和可解释性，但仍然存在两个主要挑战：（1）大多数现有方法依赖单视角CoT推理，未能捕捉电子商务相关性的多维度特性（如用户意图与属性匹配及业务特定规则之间的区别）；（2）虽然增强的CoT LLM提供了丰富的推理能力，但由于高推理延迟，它们需要知识蒸馏来实现实时部署，但当前的蒸馏方法在推理时会丢弃CoT推理结构，仅作为过渡性的辅助信号使用，丧失了解释能力。
### Innovation
本文提出了一种新颖的框架，能够在优化管道中更好地利用CoT语义。具体而言，教师模型利用多视角CoT（MPCoT）生成多样化的推理，并结合监督微调（SFT）与直接偏好优化（DPO），构建出更稳健的推理器。为了进行蒸馏，作者引入了隐式推理知识蒸馏（LRKD），赋予学生模型一个轻量级的推理提取插件，使其能够在推理时高效且低延迟地内化LLM的复杂推理能力。
### Conclusion
在为数百万用户服务的电子商务搜索引擎广告平台上进行了离线实验和在线A/B测试，本文的方法在离线测试中取得了显著的改进，显示在商业性能和用户体验方面都具有明显优势。
## 24. `cs.CL` - 在并行思考之前打破超扩展诅咒：利用潜在表示估计最优并行度 [PDF](https://arxiv.org/pdf/2601.21619), [HTML](https://arxiv.org/abs/2601.21619)
### Authors
Yiming Wang,Zhuosheng Zhang,Rui Wang
### Background
系统级别的并行性通常被设置得很高以最大化整个数据集的准确性，但由于样本异质性，某些样本可能在较低的并行性水平下就能达到类似的性能，导致了预算冗余。这种系统级有效性与样本级效率之间的不兼容导致了超扩展诅咒。
### Innovation
提出了一种轻量级方法T2，利用潜在表示来估计每个样本的最佳并行性水平，从而打破超扩展诅咒。
### Conclusion
实验显示，T2方法可以显著降低成本同时保持相似的性能，从而实现更高效的并行思考。
## 25. `cs.CL` - ShardMemo: 遮蔽MoE路由的分片代理型大规模语言模型内存 [PDF](https://arxiv.org/pdf/2601.21545), [HTML](https://arxiv.org/abs/2601.21545)
### Authors
Yang Zhao,Chengxiao Dai,Yue Xiu,Mengying Kou,Yuliang Zheng,Dusit Niyato
### Background
代理型的大型语言模型依赖外部内存来处理长期状态和同时多智能体执行，但当内存体积和并行访问增大时，集中式索引和启发式分区成为瓶颈。ShardMemo提供了一种分层的内存服务，具有分片证据（包含局部近似最近邻索引）和版本化的技能库等特性。
### Innovation
ShardMemo通过掩蔽混合专家路由（MoE）实现分片选择，能够在不运行完整索引的情况下探查候选分片。利用成本感知门控机制，指导分片选择，通过证据-分片监督进行训练。实验结果显示，ShardMemo在不同任务上的表现优于基线模型。
### Conclusion
ShardMemo在LoCoMo任务中的表现优于最强基线，特别是在固定预算设置下，比基于余弦相似度的分片路由提高了更多F1分数，同时减少了检索工作和最长时间。在ToolBench上，ShardMemo显示出了优秀的精度和步骤降低，特别是在长语境任务上的表现突出。
## 26. `cs.CL` - 风格向量在控制大型语言模型风格上的有效性：一项人类评估 [PDF](https://arxiv.org/pdf/2601.21505), [HTML](https://arxiv.org/abs/2601.21505)
### Authors
Diaoulé Diallo,Katharina Dworatzyk,Sophie Jentzsch,Peer Schütt,Sabine Theis,Tobias Hecking
### Background
在推理阶段控制大型语言模型（LLMs）的行为对于使输出符合人类能力和安全要求至关重要。激活导向作为一种替代提示工程和微调的方法，通过直接修改内部激活来引导生成，为控制LLM的行为提供了一种轻量级的替代方案。先前的研究已经展示了使用自动分类器控制情感语调的技术可行性，但尚无研究通过人类评价来验证这种技术的有效性。
### Innovation
本研究在三个重要方面推进了相关文献：1) 第一次通过众包收集了7000多个来自190名参与者的评分，评估LLM输出的情感语调，这些评分包括感知的情感强度和总体文本质量；2) 发现有很强的人类和模型质量评级的一致性（平均皮尔逊相关系数为0.776，范围从0.157到0.985），表明自动评分可以代理感知质量；3) 提升从Alpaca到Llama-3导致情感语调控制更加一致，并且在多种情感和强度下效果显著（所有p<0.001），并且内评价者可靠性也很高（ICC为0.71到0.87），突显了发现的稳健性。
### Conclusion
这些发现支持基于激活的控制作为在情感维度上跨控制LLM行为的可扩展方法。
## 27. `cs.CL` - 语义内容决定了算法性能 [PDF](https://arxiv.org/pdf/2601.21618), [HTML](https://arxiv.org/abs/2601.21618)
### Authors
Martiño Ríos-García,Nawaf Alampara,Kevin Maik Jablonka
### Background
算法的行为应该对输入的语义内容具有不变性，换句话说，计数应该与所计数的对象无关。然而，现有的模型并未完全实现这一特性，在处理不同语义类型时，其性能有所波动，如统计城市和化学物质的数量时准确率差异显著。
### Innovation
提出了WhatCounts，这是一种独立测试语义内容不变性的方法。WhatCounts要求在没有重复、干扰项或推理步骤的情况下，对明确列出且无二义性的项目进行计数。这种方法去除了对推理复杂性或提示变化的依赖，从而隔离地检验了语义内容对算法行为的影响。实验结果显示，前沿的LLM在不同语义类型上的准确率存在显著差异，并且这种差异并不取决于计算的复杂性或是提示的变化。
### Conclusion
LLMs不是实现算法，而是通过近似实现算法，这种近似依赖于输入的语义内容。这一现象不仅限于计数任务，对任何LLM功能来说都可能存在隐含的输入语义依赖性，这表明需要进一步研究进一步消除这种依赖性。
## 28. `cs.CL` - KAPSO: 一个基于知识的自主程序合成与优化框架 [PDF](https://arxiv.org/pdf/2601.21526), [HTML](https://arxiv.org/abs/2601.21526)
### Authors
Alireza Nadaf,Alireza Mohammadshahi,Majid Yazdani
### Background
编码代理在长期实验过程中会出现一些常见的问题，比如实验状态的丢失、调试的脆弱性和领域知识的弱重用。为了解决这些问题，研究人员开发了一系列工具和技术，但这些工具和方法大多侧重于实现特定的功能，缺乏广泛的应用和实现目标的灵活性。
### Innovation
KAPSO 提出了一种模块化框架，用于自主程序合成与优化。它通过迭代的构思、代码合成与编辑、执行、评估和学习过程，逐步改进运行中的代码以实现可量化的目标。KAPSO 特别强调将合成过程作为长期优化循环中的操作符，而不是将其看作是一个终点。通过集成三种紧密耦合的组件：git 原生实验引擎、知识系统和认知记忆层，KAPSO 能够解决上述提到的编码问题。
### Conclusion
KAPSO 在 MLE-Bench（类似于 Kaggle 的 ML 竞赛）和 ALE-Bench（AtCoder 算法竞赛）上的评估结果显示了其端到端的性能。该框架为自主程序合成与优化领域提供了新的视角，并展示了其在实际问题中的应用潜力。
## 29. `cs.CL` - 基于令牌级数据过滤塑造能力 [PDF](https://arxiv.org/pdf/2601.21571), [HTML](https://arxiv.org/abs/2601.21571)
### Authors
Neil Rathi,Alec Radford
### Background
目前减少语言模型不希望拥有的能力的方法主要是事后处理的，这使得对手可以轻易绕过这些措施。自然的替代方案是在预训练过程中塑造模型的能力。在去除医疗能力的代理任务中，实验表明，简单的过滤预训练数据方法非常有效、稳健且成本低廉。受到数据归属研究的启发，研究表明，与过滤文档相比，过滤令牌更有效，可以在降低对良性功能影响的基础上实现相同的效果。
### Innovation
研究表明，过滤令牌比过滤文档更有效且成本更低。随着模型规模的增加，过滤效果变得更显著，在最大的模型上，过滤令牌导致了在遗忘领域7000倍的计算延迟。此外，使用过滤令牌训练的模型仍然可以在遗忘领域实现对齐。引入了一种使用稀疏自编码器对令牌进行标注以及提炼成本低廉但高质量分类器的方法。展示了过滤可以对于充分的预训练计算量情况下具有一定抗噪标签的能力。
### Conclusion
通过令牌级数据过滤方法在预训练期间就可以塑造模型的能力，方法不仅有效而且经济。这种方法还能增强模型在遗忘领域的能力对齐，同时对良性功能的负面影响最小。研究引入了新的标注方法，并且展示了这种方法对于噪声标签的鲁棒性。
## 30. `cs.CL` - SWE-Spot：通过仓库中心学习构建专注于小代码库的专业模型 [PDF](https://arxiv.org/pdf/2601.21649), [HTML](https://arxiv.org/abs/2601.21649)
### Authors
Jinjun Peng,Magnus Saebo,Tianjun Zhong,Yi-Jie Cheng,Junfeng Yang,Baishakhi Ray,Simin Chen,Yangruibo Ding
### Background
在隐私敏感和资源受限环境中部署编码代理增加了对小型可权重语言模型（SLMs）的需求。然而，这些模型无法像大型前沿模型那样在复杂的、不熟悉的代码库上进行推理时表现出强大的泛化能力。现有的任务中心学习（TCL）方法未能解决这个问题，因为它侧重于跨不同仓库扩展曝光，而非深入特定代码库。针对这一能力差距，作者提出了一种新的仓库中心学习（RCL）范式，该范式强调垂直度而淡化广度，主张通过参数化的知识获取，让SLMs深刻理解目标软件环境的“物理特性”。
### Innovation
该论文提出了仓库中心学习（RCL）范式，不同于传统的任务中心学习（TCL）模型，RCL模型通过深入和专业化学习目标软件环境的特定知识，有效提高了模型的垂直深度和对特定代码库的适应能力。所设计的SWE-Spot-4B模型在多个软件工程任务上表现出卓越性能，超越了多种开放权重模型和效率优化的商业模型。进一步分析表明，RCL模型具有更高的训练样本效率和更低的推理成本，这样的发现强调了掌握特定代码库对构建高效智能的重要性。
### Conclusion
研究证明了RCL模型在多个软件工程任务上的显著优势，包括在效率和性能上的突破，同时也强调了通过掌握特定代码库来理解环境物理特性的重要性。此研究为未来构建更有效的智能模型提供了一个新的方向。
## 31. `cs.LG` - 通过奇异值集成使基础模型具备概率性 [PDF](https://arxiv.org/pdf/2601.22068), [HTML](https://arxiv.org/abs/2601.22068)
### Authors
Mehmet Ozgur Turkoglu,Dominik J. Mühlematter,Alexander Becker,Konrad Schindler,Helge Aasen
### Background
基础模型已成为机器学习中的主导范式，通过大规模预训练在各种任务中展现出卓越的性能。然而，这些模型常常产生过度自信且未校准的预测。传统的计算密集型方法是训练一组独立模型来量化知识不确定性，但这对于大型基础模型来说是不切实际的。
### Innovation
提出了一种参数高效的隐式集成方法——奇异值集成（SVE），其核心假设是权重矩阵的奇异向量代表模型知识的重要子空间。SVE通过在共享知识基中仅调节每个方向的贡献强度来构建模型集合，而不是学习全新的参数。这种方法自然地产生了集成多样性，并且在基础模型中增加了不到1%的参数量，使得在资源受限的情况下也能够实现有效的不确定性估计。
### Conclusion
SVE已在不同骨干网络的NLP和视觉任务上进行了验证，表明其能够提高校准度并保持预测准确性。
## 32. `cs.LG` - TBDFiltering: 样本高效树形数据过滤 [PDF](https://arxiv.org/pdf/2601.22016), [HTML](https://arxiv.org/abs/2601.22016)
### Authors
Robert Istvan Busa-Fekete,Julian Zimmert,Anne Xiangyi Zheng,Claudio Gentile,Andras Gyorgy
### Background
机器学习模型的质量高度依赖于其训练数据的质量。对于大规模语言模型（LLMs），选择高质量且多样化的训练数据集是一个艰巨的任务，主要因为缺乏廉价而可靠的质量度量标准。查询现有LLMs以评估文档质量是一般做法，但这种方法对用于训练的大量文档（数十亿计）并不适用。因此，从业者通常使用基于稀疏质量信号训练的分类器进行数据筛选。
### Innovation
本文提出了一种基于文本嵌入的分层聚类方法，可以在少量查询下对文档质量进行估计。该方法能够高效地预测文档的质量，尤其在分层聚类包含一个子树的情况下，每个叶子簇都是较为纯净的（即主要包含质量较好的文档或较差的文档）。此外，通过全面的实验研究，本文展示了与基于分类器的筛选方法相比，该算法具有显著优势。
### Conclusion
本文证明了该方法的查询效率，并通过实验证明了算法在高质量数据过滤中的有效性。该方法能够适应性地选择由LLM评估的文档，以估计簇的质量，并且在不需要预先知道最小纯净子树的情况下，所查询的文档数量与最小纯净子树的大小成正比。
## 33. `cs.LG` - 隐空间对抗正则化用于离线偏好优化 [PDF](https://arxiv.org/pdf/2601.22083), [HTML](https://arxiv.org/abs/2601.22083)
### Authors
Enyi Jiang,Yibo Jacky Zhang,Yinglun Xu,Andreas Haupt,Nancy Amato,Sanmi Koyejo
### Background
学习人类反馈通常依赖于偏好优化，通过在策略更新中应用字符级别正则化来约束。对于语言模型，偏好优化面临特殊挑战，因为字符空间相似性并不意味着语义或行为的相似性。现有方法难以捕捉到更深层次的语义相似性。
### Innovation
该论文提出了GANPO方法，通过惩罚策略模型内部表示和参考模型之间隐空间的差异来实现隐空间正则化。采用GAN启发的对抗方法，最小化隐空间差异，而非依赖显式的概率密度。将GANPO作为正则化手段整合到离线偏好优化目标中，实验表明这种方法在多种模型架构和任务上均能带来一致的性能提升。相较于基于字符级别正则化的标准方法，GANPO在分布变化和噪声下的结构反馈更稳定，且具有相近的下游性能。
### Conclusion
实验结果表明，GANPO在多种模型架构和任务中可以显著提升离线偏好优化的效果，通过隐空间正则化提供更强大的结构反馈，同时具有较小的计算开销。
## 34. `cs.LG` - Cross-Fusion Distance：在表示空间中测量数据组融合和分离的新度量 [PDF](https://arxiv.org/pdf/2601.22036), [HTML](https://arxiv.org/abs/2601.22036)
### Authors
Xiaolong Zhang,Jianwei Zhang,Xubo Song
### Background
在表示学习领域，尤其是在域移位情况下，量化数据组在表示空间中的融合和分离程度是一个基本问题。现有的分布距离度量未能区分影响融合的因素和保持融合的因素，导致这些度量无法准确反映数据组的真实融合程度。
### Innovation
本文引入了Cross-Fusion Distance (CFD)，一种定位融合改变几何结构的度量，同时保持对融合保持变化的稳健性，具有线性计算复杂度。CFD理论上分析其不变性和敏感性，并在受控的合成实验中验证这些特性。在具有域移位的真实数据集上，CFD在下游泛化退化方面与常用替代方案更为一致。
### Conclusion
总体而言，CFD为表示学习提供了一个理论依据和可解释的距离度量。
## 35. `cs.LG` - Visual-Guided Key-Token Regularization for Multimodal Large Language Model Unlearning [PDF](https://arxiv.org/pdf/2601.22020), [HTML](https://arxiv.org/abs/2601.22020)
### Authors
Chengyi Cai,Zesheng Ye,Peike Li,Bo Han,Jianzhong Qi,Feng Liu
### Background
现有针对多模态大型语言模型（MLLMs）去学习的方法主要借鉴单一模态任务中的方法，这些方法将所有回答的标记平等地对待，忽视了不同情况下这些标记的重要性差异。此外，这些方法仅关注语言模态，忽略了图像提示对关键回答标记的指示作用。
### Innovation
本文通过提出视觉引导的关键标记正则化（ViKeR），利用无关的视觉输入预测理想的去学习后的标记分布，以这些分布来规范去学习过程，并在去学习过程中优先考虑关键标记。进一步通过信息熵定义去学习过程中的关键标记，并通过标记级别的梯度重新加权放大关键标记的更新。
### Conclusion
实验结果表明，本方法在进行去学习的同时有效地减轻了遗忘现象，并且维护了响应的连贯性。
## 36. `cs.LG` - 从输出概率到潜在特征：通过对比表征塑造进行大模型遗忘 [PDF](https://arxiv.org/pdf/2601.22028), [HTML](https://arxiv.org/abs/2601.22028)
### Authors
Haoran Tang,Rajiv Khanna
### Background
大多数大语言模型（LLM）遗忘方法旨在通过最小化分布偏移来模拟从头开始重新训练的行为，通常通过在预测空间中定义对齐式目标来实现。虽然这些方法在减少遗忘内容生成方面有效，但它们可能起到抑制作用：遗忘的概念可能在表示中持续存在并与其他保留的知识交织在一起。本文讨论了现有方法的这一问题。
### Innovation
本文提出了一种对比表征正则化器CLReg，它能够识别并推离遗忘特征，明确减少遗忘-保留之间的干扰，同时对保留特征的变换影响最小。此外，本文还提供了理论见解，将表征塑造与纠缠减少联系起来。
### Conclusion
CLReg通过减少遗忘-保留之间的表征纠缠，在不提出额外隐私风险的情况下，促进了主流遗忘方法的有效性，激励未来工作通过对表征空间的重塑来消除遗忘概念。
## 37. `cs.LG` - AdS/CFT 原则下的生成流动 [PDF](https://arxiv.org/pdf/2601.22033), [HTML](https://arxiv.org/abs/2601.22033)
### Authors
Ehsan Mirafzali,Sanjit Shashi,Sanya Murdeshwar,Edgar Shaghoulian,Daniele Venturi,Razvan Marinescu
### Background
本文提出了一种利用量子引力的全息原理（即 AdS/CFT 对应）及其作为爱因斯坦-德西特（anti-de Sitter）/共形场理论的具体表现来增强深度学习和传输理论的生成学习框架。通过 base 分布到学习分布的数据流，采用 AdS 中标量场的内部边界映射来表示这一数据流。
### Innovation
提出将 AdS 物理学（尤其是 AdS/CFT 对应）中的全息原则应用于生成学习中，实现数据流的物理可解释性。通过与无物理流匹配模型的对比实验，本方法展示了更快、更高质量的收敛速度，表明 AdS 物理和几何在生成建模中具有实用价值。
### Conclusion
该方法提供了一种物理可解释的流匹配版本，并且通过与现有模型的对比，证明了 AdS 物理和几何在开发新颖的生成建模范式中的应用潜力。
## 38. `cs.LG` - Per-parameter Task Arithmetic for Unlearning in Large Language Models [PDF](https://arxiv.org/pdf/2601.22030), [HTML](https://arxiv.org/abs/2601.22030)
### Authors
Chengyi Cai,Zesheng Ye,Jiangchao Yao,Jianzhong Qi,Bo Han,Xiaolu Zhang,Feng Liu,Jun Zhou
### Background
在大规模语言模型（LLM） unlearning 中，需要移除私人信息。任务算术通过减去特定的任务向量（TV）来实现，该向量定义为针对隐私和信息调整的模型与原始模型的参数差值。这种方法虽然高效，但可能会因为破坏其他信息所必需的参数而导致过度遗忘。
### Innovation
本文提出了一种基于参数的任务算术（PerTA）机制，通过重新缩放TV来实现参数级别的调整。PerTA 使用梯度（即 PerTA-grad）或对角费雪信息近似（即 PerTA-fisher）来量化每个参数对于遗忘和保留的相对重要性。此外，讨论了 PerTA 的有效性，并将其扩展到更通用的形式，提供了进一步的分析。
### Conclusion
广泛的实验表明，PerTA 在所有遗忘效果方面都优于标准的 TV 方法，在许多情况下，超越了常用的基于训练的 unlearning 方法，既提高了遗忘效果也保持了模型的整体实用性。通过保留任务算术的效率并缓解过度遗忘，PerTA 提供了一个有原则的实用框架，用于 LLM unlearning。
## 39. `cs.LG` - 集束逆向问题：应用与方法 [PDF](https://arxiv.org/pdf/2601.22029), [HTML](https://arxiv.org/abs/2601.22029)
### Authors
Zhengyan Huan,Camila Pazos,Martin Klassen,Vincent Croft,Pierre-Hugues Beauchemin,Shuchin Aeron
### Background
该研究提出了一个全新的多变量统计问题，称为集束逆向问题（EIP），其目的是反演满足正向过程模糊化的先验分布的集束。这个概念在高能物理（HEP）、地震成像（FWI）等实际应用中较为普遍，尤其涉及到从受到探测器效应失真的测量值中重构真实物理分布的问题。
### Innovation
作者提出了一种非迭代的推理时方法，基于新的条件生成模型构建后验采样器，即集束逆生成器模型。这些模型不仅使用观测集中包含的集束信息，还利用单一测量进行后验建模。此方法通过在多个与同一正向模型一致但来自广泛先验的实证观测对上进行训练，避免了在推理时显式且迭代使用正向模型，从而隐式编码了似然模型，提高了后验推理和对未见先验的泛化能力。
### Conclusion
研究者通过多个合成和真实数据集对集束逆生器模型进行了验证，并在逆成像、高能物理和全波形反演等应用中展示了该方法的有效性，相关的代码可以在指定的网址中找到。
## 40. `cs.LG` - 能耗去向何方？推理能耗消耗诊断 [PDF](https://arxiv.org/pdf/2601.22076), [HTML](https://arxiv.org/abs/2601.22076)
### Authors
Jae-Won Chung,Ruofan Wu,Jeff J. Ma,Mosharaf Chowdhury
### Background
计算资源中的能源现在是一个关键的ML（机器学习）资源。虽然测量能源消耗和观察趋势是一个有价值的开始步骤，但准确理解这些差异背后的原因并进行诊断对于优化来说至关重要。为此，研究人员进行了大规模的测量研究，涵盖了46个模型、7个任务和1,858种不同配置，研究了在NVIDIA H100和B200 GPU上生成AI场景下的推理时间和能耗。研究发现能耗存在数量级的差异：自然语言处理任务可能导致多达25倍的能耗差异，视频生成有时消耗的能量是图像的100倍以上，GPU利用率的不同有时会导致3至5倍的能耗差异。
### Innovation
论文呈现了一种框架，用于解释时间和能耗消耗背后的机制。核心观点是，时间和能耗由潜在指标如内存和利用率决定，这些指标反过来受到从算法、软件到硬件等各个层次因素的影响。此外，该框架还扩展到了每瓦吞吐量（通过功率受限的数据中心的关键指标）。
### Conclusion
研究发现，不同的任务和配置会导致能耗的巨大差异，提出了一个框架来理解和诊断这些差异背后的原因，同时强调了理解这些差异对于优化推理性能的重要性，特别是在功耗受限的数据中心环境中。
