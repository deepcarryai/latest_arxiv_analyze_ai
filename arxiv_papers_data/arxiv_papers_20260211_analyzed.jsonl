{"llm_update_time": "20260211", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2602.07055", "html_url": "https://arxiv.org/abs/2602.07055", "title": "空间理论：基础模型能否通过主动探索构建空间信念？", "title_en": "Theory of Space: Can Foundation Models Construct Spatial Beliefs through Active Exploration?", "authors": "Pingyue Zhang,Zihan Huang,Yue Wang,Jieyu Zhang,Letian Xue,Zihan Wang,Qineng Wang,Keshigeyan Chandrasegaran,Ruohan Zhang,Yejin Choi,Ranjay Krishna,Jiajun Wu,Li Fei-Fei,Manling Li", "background": "空间具备体智能要求代理在部分可观测性下通过行动获取信息。现有的多模态基础模型在被动感知方面表现出色，但在主动、自我导向的探索能力方面研究较少。", "innovation": "提出了一种新的概念——空间信念，定义为代理的主动获取信息并通过自主探索构建、修订和利用空间信念的能力。关键创新包括阶段性空间信念探查，促使模型在每一步揭示其内部的空间表示。", "conclusion": "通过评估基础模型，发现了一些关键瓶颈：主动-被动差距、探索效率低、感知稳定性较差以及信念惰性。结论指出，当前的基础模型在主动探索过程中难以维持连贯且可修订的空间信念。"}
{"llm_update_time": "20260211", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2602.07034", "html_url": "https://arxiv.org/abs/2602.07034", "title": "ST-Raptor: 一种半结构化表格问答的人工智能系统", "title_en": "ST-Raptor: An Agentic System for Semi-Structured Table QA", "authors": "Jinxiu Qu,Zirui Tang,Hongzhang Huang,Boyu Niu,Wei Zhou,Jiannan Wang,Yitong Song,Guoliang Li,Xuanhe Zhou,Fan Wu", "background": "半结构化表格问答是一个极具挑战的任务，需要精确提取单元格内容和位置，并准确恢复表格布局中隐含的关键逻辑结构、层次关系和语义关联。实践中，这些表格通常由人类专家手动解读，这既耗费劳动力又耗时。尽管现有方法，如Text-to-SQL，通常会将半结构化表格转换成结构化的格式，导致信息损失；存在信息不完整问题；而Text-to-Code和基于多模态LLM的问答方法在处理复杂布局时往往会给出不准确的答案。", "innovation": "提出了一种名为ST-Raptor的人工智能系统，该系统通过结合可视编辑、基于树的结构建模和代理驱动的查询解决，提供一种交互式的分析环境。实验结果表明，ST-Raptor在准确性和易用性上优于现有方法。", "conclusion": "ST-Raptor在基准数据集和真实世界数据集上的实验结果表明，该方法在准确性和用户体验方面均优于现有方法。其代码可在[该链接]获得，演示视频可在[该链接]获取。"}
{"llm_update_time": "20260211", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2602.07259", "html_url": "https://arxiv.org/abs/2602.07259", "title": "基于战略资源分配的AI安全激励视角：Stackelberg安全博弈方法", "title_en": "Incentive-Aware AI Safety via Strategic Resource Allocation: A Stackelberg Security Games Perspective", "authors": "Cheol Woo Kim,Davin Choo,Tzeh Yuan Neoh,Milind Tambe", "background": "随着AI系统的日益强大和自主，确保其安全性和可靠性不仅需要在模型层面进行对齐，还需要战略监督开发和部署时涉及的人们和机构。现有安全框架主要将这种对齐视为静态优化问题，忽略了数据收集、模型评估和部署过程中的动态、对抗性激励机制。", "innovation": "提出了一种基于Stackelberg安全博弈(SSGs)的新视角，这是一种针对不确定环境下对抗性资源分配的博弈论模型。将AI监督视为防御者（审计员、评估员和部署者）和攻击者（恶意参与者、未对准的贡献者或最坏情况故障模式）之间的战略性互动，为整个AI生命周期中的激励设计、有限监督能力和对抗不确定性提供了一个统一框架。", "conclusion": "这种框架可以应用于（1）训练时对数据/反馈污染的审计，（2）在有限评审资源下的预部署评估，以及（3）对抗环境中具有鲁棒性的多模式部署。将算法对齐和机构监督设计相结合，强调通过博弈论威慑可以使得AI监督主动、风险意识强且能够抵御操纵。"}
{"llm_update_time": "20260211", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2602.07032", "html_url": "https://arxiv.org/abs/2602.07032", "title": "LLM-FSM: 通过大规模语言模型扩展有限状态推理以实现RTL代码生成", "title_en": "LLM-FSM: Scaling Large Language Models for Finite-State Reasoning in RTL Code Generation", "authors": "Yuheng Wu,Berk Gokmen,Zhouhua Xie,Peijing Li,Caroline Trippel,Priyanka Raina,Thierry Tambe", "background": "有限状态推理是指理解和实现状态依赖行为的能力，对于硬件设计至关重要。传统的基准测试要求手动构造示例，但这种方法效率低下且耗时。本文介绍了LLM-FSM，这是一种新的基准测试工具，旨在评估大型语言模型（LLMs）从自然语言规范生成正确的寄存器传输级（RTL）实现的能力。", "innovation": "LLM-FSM 首次通过完全自动化的管道构建。自动构建有限状态机（FSM）并将其转化为结构化的 YAML 格式，进一步转为自然语言规范。随后，从相同的 YAML 构建参考 RTL 和测试套件，并通过基于 LLM 和 SAT 解算器的检查验证所有 1,000 个问题。研究表明，即使是最强大的 LLMs 也会随着 FSM 复杂性的增加而显示出精度急剧下降。此外，监督微调（SFT）可以有效推广到未见过的任务，而增加推理时的计算量可以提高准确性。", "conclusion": "LLM-FSM 仍然是可扩展的，其 FSM 复杂度可以随着未来模型能力的提升而扩展。"}
{"llm_update_time": "20260211", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2602.07238", "html_url": "https://arxiv.org/abs/2602.07238", "title": "大型语言模型开发中是否存在‘秘密调料’？", "title_en": "Is there \"Secret Sauce'' in Large Language Model Development?", "authors": "Matthias Mertens,Natalia Fischl-Lanzoni,Neil Thompson", "background": "该研究通过分析2022年至2025年间发布的809个模型的训练和基准数据，探讨了大型语言模型（LLM）的性能主要是通过增加计算量来提升，还是依赖于特定的专有技术。研究人员在回归分析中考虑了发布日期和开发者的固定效应。", "innovation": "这项研究采用了一种独特的研究方法，通过对大量数据进行回归分析，并结合固定效应来区分不同开发者的优势。研究发现，在性能前沿，大多数性能差异可以归因于更高的训练计算量，而在非前沿领域，专有技术和共享算法的进步显著降低了达到固定能力标准所需的计算量。", "conclusion": "在性能前沿，80-90% 的性能差异主要由更高的训练计算量决定，表明规模而非专有技术推动了前沿的发展。而在非前沿区域，专有技术和共享算法的进步显著减少了达到固定能力门槛所需的计算量。一些公司可以更有效地生产更小的模型，甚至在同一个公司内，不同模型的训练效率也存在显著差异。"}
{"llm_update_time": "20260211", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2602.07253", "html_url": "https://arxiv.org/abs/2602.07253", "title": "从离群值检测到幻觉检测：一种几何视角", "title_en": "From Out-of-Distribution Detection to Hallucination Detection: A Geometric View", "authors": "Litian Liu,Reza Pourreza,Yubing Jian,Yao Qin,Roland Memisevic", "background": "大型语言模型中的幻觉检测是一个关键的开放问题，具有重要的安全性和可靠性意义。尽管现有方法在问答任务中表现出色，但在需要推理的任务上依然不太有效。", "innovation": "本文重新审视幻觉检测问题，通过将语言模型的下一个 token 预测任务视为分类问题，并应用离群值检测（OOD）技术，提出了一种无需训练、基于单个样本的检测方法，能够在推理任务中实现强准确性的幻觉检测。", "conclusion": "我们的工作表明，将幻觉检测重新框架为离群值检测提供了一条充满希望且可扩展的途径以提升语言模型的安全性。"}
{"llm_update_time": "20260211", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2602.07153", "html_url": "https://arxiv.org/abs/2602.07153", "title": "ANCHOR: 基于关键节点的数据生成用于GUI代理", "title_en": "ANCHOR: Branch-Point Data Generation for GUI Agents", "authors": "Jinbiao Wei,Yilun Zhao,Kangqi Ni,Arman Cohan", "background": "端到端的GUI代理需要大量的高质量交互数据，但收集人类演示数据成本高，现有的合成管道往往受限于任务多样性有限或产生噪声的、目标漂移的轨迹。", "innovation": "提出了一种名为Anchor的轨迹扩展框架，该框架能够从少量验证过的种子演示中规模化监督。框架从每个种子开始，识别出与有意义状态变化对应的分支点，并在此基础上提出新任务变体。执行代理遵循提出的说明生成新轨迹，验证者通过状态感知检查和轨迹级别一致性来确保任务完成。为了提高监督质量，采用了任务条件下的步骤级过滤，移除非承载动作，并对分支后段进行降噪处理，以保持一致的意图。", "conclusion": "在标准桌面基准OSWorld和WindowsAgentArena上的实验表明，使用扩展数据集微调的模型相对于零样本代理和代表性合成基线实现了一致的性能提升，并且能够在多个应用程序和操作系统上泛化。"}
{"llm_update_time": "20260211", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2602.07187", "html_url": "https://arxiv.org/abs/2602.07187", "title": "PreFlect: 从回顾式反思到前瞻性反思在大型语言模型代理中的转变", "title_en": "PreFlect: From Retrospective to Prospective Reflection in Large Language Model Agents", "authors": "Hanyu Wang,Yuanpu Cao,Lu Lin,Jinghui Chen", "background": "现有的大型语言模型代理通常通过自我反思来提高性能，其中代理通过迭代分析先前的行动来纠正错误。然而，现有的反思方法本质上是回顾性的：代理先行动，然后观察到错误后才尝试恢复。", "innovation": "本文介绍了一种前瞻反思机制PreFlect，该机制将范式从事后纠正转变为执行前的预见性思考，即在执行前批评和改进代理计划。通过提取历史代理轨迹中的规划错误，捕捉过去的执行中反复出现的成功和失败模式，并结合运行时的动态重规划机制来调整计划，从而支持基于实例的前瞻性反思。", "conclusion": "在不同基准上的评估表明，PreFlect 显著提高了代理在复杂现实任务中的总体效用，优于几种强的反思基线和其他更复杂代理架构，代码将更新至 provided URL。"}
{"llm_update_time": "20260211", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2602.07035", "html_url": "https://arxiv.org/abs/2602.07035", "title": "DLLM-Searcher: 调整扩散大规模语言模型以适应搜索代理", "title_en": "DLLM-Searcher: Adapting Diffusion Large Language Model for Search Agents", "authors": "Jiahao Zhao,Shaoxuan Xu,Zhongxiang Sun,Fengqi Zhu,Jingyang Ou,Yuling Shi,Chongxuan Li,Xiao Zhang,Jun Xu", "background": "近期，扩散大语言模型（dLLMs）展示了独特的优势，主要得益于其并行解码机制和灵活的生成范式。同时，尽管搜索代理迅速发展，但其实际部署受到根本性的局限——即时挑战（Latency Challenge），即在ReAct代理范式下，多轮推理、工具调用及工具响应等待的串行执行造成了严重的端到端延迟。尽管dLLMs具备独特优势，现有的dLLM基础架构面临代理能力挑战，表现为它们在推理和工具调用方面的表现较弱，阻碍了其优势的实际应用。", "innovation": "本文提出了DLLM-Searcher，一种针对dLLM基础架构的优化框架，旨在解决代理能力挑战，设计了一个包含代理指导监督微调（Agentic SFT）和代理减少变差偏好优化（Agentic VRPO）的两阶段后训练管道，增强基础dLLM的信息搜索和推理能力。此外，通过利用dLLMs的灵活生成机制，本文提出了一个新型代理范式——并行推理与执行（P-ReAct），能够指导模型优先解码tool_call指令，在等待工具返回期间继续思考。实验结果表明，DLLM-Searcher的性能与主流基于LLM的搜索代理相当，P-ReAct 的推理加速大约为15%。", "conclusion": "实验结果表明，DLLM-Searcher达到了与主流基于LLM的搜索代理相当的性能，而P-ReAct则实现了约15%的推理加速。阐述了通过增强dLLM的能力并利用其并行机制减少延迟挑战的有效解决方案，并分享了代码。"}
{"llm_update_time": "20260211", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2602.07040", "html_url": "https://arxiv.org/abs/2602.07040", "title": "Aster: 自比现有方法快20倍的自主科学发现", "title_en": "Aster: Autonomous Scientific Discovery over 20x Faster Than Existing Methods", "authors": "Emmett Bicker", "background": "当前已有框架在自主科学发现方面存在速度较慢的局限性。现有的科学发现过程往往迭代次数较多，适用于短期评价任务，而对于那些需要长时间评估的任务（如多小时的机器学习训练）则显得力不从心。", "innovation": "Aster 是一种能够自主进行科学发现的人工智能代理，相比于现有框架效率提升了20倍。它可以在给定任务、初始程序和评估程序性能的脚本后，通过迭代不断改进程序，常常达到新的最佳性能。相较于之前的技术，Aster 能够显著减少发现新颖解决方案所需的迭代次数，从而扩大可解决问题的范围。", "conclusion": "Aster 在数学、GPU 内核工程、生物学、神经科学以及语言模型训练等多个领域都达到了SOTA（State-of-the-Art）的结果，尤其在纳米GPT速度赛中表现出色。除ZAPBench外，在所有实验任务中，Aster 均达成了领先或与最佳人类解决方案相近的结果，且计算资源消耗远低于传统方法。Aster 提供了网页界面和API，方便用户访问。"}
{"llm_update_time": "20260211", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2602.07025", "html_url": "https://arxiv.org/abs/2602.07025", "title": "视觉语言模型中的表示失败的几何结构", "title_en": "The Geometry of Representational Failures in Vision Language Models", "authors": "Daniele Savietto,Declan Campbell,André Panisson,Marco Nurisso,Giovanni Petri,Jonathan D. Cohen,Alan Perotti", "background": "视觉-语言模型（VLMs）在多对象视觉任务中表现出令人困惑的失败，如创建不存在的元素或在干扰中无法识别最相似的对象。这些错误反映了人类认知限制，如“绑定问题”。然而，这种失败在人工系统中的内在机制尚不清楚。", "innovation": "通过分析开放权重VLMs（Qwen、InternVL、Gemma）的表示几何结构，比较方法以提取“概念向量”——编码视觉概念的潜在方向，提出了机械机制见解。通过控制干预验证了这些概念向量，使其能够可靠地在简化和自然视觉任务中操纵模型行为。观察到这些向量之间的几何重叠与特定错误模式显著相关，提供了一个与内部表示如何塑造模型行为且驱动视觉失败的量化框架。", "conclusion": "研究发现，特定错误模式与概念向量之间几何重叠的强相关性，有助于理解内部表示如何影响模型行为并驱动视觉错误。该研究为视觉-语言模型的内部机制提供了新的洞见，为理解模型错误提供了定量框架。"}
{"llm_update_time": "20260211", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2602.07023", "html_url": "https://arxiv.org/abs/2602.07023", "title": "LLM代理行为一致性的验证：基于股票市场模拟的交易风格转换分析", "title_en": "Behavioral Consistency Validation for LLM Agents: An Analysis of Trading-Style Switching through Stock-Market Simulation", "authors": "Zeping Li,Guancheng Wan,Keyang Chen,Yu Chen,Yiwen Zhao,Philip Torr,Guangnan Ye,Zhenfei Yin,Hongfeng Chai", "background": "近年来，大型语言模型（LLMs）越来越多地被用作金融股票市场模拟中的代理，以检验微观行为如何聚合为宏观现象。然而，一个关键问题浮现：LLM代理的行为是否与真实市场参与者的一致？这种一致性是模拟结果有效的关键。传统模拟大多在初始化时固定策略，无法反映实际交易动态，因此本文选择一个金融股票市场情景，测试行为一致性。", "innovation": "本文创新之处在于通过股票市场模拟评估代理策略转换与金融理论的一致性，并引入了四种行为一致性指标，使用Mann-Whitney U检验比较代理在模拟过程中的风格转换行为与金融理论，表明最近的LLMs的行为与行为金融理论仅部分一致，需要在代理行为与金融理论之间进一步改进。", "conclusion": "近年来的大型语言模型在转换行为方面仅部分符合行为金融理论，这表明在使代理行为与金融理论更一致方面仍需进一步改进。"}
{"llm_update_time": "20260211", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2602.07014", "html_url": "https://arxiv.org/abs/2602.07014", "title": "Vectra：电子商务图像内机器翻译的新型指标、数据集和模型", "title_en": "Vectra: A New Metric, Dataset, and Model for Visual Quality Assessment in E-Commerce In-Image Machine Translation", "authors": "Qingyu Wu,Yuxuan Han,Haijun Li,Zhao Xu,Jianshan Zhao,Xu Jin,Longyue Wang,Weihua Luo", "background": "当前的研究主要集中在图像内机器翻译（IIMT）的机器翻译评估上，而图像的视觉呈现质量对于用户体验至关重要。现有方法在处理密集的商品图像和多模态缺陷时缺乏解释性，而基于模型的方法则缺乏领域验证的具体奖励信号。", "innovation": "提出 Vectra，这是一种参考自由的、基于多模态语言模型（MLLM）的视觉质量评估框架，用于电子商务中的 IIMT。Vectra 包含三个组成部分：（1）可解释的 Vectra 分数系统，通过空间感知的缺陷区域比（DAR）量化将视觉质量分解为 14 个维度；（2）矢量数据集，包含 1.1M 张商品图像，分为系统评估基准、指令调优的推理标注和专家标注的偏好；（3） Vectra 模型，一个包含 4B 个参数的 MLLM，既能生成定量评分，又能提供诊断性分析。", "conclusion": "实验表明，Vectra 在与人类排名的相关性上达到了最先进的水平，并且在评分性能方面优于如 GPT-5 和 Gemini-3 等顶级 MLLMs。数据集和模型将在文章被接受后发布。"}
{"llm_update_time": "20260211", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2602.07028", "html_url": "https://arxiv.org/abs/2602.07028", "title": "CNN和CNN-ANFIS架构的对抗鲁棒性比较研究", "title_en": "A Comparative Study of Adversarial Robustness in CNN and CNN-ANFIS Architectures", "authors": "Kaaustaaub Shankar,Bharadwaj Dogga,Kelly Cohen", "background": "卷积神经网络(CNNs)在图像分类方面表现出强大的性能，但缺乏可解释性且易受对抗攻击影响。神经-模糊混合体如DCNFIS通过将全连接的CNN分类器替换为自适应神经-模糊推理系统(ANFIS)以提高可解释性，但其鲁棒性尚未得到充分探索。此研究在MNIST、Fashion-MNIST、CIFAR-10和CIFAR-100数据集上，使用基于梯度的(如PGD)和非基于梯度的(如Square)攻击方法，对比了标准CNN(如ConvNet、VGG、ResNet18)及其结合ANFIS的版本之间的对抗鲁棒性。", "innovation": "首次系统性对比了在标准CNN和结合ANFIS的CNN架构上，攻击方式对模型性能的影响，特别是在对抗鲁棒性方面的表现差异，为选择合适的技术方案提供参考。", "conclusion": "ANFIS集成在不同架构下的效果不同，ResNet18-ANFIS在对抗鲁棒性方面表现出改进，而VGG-ANFIS则往往低于其基础模型。这些发现表明，神经-模糊增强可以提高特定架构的鲁棒性，但不具有普遍的适用性。"}
{"llm_update_time": "20260211", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2602.07036", "html_url": "https://arxiv.org/abs/2602.07036", "title": "MENASpeechBank: 一个基于人物条件的多轮对话参考语音库，用于AudioLLMs", "title_en": "MENASpeechBank: A Reference Voice Bank with Persona-Conditioned Multi-Turn Conversations for AudioLLMs", "authors": "Zien Sheikh Ali,Hunzalah Hassan Bhatti,Rabindra Nath Nandi,Shammur Absar Chowdhury,Firoj Alam", "background": "随着AudioLLMs的发展，其能够通过语音和音频进行指令遵循和通用任务的处理，但随着研究的深入，数据的多样性、对话的自然性和指示对齐能力的缺乏成为了限制性的瓶颈，特别是在多个人设和方言覆盖方面。这对于基于人物背景的互动尤其重要，因为收集和发布包含多种说话人的真实录音成本高且速度慢。", "innovation": "本文介绍了MENASpeechBank，一个包含约18,000个高质量片段的语音库，这些片段来自124位来自中东和北非国家的说话人，覆盖英语、现代标准阿拉伯语和多种地方阿拉伯语变体。基于这一资源，开发了一个可控的合成数据管道：(i)构建了包含世界价值观调查启发式特征的人物档案，(ii)定义了约5000个对话场景的分类，(iii)通过语义相似性将人物与场景匹配，(iv)利用LLM生成约417,000个带有用户角色扮演的对话，(v)通过条件参考说话人音频使用户部分保持说话人的身份和多样性。", "conclusion": "本文同时评估了合成和真人录音的对话，并提供了详细的分析。MENASpeechBank和生成的对话将会被公开发布，供社区使用。"}
{"llm_update_time": "20260211", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2602.07017", "html_url": "https://arxiv.org/abs/2602.07017", "title": "XAI-CLIP：基于区域引导的扰动框架，用于多模态视觉-语言模型中的可解释医学图像分割", "title_en": "XAI-CLIP: ROI-Guided Perturbation Framework for Explainable Medical Image Segmentation in Multimodal Vision-Language Models", "authors": "Thuraya Alzubaidi,Sana Ammar,Maryam Alsharqi,Islem Rekik,Muzammil Behzad", "background": "医学图像分割是临床工作流程中的关键组成部分，能够实现准确的诊断、治疗计划和疾病监测。尽管基于变压器的模型在性能上优于卷积架构，但它们的低可解释性仍然是临床信任和部署的主要障碍。现有的可解释人工智能（XAI）技术，包括梯度基显著性方法和扰动基方法，往往计算成本高、需要多次前向传播，并经常产生噪声或与解剖无关的解释。", "innovation": "我们提出了一种基于区域引导的扰动框架XAI-CLIP，该框架利用多模态视觉-语言模型嵌入来定位临床有意义的解剖区域，并引导解释过程。通过集成语言指示的区域定位，结合医学图像分割，并应用针对区域的细微扰动，提出的这种方法生成更清晰的边界意识的显著性图，同时大大减少了计算开销。实验证明，XAI-CLIP在FLARE22和CHAOS数据集上实现了高达60%的运行时间减少、44.6%的Dice分数提升和96.7%的交集比分数提升，相较于传统扰动方法在基于遮蔽的解释中。定性结果显示，XAI-CLIP生成了更清洁且更解剖一致的归因图，减少了伪影，表明将多模态视觉-语言表示融入基于扰动的XAI框架中显著提高了可解释性和效率，从而实现了透明和临床可部署的医学图像分割系统。", "conclusion": "实验和定性结果进一步证明了XAI-CLIP通过将多模态视觉-语言表示融引入基于扰动的XAI框架中，显著提高了医学图像分割系统的可解释性和效率，从而使得这些系统在临床环境中更加透明和可靠。"}
{"llm_update_time": "20260211", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2602.07026", "html_url": "https://arxiv.org/abs/2602.07026", "title": "模态间隙驱动的子空间对齐训练范式用于多模态大型语言模型", "title_en": "Modality Gap-Driven Subspace Alignment Training Paradigm For Multimodal Large Language Models", "authors": "Xiaomin Yu,Yi Xin,Wenjie Zhang,Chonghan Liu,Hanzhen Zhao,Xiaoxing Hu,Xinlei Yu,Ziyue Qiao,Hao Tang,Xue Yang,Xiaobin Hu,Chengwei Qin,Hui Xiong,Yu Qiao,Shuicheng Yan", "background": "尽管多模态对比学习在视觉和语言表示对齐方面取得了成功，但在不同的模态表达相同语义时仍存在显著的几何歧异，即模态间隙问题。现有的方法多基于简化为各向同性的假设，难以在大规模场景中应用。", "innovation": "本文提出了固定基准框架下的模态间隙理论，并据此开发了无训练的模态对齐策略ReAlign和基于ReAlign的可扩展训练范式ReVision。ReAlign利用在线未配对数据的统计信息进行文本表示的图像表示分布对齐，而ReVision将ReAlign整合到预训练阶段，使模型在视觉指令调优之前能从未配对的文本中学习视觉表示分布，从而避免了大规模高质量图像-文本配对的需要。", "conclusion": "研究表明，统计上对齐的未配对数据可以有效地替代昂贵的图像-文本配对，为多模态大型语言模型的高效扩展提供了稳健的路径。"}
{"llm_update_time": "20260211", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2602.07021", "html_url": "https://arxiv.org/abs/2602.07021", "title": "AI for Sustainable Data Protection and Fair Algorithmic Management in Environmental Regulation", "title_en": "AI for Sustainable Data Protection and Fair Algorithmic Management in Environmental Regulation", "authors": "Sahibpreet Singh,Saksham Sharma", "background": "AI的整合使环境法规管理中数据管理取得了显著进步，特别是在数据保护和算法公平方面。传统加密方法在处理动态环境数据时面临局限性，亟需探索先进的加密技术。研究着眼于评估AI如何通过这些技术增强数据保护，同时促进算法的公平管理。", "innovation": "本研究通过全面审查AI增强的同态加密（HE）和多方计算（MPC）的最新进展，并分析这些技术如何应用于环境数据监管，提出了AI驱动的动态密钥管理、自适应加密方案、优化的计算效率以及AI增强协议优化和故障缓解技术在MPC中的应用，显著提高了环境数据处理的安全性。", "conclusion": "研究指出了在AI、网络法规与环境法规交汇处需要填补的重要研究缺口，特别是在解决算法偏差、透明度和问责问题方面。研究表明需要更严格的网络法规和发展全面的法规来保障环境数据的安全。未来的研究应着重于在安全性和隐私性之间找到平衡，确保监管框架能够适应技术进步。"}
{"llm_update_time": "20260211", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2602.07031", "html_url": "https://arxiv.org/abs/2602.07031", "title": "Lagged backward-compatible physics-informed neural networks for unsaturated soil consolidation analysis", "title_en": "Lagged backward-compatible physics-informed neural networks for unsaturated soil consolidation analysis", "authors": "Dong Li(1),Shuai Huang(2),Yapeng Cao(3),Yujun Cui(4),Xiaobin Wei(5),Hongtao Cao(6) ((1) Department of Civil, Environmental, and Infrastructure Engineering, George Mason University, Fairfax, VA, USA (2) National Institute of Natural Hazards, Ministry of Emergency Management, Beijing, China (3) State Key Laboratory of Cryospheric Science and Frozen Soil Engineering, Northwest Institute of Eco-Environment and Resources, Chinese Academy of Sciences, Lanzhou, China, Navier Laboratory, École Nationale des Ponts et Chaussées, Marne-la-Vallée Cedex 2, France (4) Navier Laboratory, École Nationale des Ponts et Chaussées, Marne-la-Vallée Cedex 2, France (5) School of Civil Engineering, Hebei University of Engineering, Handan, China (6) College of Civil Engineering, Zhejiang University of Technology, Hangzhou, China)", "background": "本研究旨在利用拉格滞后后向兼容物理信息神经网络（LBC-PINN）模拟和反演多尺度时间域下的长期加载下的一维不饱和土壤固结。该研究针对气压和水压在多尺度时间范围内的耦合消散难题，采用对数时间分割、滞后兼容损失强制以及段间迁移学习的方法进行建模。", "innovation": "该研究开发了一种LBC-PINN，通过引入对数时间分割、滞后兼容损失强制以及段间迁移学习来解决多尺度时间域下的耦合气水压力消散问题。在前向分析中，使用推荐的时间分割方案，LBC-PINN能够准确预测孔隙气压和孔隙水压的变化。简化的时间分割策略提高了计算效率，同时保持了预测准确性。敏感性分析表明，该框架在气相渗透率与水相渗透率比值从1e-3到1e3的变化中都具有鲁棒性。", "conclusion": "研究结果表明，LBC-PINN在长达1e10秒的模拟中表现良好，均方绝对误差低于1e-2，验证了其在不饱和土壤固结分析中的有效性和可靠性，尤其在计算效率和预测准确性之间的平衡上取得了较好的效果。"}
{"llm_update_time": "20260211", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2602.07037", "html_url": "https://arxiv.org/abs/2602.07037", "title": "基于随机尖峰神经元的SNN可以从根本上是贝叶斯的", "title_en": "Stochastic Spiking Neuron Based SNN Can be Inherently Bayesian", "authors": "Huannan Zheng,Jingli Liu,Kezhou Yang", "background": "生物神经系统的不确定性似乎在计算上是有益的而非有害的。但在神经形态计算系统中，设备的差异性往往限制了系统性能，包括准确性和效率。现有的尖神经网络（SNN）受设备差异的影响表现不佳。", "innovation": "本文提出了一个同步贝叶斯神经网络（SBNN）框架，该框架结合了基于磁隧道结的内在设备随机性动态模型和随机阈值神经元模型。通过将噪声作为功能性的贝叶斯资源加以利用，实现了具有8位精度，达到99.16%的MNIST准确率和94.84%的CIFAR10准确率。实验表明，使用率估计方法可提供约20倍的训练加速。SBNN展现出良好的鲁棒性，对比标准SNN在权重噪声和输入噪声下准确率分别提高了67%和12%。至今硬件验证证实，物理设备实现并未造成算法模型所预测的不可见的准确性和校准损失，转化为神经元不确定性为在不确定环境下实现紧凑和节能的神经形态计算提供了一条途径。", "conclusion": "SBNN框架有效地利用了设备随机性，提高了网络的准确性和鲁棒性，并通过硬件验证支持了转化设备随机性为神经元不确定性的可行性方案，在不确定环境中实现了高效、节能的神经形态计算系统。"}
{"llm_update_time": "20260211", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2602.07447", "html_url": "https://arxiv.org/abs/2602.07447", "title": "使用计算工具衡量罗曼语族语言之间的相互可懂性", "title_en": "Measuring cross-language intelligibility between Romance languages with computational tools", "authors": "Liviu P Dinu,Ana Sabina Uban,Bogdan Iordache,Anca Dinu,Simona Georgescu", "background": "本文分析了近似语言间的相互可懂性，并针对罗曼语族的语言进行应用。研究人员使用表层和语义相似性衡量相关词汇之间的相似性来引入一种新颖的计算度量标准，用于估计可懂度，并测量罗曼语族五种主要语言（法语、意大利语、葡萄牙语、西班牙语和罗马尼亚语）之间的相互可懂性。他们使用词的音标和音素形式以及不同类型平行语料库和词义表示的向量模型进行比较。所得的可懂性分数证实了跨语言可懂性不对称的相关直觉，并与人类实验中的填空测试结果有显著的相关性。", "innovation": "本文的创新在于提出了一种基于词汇表层相似性和语义相似性的新颖计算可懂度度量标准，并使用不同形式的词语和多种语料库以及向量模型来测量罗曼语族五种主要语言之间的相互可懂性。这种方法有助于更准确地理解语言间的相似性和差异性。", "conclusion": "研究结果表明，所得到的可懂性分数不仅证实了语言间可懂性不对称的直觉，而且与人类实验中的填空测试结果高度相关，这表明计算可懂度度量工具可以有效地评估语言间的相互可懂性，并有助于更好地理解不同语言之间的差异。"}
{"llm_update_time": "20260211", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2602.07546", "html_url": "https://arxiv.org/abs/2602.07546", "title": "通过长度正则化在扩散语言模型中改进变长生成", "title_en": "Improving Variable-Length Generation in Diffusion Language Models via Length Regularization", "authors": "Zicong Cheng,Ruixuan Jia,Jia Li,Guo-Wei Yang,Meng-Hao Guo,Shi-Min Hu", "background": "差分大型语言模型（DLLMs）天生不适合进行变长生成，因为它们的推理是在固定长度的画布上进行的，并且隐含地假设了一个已知的目标长度。当目标长度未知时，比如在实际的完成和填充任务中，直接比较不同掩码长度的置信度会导致系统的偏差，从而导致生成不足或重复的内容。这项工作表明，这种失败源于生成置信度估计中的固有长度偏差，使得现有的DLLMs没有可靠的方法来确定生成长度，从而使得变长推理不可靠。", "innovation": "本文提出了一种名为LR-DLLM的长度正则化推理框架，它将生成长度明确作为一个变量，并在推理时实现可靠的长度确定。通过显式的长度正则化，它将语义兼容性与由长度引起的不确定性分离，纠正了偏差的置信度估计。基于此，LR-DLLM允许生成范围的动态扩展或收缩，无需修改底层DLLM或其训练流程。", "conclusion": "实验表明，LR-DLLM在HumanEvalInfilling任务中实现了51.3%的Pass@1（相对于DreamOn有13.4%的提升），并且在四语言的McEval中，平均Pass@1为51.5%（相对于DreamOn有14.3%的提升）。\n"}
{"llm_update_time": "20260211", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2602.07594", "html_url": "https://arxiv.org/abs/2602.07594", "title": "学会自我验证使语言模型成为更好的推理者", "title_en": "Learning to Self-Verify Makes Language Models Better Reasoners", "authors": "Yuxin Chen,Yu Wang,Yi Zhang,Ziang Ye,Zhengzhou Cai,Yaorui Shi,Qi Gu,Hui Su,Xunliang Cai,Xiang Wang,An Zhang,Tat-Seng Chua", "background": "最近的大语言模型在生成复杂任务的前景推理路径方面表现优异，但它们自我验证答案的能力仍然较弱，显示出生成能力和自我验证能力之间的持久能力不对称。", "innovation": "研究发现，即使在同一个任务上，提高生成能力并不能带来相应地提高自我验证能力。进一步研究提出了一种多任务强化学习框架，将自我验证整合到生成训练中，作为两个独立但互补的目标同时优化。实验结果显示，这种结合训练方法在生成和验证能力上都优于仅生成训练。", "conclusion": "通过将自我验证纳入生成训练中，可以大幅提升语言模型的推理能力，其准确性和推理痕迹更为高效和有效。"}
{"llm_update_time": "20260211", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2602.07497", "html_url": "https://arxiv.org/abs/2602.07497", "title": "从本地 meme 到全球协调：视觉-语言模型在有害 meme 检测中的跨文化评估", "title_en": "From Native Memes to Global Moderation: Cros-Cultural Evaluation of Vision-Language Models for Hateful Meme Detection", "authors": "Mo Wang,Kaixuan Ren,Pratik Jalan,Ahmed Ashraf,Tuong Vy Vu,Rahul Seetharaman,Shah Nawaz,Usman Naseem", "background": "文化背景深刻影响着人们对在线内容的解读，然而现有的视觉-语言模型（VLMs）主要通过西方或以英语为中心的视角进行训练，这限制了它们在有害 meme 检测等任务中的公平性和跨文化鲁棒性。", "innovation": "本文提出了一套系统评估框架，旨在诊断并量化最先进的 VLMs 在跨文化 meme 数据集中的鲁棒性，分析了三个维度：（i）学习策略（零样本 vs. 一样本），（ii）提示语言（本地 vs. 英语），和（iii）翻译对意义和检测的影响。研究结果表明，常见的“先翻译再检测”方法会损害性能，而文化对齐的干预措施——使用本地语言提示和一样本学习——能够显著提高检测效果。", "conclusion": "研究揭示了系统性向西方安全规范靠拢的趋势，并提出了缓解此类偏见的实际策略，指导全球鲁棒多模态调节系统的开发。"}
{"llm_update_time": "20260211", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2602.07381", "html_url": "https://arxiv.org/abs/2602.07381", "title": "当模型说‘不予置评’时，我们知道有帮助性已死亡，诚实性已重生，安全性已恐惧", "title_en": "When the Model Said 'No Comment', We Knew Helpfulness Was Dead, Honesty Was Alive, and Safety Was Terrified", "authors": "Gautam Siddharth Kashyap,Mark Dras,Usman Naseem", "background": "大型语言模型（LLMs）的安全部署需要符合人类的价值观，包括有益、无害、诚实（HHH）。现有方法使用监督微调（SFT）和专家混合（MoE）来对齐LLMs，但这些方法在处理多目标设置时存在挑战，如SFT导致目标冲突引起干扰，MoE则面对专家路由错配的问题。", "innovation": "提出了一种双阶段框架AlignX。第一阶段使用注入提示的微调来分离轴向特定的任务特征，缓解灾难性遗忘。第二阶段采用MoCaE模块，利用分形和自然几何来校准专家路由，提高推理可靠性。相比之前的MoE，AlignX在Alpaca（有帮助性）、BeaverTails（无害性）和TruthfulQA（诚实性）方面取得了显著提升，并减少了超过35%的延迟和内存使用。", "conclusion": "AlignX在四个LLM上的跨验证结果表明其通用性，显著提升了模型的帮助性、无害性和诚实性，同时降低了延迟和内存使用。"}
{"llm_update_time": "20260211", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2602.07451", "html_url": "https://arxiv.org/abs/2602.07451", "title": "DLLM Agent: 见得更远，跑得更快", "title_en": "DLLM Agent: See Farther, Run Faster", "authors": "Huiling Zhen,Weizhe Lin,Renxi Liu,Kai Han,Yiming Li,Yuchuan Tian,Hanting Chen,Xiaoguang Li,Xiaosong Li,Chen Chen,Xianzhi Yu,Mingxuan Yuan,Youliang Yan,Peifeng Qin,Jun Wang,Yu Wang,Dacheng Tao,Yunhe Wang", "background": "扩散型大规模语言模型(DLLMs)在替代自回归(AR)解码方面展示出有吸引力的效率和建模特性，但它们在自主多步决策制定中的影响仍未被充分研究。本研究旨在探索当生成范式发生变化，但代理框架和监督保持不变时，扩散模型是否会导致系统性不同的规划和工具使用行为，并且这些差异是否转化为端到端效率提升。", "innovation": "研究通过使用相同代理流程(DeepDiver)实例化DLLM和AR骨干模型，并在相同的路径数据上进行配对的代理导向微调，以研究扩散模型对代理行为的影响。研究发现，相较于AR代理，在具有相似准确性的前提下，DLLM代理在全程平均快30%以上，某些情况下甚至快8倍。此外，条件是任务正确完成的情况下，DLLM代理需要更少的交互轮次和工具调用，这与更早收敛于正确操作路径并且减少回溯的高规划命中率相一致。此外，研究还提出了部署扩散模型代理的两个实用考虑：第一，朴素的DLLM策略更容易出现结构化的工具调用失败，需要更强的工具调用特定训练来发出有效的模式和参数；第二，为了处理包含上下文和操作跨度的多轮输入，扩散方法的跨度篡改需要对齐的注意力遮蔽以避免虚假的上下文-操作信息流。如果没有这样的对齐，性能会下降。最后，研究分析了工作流程阶段的注意力动态，发现范式特定的协调模式，表明扩散支持代理有更强的整体规划信号。", "conclusion": "研究结果表明，在具有相似准确性的条件下，扩散支持的DLLM代理在全程中平均快30%以上，某些情况下甚至快8倍。条件是任务正确完成的情况下，它需要更少的交互轮次和工具调用，暗示更高的规划命中率并且较早地收敛于正确的行动路径，减少回溯。此外，研究还提出了部署扩散型代理的两个实用考虑：第一，朴素的DLLM策略更容易出现结构化的工具调用失败，需要更强的工具调用特定训练来发出有效的模式和参数；第二，为了处理包含上下文和操作跨度的多轮输入，扩散方法的跨度篡改需要对齐的注意力遮蔽以避免虚假的上下文-操作信息流。这表明了扩散支持的代理在效率提升和更好规划上的潜力。"}
{"llm_update_time": "20260211", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2602.07499", "html_url": "https://arxiv.org/abs/2602.07499", "title": "一步步简化：引导对话语言模型进行多语言无监督可控句子简化", "title_en": "Let's Simplify Step by Step: Guiding LLM Towards Multilingual Unsupervised Proficiency-Controlled Sentence Simplification", "authors": "Jingshen Zhang,Xin Ying Qiu,Lifang Lu,Zhuhua Huang,Yutao Hu,Yuechang Wu,JunYu Lu", "background": "大语言模型在专业控制下的句子简化能力有限，尤其是在跨越大可读性层次简化时更为明显。现有的简化方法在这些方面表现不足。", "innovation": "提出了一种框架，通过动态路径规划、语义感知的范例选择以及结合对话历史的逐步推理生成，将复杂的简化过程分解为可管理的步骤。", "conclusion": "此方法在两个基准数据集上对五种语言的评估中显示出简化的有效性提高，同时计算步骤减少22-42%。人类评估确认简化效果与意义保存之间存在基本权衡。即使人类注释者在意义保存上的判断也存在分歧，突显了该任务的复杂性。研究结果表明，逐步简化虽然提高了控制能力，但在广泛简化过程中保留语义真实性仍然是一个开放的挑战。"}
{"llm_update_time": "20260211", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2602.07382", "html_url": "https://arxiv.org/abs/2602.07382", "title": "领域知识注入在法律文件摘要中的优势：印度法院判决从英语到印地语的案例研究", "title_en": "Advantages of Domain Knowledge Injection for Legal Document Summarization: A Case Study on Summarizing Indian Court Judgments in English and Hindi", "authors": "Debtanu Datta,Rajdeep Mukherjee,Adrijit Goswami,Saptarshi Ghosh", "background": "印度法律法庭判决的总结是一个复杂的过程，不仅因为法律文本语言复杂且结构不规范，还因为大量印度人口无法理解法律文本中的复杂英语，因此需要生成印度语摘要。此项研究旨在通过注入领域知识来提升印度法律文本的总结质量，生成英文和印地语摘要。", "innovation": "研究提出了一种框架，通过引入针对法律文本训练的领域特定预训练编码器来增强提取式神经摘要模型。此外，研究还探索了将法律领域的知识注入生成模型（包括大型语言模型）中，通过在大量英文和印地语法律语料库上进行持续预训练的方式进行实现。", "conclusion": "研究提出的策略在英语到英语和英语到印地语的印度法律文件总结中取得了统计上显著的提升，这不仅通过标准评估指标衡量，还通过法律领域专家验证，证明了该方法的有效性。"}
{"llm_update_time": "20260211", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2602.07464", "html_url": "https://arxiv.org/abs/2602.07464", "title": "SED-SFT: Selectively Encouraging Diversity in Supervised Fine-Tuning", "title_en": "SED-SFT: Selectively Encouraging Diversity in Supervised Fine-Tuning", "authors": "Yijie Chen,Yijin Liu,Fandong Meng", "background": "监督微调（SFT）后跟强化学习（RL）已成为大型语言模型（LLMs）的标准后训练范式。传统的SFT过程，由交叉熵（CE）损失驱动，往往引起模式崩溃，即模型过集中在特定的响应模式上。这导致后续RL阶段的探索效率受到严重限制。虽然最近的一些研究试图通过替换CE损失来改善SFT，以保持多样性和优化更新策略，但这些方法无法在多样性和准确度之间找到合适的平衡，从而导致RL性能不佳。", "innovation": "本文提出了SED-SFT，这是一种自适应地基于标记探索空间鼓励多样性的框架。该框架在优化目标中引入了一个具有选择性屏蔽机制的选择性熵正则化项。实验结果表明，与CE损失相比，SED-SFT在八个数学基准测试中显著提高了生成多样性，且额外的计算开销可以忽略不计，从而在标准CE基础上分别提高了Llama-3.2-3B-Instruct和Qwen2.5-Math-7B-Instruct的RL性能，增幅分别为2.06和1.20个点。", "conclusion": "SED-SFT相比传统CE损失框架，能够在保持生成多样性的前提下提高后续RL性能，适用于大型语言模型的后训练过程，并且计算效率高，对于促进模型的多样性探索具有重要价值。"}
{"llm_update_time": "20260211", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2602.07376", "html_url": "https://arxiv.org/abs/2602.07376", "title": "大型语言模型在安全方面是否反映出了人口统计学的多样性？", "title_en": "Do Large Language Models Reflect Demographic Pluralism in Safety?", "authors": "Usman Naseem,Gautam Siddharth Kashyap,Sushant Kumar Ray,Rafiq Ali,Ebad Shabbir,Abdullah Mohammad", "background": "大型语言模型（LLM）的安全性本质上是多元的，反映了道德规范、文化期望和人口背景的差异。但是，现有的对齐数据集，如ANTHROPIC-HH和DICES，依赖于人口特征狭窄的标注者池，忽视了不同社区在安全性感知方面的差异。", "innovation": "Demo-SafetyBench通过直接在提示级别建模人口统计学的多样性，解耦价值框架和响应，从而解决了这一问题。第一阶段中，使用Mistral 7B-Instruct-v0.3重新分类DICES的提示，以BEAVERTAILS为参考，保留人口统计学元数据，利用Llama-3.1-8B-Instruct和SimHash进行去重，扩充了低资源类别，产生了43,050个样本。第二阶段，使用LLMs-as-Raters-Gemma-7B、GPT-4o和LLaMA-2-7B进行零样本推理，评估多元敏感性。平衡的阈值实现了高度的可靠性（ICC = 0.87）和低的人口统计学敏感性（DS = 0.12），证明了多元安全性评估可以既可扩展又具有人口统计学鲁棒性。", "conclusion": "综上所述，多元安全性评价既可以扩展又能保持人口统计学的稳健性，为评估大型语言模型的安全性提供了方法上的创新。"}
{"llm_update_time": "20260211", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.08809", "html_url": "https://arxiv.org/abs/2506.08809", "title": "训练-free 高分辨率扇束图像补全的推理", "title_en": "Training-Free Inference for High-Resolution Sinogram Completion", "authors": "Jiaze E,Srutarshi Banerjee,Tekin Bicer,Guannan Wang,Yanfu Zhang,Bin Ren", "background": "高分辨率扇束图像补全是计算机断层扫描重建的关键，缺失的投影会导致严重的伪影。扩散模型在这种任务中提供了强大的生成先验，但其推理成本会随着分辨率的提高而急剧增加。", "innovation": "提出了一种无需训练且高效的扩散模型推理方法HRSino，用于高分辨率扇束图像补全。HRSino通过明确考虑信号特征的空间异质性（如频谱稀疏性和局部复杂性），按照各空间区域和分辨率的特性分配推理努力，而不是采用统一的高分辨率扩散步骤。这使得在粗尺度上能够捕捉到全局一致性，而在必要时只细化局部细节。", "conclusion": "HRSino相比最先进的框架，在峰值内存使用和推理时间上分别减少了30.81%和17.58%，并且在不同数据集和分辨率上保持了补全准确性。"}
{"llm_update_time": "20260211", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.11472", "html_url": "https://arxiv.org/abs/2506.11472", "title": "针对视觉感知攻击固有鲁棒的VLMs", "title_en": "Toward Inherently Robust VLMs Against Visual Perception Attacks", "authors": "Pedram MohajerAnsari(1),Amir Salarpour(1),Michael Kühr(2),Siyu Huang(1),Mohammad Hamad(2),Sebastian Steinhorst(2),Habeeb Olufowobi(3),Bing Li(1),Mert D. Pesé(1) ((1) Clemson University, Clemson, SC, USA, (2) Technical University of Munich, Munich, Germany, (3) University of Texas at Arlington, Arlington, TX, USA)", "background": "自动驾驶车辆依赖深度神经网络（DNNs）进行交通标志识别、车道定位和车辆检测，但这些模型容易受到攻击，导致误分类，威胁交通安全。现有的防御措施（如对抗训练）通常无法泛化，并且会降低干净图像的准确率。", "innovation": "作者引入了Vehicle Vision-Language Models（V2LMs），这是一种专为自动驾驶车辆感知任务优化的微调视觉语言模型。V2LMs在面对未知攻击时表现出更高的鲁棒性，无需对抗训练即可保持更高的对抗准确率，相比传统DNNs在攻击下的准确性下降幅度小得多。同时，Tandem部署（单一模型处理所有任务）与Solo部署相比，在保持相当的鲁棒性的同时，还能够节省内存。此外，作者还探索了将V2LMs与现有的感知堆栈并行集成，以增强系统的抗攻击能力。", "conclusion": "实验结果表明，V2LMs是实现安全和鲁棒的自动驾驶感知的一个有前景的方向。"}
{"llm_update_time": "20260211", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.14811", "html_url": "https://arxiv.org/abs/2507.14811", "title": "SegQuant: 一种感知语义和通用的扩散模型量化框架", "title_en": "SegQuant: A Semantics-Aware and Generalizable Quantization Framework for Diffusion Models", "authors": "Jiaji Zhang,Ruichao Sun,Hailiang Zhao,Jiaju Wu,Peng Chen,Hao Li,Yuying Liu,Kingsum Chow,Gang Xiong,Shuiguang Deng", "background": "扩散模型展示了出色的生成能力，但计算强度大，这在资源受限或对延迟敏感的环境中构成了重大挑战。量化提供了有效减少模型大小和计算成本的方法，特别是在不重新训练或需要训练数据的情况下。然而，现有扩散模型的后训练量化方法往往依赖于特定架构的启发式方法，这限制了它们的通用性和与工业部署管道的集成。", "innovation": "本文提出了SegQuant，这是一种统一的量化框架，它通过结合互补技术来增强跨模型的通用性。SegQuant包括一种基于图、具有段意识的量化策略(SegLinear)，这种策略捕捉结构语义和空间异质性，以及一种双尺度量化方案(DualScale)，它保留了不对称激活，这对于保持生成输出的视觉保真度至关重要。SegQuant不仅适用于基于Transformer的扩散模型，还能实现强大的性能，确保与主流部署工具无缝兼容。", "conclusion": "SegQuant 是一个广泛的适用带段意识和结构感知的泛化量化框架，它通过结合互补技术增强了跨模型的通用性，确保了强大的性能并且与主流部署工具的无缝集成。"}
{"llm_update_time": "20260211", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.10371", "html_url": "https://arxiv.org/abs/2506.10371", "title": "基于图像滤波和增强的Transformer revisit", "title_en": "Revisiting Transformers with Insights from Image Filtering and Boosting", "authors": "Laziz U. Abdullaev,Maksim Tkachenko,Tan M. Nguyen", "background": "自注意力机制是基于Transformer的尖端深度学习架构的核心部分，但它是很大程度上基于直觉驱动的，并且本质上很难解释。因此，建立一个能解释其显著成功及其局限性的稳健理论基础，成为了当前研究中的一个重要焦点。一些研究方向通过图像去噪和非参数回归的角度来理解自注意力机制，尽管这些方法很有前景，但现有的框架仍然缺乏对各种增强自注意力的架构组件的更深入的机制性解释。本文旨在通过开发一个统一的图像处理框架来增进这一理解，该框架不仅能解释自注意力计算本身，还能解释位置编码和残差连接等各种组件的作用，包括后来的各种变体。", "innovation": "本文提出了一种新的统一图像处理框架，该框架不仅解释了自注意力计算本身，还详细阐明了位置编码和残差连接等各种架构组件的作用，包括后来的各种变体。在此基础上，识别出了两种概念之间的潜在差异，并致力于解决这一问题。通过引入两种独立的Transformer架构修改，提出的框架不仅提高了可解释性，还观察到基于图像处理的方法在语言和视觉任务上的准确性和鲁棒性都有显著提高，特别是对于长序列的理解。", "conclusion": "通过引入基于图像处理的框架和修改，本文不仅增强了对自注意力机制及其组件的理解，还在实际任务中展示了基于图像处理的方法的优越性能，为Transformer架构的设计和改进提供了新的思路和方法。"}
{"llm_update_time": "20260211", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.13564", "html_url": "https://arxiv.org/abs/2506.13564", "title": "基于门控注意力和可学习采样的状态空间分层压缩在大型多模态模型中一小时视频理解", "title_en": "State-Space Hierarchical Compression with Gated Attention and Learnable Sampling for Hour-Long Video Understanding in Large Multimodal Models", "authors": "Geewook Kim,Minjoon Seo", "background": "在处理长时间视频时，如何有效压缩视频帧特征以减轻大型多模态模型中的标记爆炸问题成为关键挑战。", "innovation": "提出了一种基于双向状态空间模型的高效框架，该模型配备有门控跳过连接和可学习加权平均池化机制，应用于周期插入的习得查询。此结构实现了在空间和时间维度上的分层下采样，同时有效地压缩视频多帧信息并保持性能。", "conclusion": "该方法在多种基准测试中展示出与最先进的模型竞争的结果，同时显著减少了总的标记预算。实验表明，状态空间模型的有效性优于传统模块，且该框架资源高效，适用于实际部署。"}
{"llm_update_time": "20260211", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.13428", "html_url": "https://arxiv.org/abs/2507.13428", "title": "PhyWorldBench", "title_en": "\"PhyWorldBench\": A Comprehensive Evaluation of Physical Realism in Text-to-Video Models", "authors": "Jing Gu,Xian Liu,Yu Zeng,Ashwin Nagarajan,Fangrui Zhu,Daniel Hong,Yue Fan,Qianqi Yan,Kaiwen Zhou,Ming-Yu Liu,Xin Eric Wang", "background": "视频生成模型已经在生成高质量、逼真的内容方面取得了显著进展，但它们准确模拟物理现象的能力仍然是一个重要的未解决的挑战。为了评估视频生成模型基于其遵循物理定律的程度，本文提出了PhyWorldBench基准，涵盖从基本原理到复杂场景的物理现象。", "innovation": "PhyWorldBench基准不仅涵盖了从基本物理原则到复杂场景的物理现象，还引入了一个新的反物理类别，通过故意违反现实世界的物理定律来评估模型是否能保持逻辑一致性。此外，通过大规模的人类评估和利用当前的多模态大型语言模型以零样本方式评估物理现实性，表明了该基准的创新性。", "conclusion": "通过系统测试1050个精心策划的提示，涵盖了基础、复合和反物理场景，本文识别了模型在遵守现实世界物理定律方面面临的关键挑战，并进一步分析了它们在不同类型物理现象和提示下的表现，提出了针对增强物理原理一致性的建议。"}
{"llm_update_time": "20260211", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.16796", "html_url": "https://arxiv.org/abs/2506.16796", "title": "RealSR-R1: 使用视觉语言链式思考的强化学习在真实世界图像超分辨率", "title_en": "RealSR-R1: Reinforcement Learning for Real-World Image Super-Resolution with Vision-Language Chain-of-Thought", "authors": "Junbo Qiao,Miaomiao Cai,Wei Li,Xudong Huang,Jie Hu,Xinghao Chen,Shaohui Lin,Hongkai Xiong", "background": "图像超分辨率（image super-resolution）是图像恢复中最具挑战性的任务之一。现有的方法在准确理解退化图像内容方面存在困难，导致重建图像的保真度低且不自然。", "innovation": "本文提出了RealSR-R1模型，增强RealSR模型的理解和推理能力。通过借鉴大型语言模型中的链式思考（CoT）成功经验，作者提出了一个融合视觉和语言推理的框架（VLCoT），旨在通过逐步生成更完整的文本和更高分辨率的图像来精准恢复图像细节。为解决传统监督学习方法在实际场景中无法泛化的挑战，作者首次引入了群组相对策略优化（GRPO），设计了四种奖励函数以优化模型的表现。", "conclusion": "大量实验表明，本文提出的RealSR-R1可以生成逼真的细节并准确理解图像内容，尤其在语义丰富或严重退化的场景中表现出色。"}
{"llm_update_time": "20260211", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.01835", "html_url": "https://arxiv.org/abs/2507.01835", "title": "调节与重建：从智能手机多视角图像学习超光谱成像", "title_en": "Modulate and Reconstruct: Learning Hyperspectral Imaging from Misaligned Smartphone Views", "authors": "Daniil Reutsky,Daniil Vladimirov,Yasin Mamedov,Georgy Perevozchikov,Nancy Mehta,Egor Ershov,Radu Timofte", "background": "超光谱重构（HSR）从RGB图像中是一个由于光谱信息严重丢失而固有的不良问题。现有方法通常依赖单一的RGB图像，这限制了重构的准确度。", "innovation": "本文提出了一种新的多图像至超光谱重构（MI-HSR）框架，利用三镜头智能手机系统，其中配备有精心选择的滤波器。这项配置在理论和实证分析的基础上，能够比传统的单镜头设置提供更丰富的光谱观测。为此，我们创建了Doomer数据集，包含三个智能手机摄像头及参考超光谱相机对不同场景捕捉的对齐图像，支持这一新范式。我们展示了所提出的HSR模型在新基准上优于现有的方法，证明了本文的设置相比普通RGB相机，可以达到30%更加准确的光谱估计。", "conclusion": "我们的研究结果表明，通过经济型硬件实现多视角光谱过滤可以解锁更准确和实用的超光谱成像解决方案。"}
{"llm_update_time": "20260211", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23278", "html_url": "https://arxiv.org/abs/2507.23278", "title": "UniLiP：将CLIP适应为统一的多模态理解和生成编辑", "title_en": "UniLiP: Adapting CLIP for Unified Multimodal Understanding, Generation and Editing", "authors": "Hao Tang,Chenwei Xie,Xiaoyi Bao,Tingyu Weng,Pandeng Li,Yun Zheng,Liwei Wang", "background": "尽管CLIP在理解方面表现出色，但它缺乏重建能力，这使得它无法成为统一的视觉编码器。之前基于CLIP的统一方法无法均衡理解和重建，导致语义退化或不一致的重建。", "innovation": "提出了一个新颖的两阶段训练方案，并引入了自我蒸馏策略，该方案逐渐赋予CLIP高保真重建能力，同时保留其原始的理解性能。进一步开发了基于MetaQuery框架的双条件架构，利用多模态隐藏状态和可学习查询嵌入来利用多模态大型语言模型的强大推理解释能力。", "conclusion": "UniLIP使用仅1B和3B的参数即可超越更大规模的统一模型（如7B的BAGEL和12B的Uniworld-V1），在GenEval、WISE和ImgEdit上的表现达到了最先进的0.90、0.63和3.94。这些结果表明，UniLIP成功扩展了CLIP的应用范围，不仅作为理解任务的最优选择，还在生成和编辑任务中也取得了高度竞争力的表现。"}
{"llm_update_time": "20260211", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.03006", "html_url": "https://arxiv.org/abs/2507.03006", "title": "拓扑特征签名 vs. 梯度直方图：医疗图像分类中的对比研究", "title_en": "Topological Signatures vs. Gradient Histograms: A Comparative Study for Medical Image Classification", "authors": "Faisal Ahmed", "background": "本文对两种完全不同特征提取范式——直方图导向梯度（HOG）和拓扑数据分析（TDA），在视网膜前极图像分类中的性能进行了对比评估。HOG模型通过建模空间区域内的梯度方向分布来捕捉局部结构信息，从而编码纹理和边缘模式；而TDA则利用立方持久同调技术提取全局拓扑描述符，以表征形状、连通性和基于强度的结构特征。", "innovation": "这项工作首次将HOG和TDA这两种完全不同的特征提取方法应用于视网膜前极图像分类，特别在糖尿病视网膜病变的二分类和五级严重程度分级中进行评估，并且使用常见的机器学习模型和10折交叉验证方法进行了验证。", "conclusion": "实验结果表明，XGBoost 在两种特征类型下都取得了最好的表现。对于二分类任务，HOG 和 TDA 分别达到 94.29% 和 94.18% 的准确率，而对于多分类任务，二者分别获得了 74.41% 和 74.69% 的准确率。这些结果证明了梯度和拓扑特征在视网膜图像结构表示中的互补性，并强调了结合这两种方法来进行可解释和鲁棒医疗图像分类的潜力。"}
{"llm_update_time": "20260211", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.15782", "html_url": "https://arxiv.org/abs/2505.15782", "title": "在单试运行框架下使用在线规划解决一般用途马尔可夫决策过程", "title_en": "Solving General-Utility Markov Decision Processes in the Single-Trial Regime with Online Planning", "authors": "Pedro P. Santos,Alberto Sardinha,Francisco S. Melo", "background": "以往的研究通常关注无限时间折扣的一般用途马尔可夫决策过程（GUMDP）在多试运行框架下的求解方法。然而，实际应用中，代理的表现往往是基于单个轨迹进行评估的，这种情况下之前的解决方法并不适用。本文旨在填补这一空白，研究如何在单试运行框架下解决GUMDP。", "innovation": "本文提出了首个针对单试运行框架下无限时间折扣的一般用途马尔可夫决策过程的解决方法，采用在线规划技术，特别是蒙特卡洛树搜索算法。同时，首次为单试运行框架下的策略优化提供了基础理论分析，探讨了何种策略类能满足最优性要求，并研究了策略优化的计算复杂性。", "conclusion": "实验结果表明，本文提出的方法在与基准方法的比较中表现出了更好的性能。"}
{"llm_update_time": "20260211", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.16741", "html_url": "https://arxiv.org/abs/2505.16741", "title": "最小注意度元增强学习", "title_en": "Meta-reinforcement learning with minimum attention", "authors": "Shashank Gupta,Pilhwa Lee", "background": "该研究基于Brockett提出的变化控制中的最小努力原则。最小努力原则强调在控制状态和时间的变化时应用最少的干预。这种思想与生物控制的模拟密切相关，例如运动学习过程中的最小努力原则也被用来模仿神经肌肉控制机制。最小注意度被应用于强化学习中，体现在奖励设计中，并探究了它与元学习和稳定性之间的关系。", "innovation": "该研究探讨了最小注意度在高维非线性动态系统中的元增强学习应用，使用了基于模型的元学习方法，交替进行了基于模型的学习和基于梯度的元策略学习。实验结果显示，最小注意度在模型自由和基于模型的RL算法中表现出优越性，特别是在快速适应少量示例和减少模型及环境扰动引起的方差方面。", "conclusion": "最小注意度增强了能量效率，并展示了优于现有顶级算法的性能，在少数示例下的快速适应和从模型及环境扰动中显著减少变异性方面表现突出。"}
{"llm_update_time": "20260211", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.18996", "html_url": "https://arxiv.org/abs/2505.18996", "title": "自适应且结构意识下的混合神经常微分方程稀疏化", "title_en": "Automatic and Structure-Aware Sparsification of Hybrid Neural ODEs", "authors": "Bob Junyi Zou,Lu Tian", "background": "混合神经常微分方程（neural ODEs）将机制性模型与神经 ODEs 结合，提供了较强的归纳偏置和灵活性，并特别适用于数据稀缺的医疗保健情境。然而，机制性模型带来的过多潜在状态和交互可能导致训练效率低下和过拟合，从而限制了混合神经 ODEs 的实用性。", "innovation": "本文提出了一种新的混合管道，用于自动选择和优化机制性神经 ODEs 的状态和结构，结合领域知识驱动的图修改与数据驱动的正则化方法，以稀疏化模型并提升预测性能和稳定性，同时保持机制的真实性。", "conclusion": "实验在合成和实际数据上的结果表明，这种方法在保持所需稀疏性的情况下提高了预测性能和稳健性，建立了混合模型在医疗保健应用中有效减少的方法。"}
{"llm_update_time": "20260211", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.20123", "html_url": "https://arxiv.org/abs/2505.20123", "title": "通过概率流距离理解扩散蒸馏的泛化问题", "title_en": "Understanding Generalization in Diffusion Distillation via Probability Flow Distance", "authors": "Huijie Zhang,Zijian Huang,Siyi Chen,Jinfan Zhou,Zekai Zhang,Peng Wang,Qing Qu", "background": "扩散蒸馏提供了一种有效的方法，可用于学习轻量级和几步的扩散模型，并且在生成方面效率很高。然而，评估其泛化能力仍然具有挑战性：理论度量往往对于高维数据来说并不实用，而没有实际度量可以严格衡量泛化能力。", "innovation": "本文通过引入概率流距离（PFD），这是一种理论依据扎实且计算效率高的度量标准，用于测量泛化能力。PFD通过比较概率流ODE引起的噪声到数据映射之间的分布来量化距离。利用PFD在扩散蒸馏设置下，我们发现了几个关键的泛化行为，包括量化从记忆到泛化的量化行为、分批次训练动态中的双重下降行为以及偏差-方差分解。", "conclusion": "这项工作为扩散蒸馏中的泛化研究奠定了基础，并将其与扩散训练连接起来。"}
{"llm_update_time": "20260211", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.04542", "html_url": "https://arxiv.org/abs/2506.04542", "title": "Neural MJD: 非站定Merton跳扩散的神经网络模型", "title_en": "Neural MJD: Neural Non-Stationary Merton Jump Diffusion for Time Series Prediction", "authors": "Yuanpei Gao,Qi Yan,Yan Leng,Renjie Liao", "background": "尽管深度学习方法在时间序列预测中取得了强劲的性能，但它们的黑盒特性和无法明确表示潜在的随机过程时常限制了它们对非站定数据的泛化能力，尤其是在存在突然变化的情况下。", "innovation": "提出了一种基于神经网络的非站定Merton跳扩散模型（Neural MJD），该模型明确将预测表述为随机微分方程（SDE）模拟问题，结合非齐次伊藤扩散来捕捉非站定的随机动态，以及非齐次复合泊松过程来建模突然跳跃。为了使学习变得易于处理，引入了一种概率缩放机制，限制了小时间间隔内跳跃的数量，并提供了对该近似的理论误差上限。此外，还提出了一种重新启动式Euler-Maruyama求解器，相较于标准求解器，在估计期望状态和降低方差方面具有可证明的较低误差边界。", "conclusion": "在合成和真实数据集上的实验表明，Neural MJD 比最先进的深度学习和统计学习方法表现出更优的表现。"}
{"llm_update_time": "20260211", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.03111", "html_url": "https://arxiv.org/abs/2506.03111", "title": "快速多尺度流体流动建模的校正流", "title_en": "Rectified Flows for Fast Multiscale Fluid Flow Modeling", "authors": "Victor Armegioiu,Yannick Ramic,Siddhartha Mishra", "background": "统计代理模型在流体流动中的应用面临着挑战，因为流动的动力学是多尺度的，并且对初始条件极为敏感。条件扩散型代理可以是准确的，但通常需要数百个随机采样步骤。本文背景在于现有方法在多尺度问题上的效率较低。", "innovation": "本文提出了一种校正流代理方法，该方法能够学习一个与输入到输出法律相关的时空依赖速度场，并沿着几乎直线的轨迹进行传播。推理过程是确定性的ODE求解，使得每次函数评估更具信息性。相比于基于分数的扩散方法需要128步，本文方法仅需8步就可以达到相似的统计后验结果。", "conclusion": "通过理论分析，本文推导出误差的一步分裂方法，并且通过一个校正时间的直线性控制ODE局部截断误差，为实际的步长/步骤数量指导提供了帮助。为了改善这一效果，引入了一个曲率感知采样器，该采样器使用指数移动平均（EMA）直线性代理来适应推理过程中的混合和步长。实验结果表明，该方法在马尔可夫统计和频谱上匹配扩散基线，并保持了更精细的流体结构特征，同时显著降低了推理成本。"}
{"llm_update_time": "20260211", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.15047", "html_url": "https://arxiv.org/abs/2505.15047", "title": "PiFlow：基于原理的多智能体协作科学发现", "title_en": "PiFlow: Principle-Aware Scientific Discovery with Multi-Agent Collaboration", "authors": "Yingming Pu,Tao Lin,Hongyu Chen", "background": "现有的基于大型语言模型（LLM）的多智能体系统（MAS）在科学研究中显示出很大的潜力，但是目前这些方法往往依赖于预定义的工作流程，缺少理性的约束条件，导致了无目标的假设和难以将假设与证据一致地链接，从而影响了对不确定性的系统化缩减。", "innovation": "本文提出了一种信息理论框架PiFlow，将自动化科学发现视为由原理指导的结构化不确定性减少问题。通过广泛的研究表明，与最先进的方法相比，PiFlow在三个不同的科学领域中可以提高发现效率31.18%~41.73%，提高解决方案质量12.47%~31.72%，使解决方案时间加速5.6倍，同时减少高达27%的令牌消耗，并提供了一个能够与现有架构插件配置的模块。", "conclusion": "PiFlow通过建立了高效代理科学发现的新范式，为更稳健和加速的AI驱动研究铺平了道路。"}
{"llm_update_time": "20260211", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.19238", "html_url": "https://arxiv.org/abs/2505.19238", "title": "在具有迭代复杂性保证的鲁棒约束MDPs中高效策略优化", "title_en": "Efficient Policy Optimization in Robust Constrained MDPs with Iteration Complexity Guarantees", "authors": "Sourav Ganguly,Kishan Panaganti,Arnob Ghosh,Adam Wierman", "background": "受限决策制定是确保实时控制系统中安全策略设计的关键。然而，模拟环境往往无法捕捉到现实世界中的各种不利因素。本文针对在存在真实模型与可访问模拟器或名义模型之间偏差的情况下，学习同时最大化累积奖励和满足约束条件的策略。特别地，考虑了在不确定性集合中心存在未知名义模型的情况下，如何最大化奖励并满足对最坏可能的随机模型的约束条件的鲁棒约束MDP（RCMDP）问题。", "innovation": "提出了一个新颖的技术，能够在满足约束条件的同时有效最小化约束值函数；同时，在所有约束条件满足时，可以最大化鲁棒奖励值函数。证明了该算法在最多$\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{}}))))}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}$的次优性且经过$O(\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{}}))))}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}$次迭代后找到可行策略。与现有技术相比，不需要使用二分搜索，因此对于较小的折扣因子$\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{}}))))}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}$，可以减少至少4倍的计算时间；对于较大的$\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{}}))))}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}$可以减少至少6倍的计算时间。", "conclusion": "本文提出的方法通过直接优化约束值函数并结合鲁棒性，在较少的迭代次数下能够有效地找到满足约束条件并最大化鲁棒奖励的策略，提高了策略优化的效率。"}
{"llm_update_time": "20260211", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.17854", "html_url": "https://arxiv.org/abs/2505.17854", "title": "从阴影中探索潜在空间进行神经网络验证", "title_en": "Out of the Shadows: Exploring a Latent Space for Neural Network Verification", "authors": "Lukas Koller,Tobias Ladner,Matthias Althoff", "background": "神经网络在许多领域广泛应用，但往往对输入变化敏感。安全关键应用中，需要进行形式验证以避免意外行为，而形式验证是一个极为复杂的问题。现有许多先进的验证算法通过可抵达性分析或抽象解释来界定神经网络可能的输出集，但由于保守性常导致验证结果不确定。", "innovation": "提出了一种新颖的基于规范驱动的输入细化程序，通过迭代求解神经网络的预像，减少可能输入的集合，直到仅包含潜在的错误输入。利用投影基集合表示生成的潜在空间，将输出规范转化为输入空间。使用基于投影集合表示（例如：zonotope）的效率验证工具，通过分支边界过程显著减少子问题数量。这种方法实现了仅使用矩阵操作的工具实现，通过高效的GPU加速获得显著加速。", "conclusion": "提出的工具在国际神经网络验证竞赛中展示了竞争力，与顶级工具相比具有良好的性能。"}
{"llm_update_time": "20260211", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.00175", "html_url": "https://arxiv.org/abs/2506.00175", "title": "现代AI系统的功劳与责任：现代AI系统中的问责制归因", "title_en": "Who Gets Credit or Blame? Attributing Accountability in Modern AI Systems", "authors": "Shichang Zhang,Hongzhe Du,Jiaqi W. Ma,Himabindu Lakkaraju", "background": "现代AI系统通常通过预训练、微调和后续适应或对齐等多阶段过程开发。每一步都基于之前的步骤，并以不同的方式更新模型。然而，当部署后的模型成功或失败时，很难确定哪一阶段的责任以及责任的程度。", "innovation": "提出了一个通用框架来回答关于阶段影响的反事实问题: 如果某阶段的更新没有发生，模型的行为将如何变化？该框架引入了不需要重新训练模型、计算阶段影响的估计器，并考虑了数据和模型优化动力学的关键方面，如学习率计划、动量和权重衰减。", "conclusion": "通过归因结果，该方法能够识别和消除图像分类和文本毒性检测任务中的伪相关，这些任务跨越多个阶段开发。该方法为模型分析提供了一个实际工具，并代表了更具问责制的AI开发的重要一步。"}
