# 20260209
[![Subscribe_Visitors](https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss)](https://github.com/nituchao/latest_arxiv_analyze_ai)

## 1. `cs.AI` - 迈向可减少不确定性建模以实现可靠的大型语言模型代理 [PDF](https://arxiv.org/pdf/2602.05073), [HTML](https://arxiv.org/abs/2602.05073)
### Authors
Changdae Oh,Seongheon Park,To Eun Kim,Jiatong Li,Wendi Li,Samuel Yeh,Xuefeng Du,Hamed Hassani,Paul Bogdan,Dawn Song,Sharon Li
### Background
大型语言模型（LLMs）在日常应用中的安全性保障关键在于不确定性量化（UQ）的确定，尽管LLM代理在复杂任务中的应用日益增多，但大部分UQ研究仍然局限于单轮问答任务。
### Innovation
提出了一种新的代理UQ视角，即条件下的不确定性减少过程，并构建了一个概念框架，用于在设计LLM代理设置中的UQ时提供实用指导。
### Conclusion
阐述了代理UQ在前沿LLM开发和特定领域应用中的实际意义，并指出了现存的问题。
## 2. `cs.AI` - 理解大型语言模型评估者的行为：基于商户风险评估的结构化多评估者框架 [PDF](https://arxiv.org/pdf/2602.05110), [HTML](https://arxiv.org/abs/2602.05110)
### Authors
Liang Wang,Junpeng Wang,Chin-chia Michael Yeh,Yan Zheng,Jiarui Sun,Xiran Fan,Xin Dai,Yujie Fan,Yiwei Cai
### Background
大型语言模型（LLMs）在评价推理质量方面被广泛应用，但在商户类别代码（MCC）基于的商户风险评估场景中的可靠性和偏差方面仍缺乏深刻的理解。
### Innovation
引入了一种结构化的多评估者框架，该框架结合了五项标准评分表和蒙特卡洛评分来评估推理质量及评估者的一致性；利用共识偏差指标来建立独立于法官的参考标准；并首次揭示了不同LLM在自我评价和跨模型偏差方面的显著差异。
### Conclusion
框架提供了评估LLM作为评估者系统的可重复基础，并强调在操作性金融环境中需要具备偏见意识的规程。
## 3. `cs.AI` - 使用燃料补充和自适应碰撞规避的强化学习优化多碎片对接任务规划 [PDF](https://arxiv.org/pdf/2602.05075), [HTML](https://arxiv.org/abs/2602.05075)
### Authors
Agni Bandyopadhyay,Gunther Waxenegger-Wilfing
### Background
随着地球轨道空间碎片不断增多，主动碎片清除（ADR）任务面临的挑战日益增加，这些任务需要在确保安全操作的同时尽量减少在轨碰撞的风险。本文针对小卫星进行多碎片清除任务，提出了一个基于强化学习的框架，以便增强自适应碰撞规避能力。
### Innovation
该框架在一个新的背景下构建，即结合了燃料补充策略、高效任务规划和自适应碰撞规避技术，以优化小卫星的近距离交会操作。使用掩蔽的Proximal Policy Optimization (PPO)算法，RL智能体可以根据实时轨道条件动态调整操作。此外，框架还考虑了燃料效率、规避主动碰撞区和动态轨道参数最优化。
### Conclusion
通过仿真测试，该RL框架展示了降低碰撞风险、提高任务效率的效果，显著优于传统的启发式方法。此工作为计划复杂的多碎片清除任务提供了扩展解决方案，并适用于其他多目标对接任务的自主空间任务规划难题。
## 4. `cs.AI` - GAMMS: 基于图的对抗性多智能体建模模拟器 [PDF](https://arxiv.org/pdf/2602.05105), [HTML](https://arxiv.org/abs/2602.05105)
### Authors
Rohan Patil,Jai Malegaonkar,Xiao Jiang,Andre Dion,Gaurav S. Sukhatme,Henrik I. Christensen
### Background
随着智能系统和多智能体协调在实际应用中的重要性日益增大，对既具有扩展性又易于使用的模拟工具的需求也日益增长。现有的高保真度模拟器虽然功能强大，但往往计算成本很高，不适于快速原型设计或大规模智能体部署。
### Innovation
GAMMS是一个轻量级但扩展性强的模拟框架，旨在支持复杂环境（如城市路网和通信系统）中智能体行为的快速开发与评估。GAMMS强调五大核心目标：扩展性、易于使用、以集成为主的设计、快速可视化反馈和现实世界的应用。它支持不同类型（包括使用大规模语言模型的）智能体，能有效降低研究人员的门槛，并促进多智能体系统、自主规划和对抗性建模的实验和创新。
### Conclusion
通过在标准硬件上实现高性能模拟，GAMMS促进了多智能体系统的研究与创新。GAMMS开源，并可在以下链接获取：this https URL
## 5. `cs.AI` - Artificial Intelligence as Strange Intelligence: Against Linear Models of Intelligence [PDF](https://arxiv.org/pdf/2602.04986), [HTML](https://arxiv.org/abs/2602.04986)
### Authors
Kendra Chilson,Eric Schwitzgebel
### Background
本文讨论了 Susan Schneider 对 AI 进步线性模型的批评，并提出了两种新型概念：?熟悉智能?和?陌生智能?。文章认为 AI 智能更可能是陌生智能，这打破了熟悉的智能模式，表现为在某些领域具有超人类能力而在其他领域则表现出亚人类水平，甚至在同一领域也可能表现出超人的洞察力和令人惊讶的错误。
### Innovation
文章引入了两种新概念：?熟悉智能?（familiar intelligence）和?陌生智能?（strange intelligence）。作者开发并捍卫了一种非线性的智能模型，认为?通用智能?不是一个统一的能力，而是能够在各种环境和目标中高效运作的能力。这一模型挑战了将智能归结为单一的线性指标，提出了对评估 AI 能力的对抗性测试方法的看法。
### Conclusion
如果 AI 是陌生智能，那么即使是最先进的系统也可能会在看似明显的任务上失败。在非线性模型下，这些错误本身并不能作为系统缺乏出色一般智能的证据。相反，某类任务上的出色表现，如 IQ 测试，也不能被认为是超出特定任务范围的能力证据。
## 6. `cs.AI` - MINT: Minimal Information Neuro-Symbolic Tree for Objective-Driven Knowledge-Gap Reasoning and Active Elicitation [PDF](https://arxiv.org/pdf/2602.05048), [HTML](https://arxiv.org/abs/2602.05048)
### Authors
Zeyu Fang,Tian Lan,Mahdi Imani
### Background
在开放环境中通过语言进行的人机联合规划是人机团队合作的关键领域。由于涉及不完整信息和未知因素（如涉及的对象、人类目标/意图等），联合规划中存在知识空白。本文探讨了发现最优的人工智能（AI）检测策略，使其能够主动促使人类提出输入，在以对象为中心的规划中，这有助于解决知识空白。通过这种方式，旨在优化AI在规划中的启发策略和提出的查询。
### Innovation
提出了一种名为MINT（Minimal Information Neuro-Symbolic Tree）的方法，用于推理知识空白的影和利用自我博弈来优化AI检测策略及其查询。MINT方法通过构建符号树来考虑可能的人机交互，并咨询神经规划策略以估计剩余的知识空洞性对规划结果的不确定性。此外，通过利用大型语言模型（LLM）来搜索和总结MINT的推理过程，制定一系列查询以优化地获得人类输入，从而实现最佳规划性能。通过分析扩展马尔可夫决策过程中的知识空隙，进一步确保了带有主动人类填写的MINT的回报保证。
### Conclusion
在三个涉及未知对象的真实度逐渐增强的基准测试中，基于MINT的方法通过每次任务发布少量问题，实现了接近专家级的表现，同时显著提高了奖励和成功率。
## 7. `cs.AI` - DeepRead：文档结构感知推理以增强主动搜索 [PDF](https://arxiv.org/pdf/2602.05014), [HTML](https://arxiv.org/abs/2602.05014)
### Authors
Zhanli Li,Huiwen Tian,Lvzhou Luo,Yixuan Cao,Ping Luo
### Background
随着工具使用和行动者型大型语言模型（LLMs）的迅速发展，检索增强生成（RAG）从一次性的被动检索转变为多轮次、决策驱动的证据获取。尽管在开放域中取得了良好的结果，现有的行动者型搜索引擎框架通常将长文档视为扁平化的片段集合，未能充分利用原文档自然先验，如层次结构和顺序论述结构。因此，本研究引入了DeepRead，一种结构感知的多轮次文档推理代理，它明确操作这些先验以进行长文档问题解答。
### Innovation
DeepRead 利用基于LLM的OCR模型将PDF转换为结构化的Markdown格式，保留标题和段落边界。它在段落级别索引文档，并为每个段落分配包含其部分身份和部分内顺序的坐标的元数据键。在此表示基础上，DeepRead 为LLM配备了两个互补工具：一个检索工具，可以在轻量级扫描上下文中精确定位相关段落并暴露其结构坐标；一个阅读部分工具，可以在指定的部分和段落范围内进行连续、顺序保持的阅读。
### Conclusion
我们的实验表明，DeepRead 在文档问题解答中显著优于Search-o1风格的行动者型搜索。检索和阅读工具之间协同效应也得到了验证。我们细致的行为分析揭示了一种类似于人类“定位后阅读”行为的阅读和推理范式。
## 8. `cs.AI` - 在图论中评估大型语言模型：已解决和未解决的问题对计算教育的影响 [PDF](https://arxiv.org/pdf/2602.05059), [HTML](https://arxiv.org/abs/2602.05059)
### Authors
Adithya Kulkarni,Mohna Chakraborty,Jay Bagga
### Background
随着大型语言模型被越来越多的学生用于探索计算机科学中包括图论在内的高级材料，它们现在正逐渐融入本科和研究生课程。因此，了解这些工具在支持数学严谨思维方面的可靠程度变得尤为重要。本文研究了一个大型语言模型在图论中两个相关问题上的表现，即一个已解决的关于线图文雅性的问题和一个尚未解决的开放问题。题目采用了反映真实数学研究的八阶段评估程序，包括解释、探索、策略形成和证明构造等步骤。
### Innovation
研究提出了一种八阶段的评估框架，该框架反映了真实的数学探究过程，并用以评估大型语言模型在图论问题上的表现。同时，研究还明确了大型语言模型在支持已知材料的探索性学习方面的有效性，指出了它们在需要新颖数学洞察或关键结构推理任务中的局限性。
### Conclusion
研究结果表明，大型语言模型可以支持已知材料的探索，但在需要新颖数学洞察或关键结构推理的任务中仍有限制。对计算教育来说，这些发现突显了引导学生利用大型语言模型进行概念性探索的重要性，同时强调了独立验证和严谨论证对于正式问题解决的依赖性。
## 9. `cs.AI` - VERA-MH: 一个开源心理健康AI安全评估的可靠性和有效性的评估 [PDF](https://arxiv.org/pdf/2602.05088), [HTML](https://arxiv.org/abs/2602.05088)
### Authors
Kate H. Bentley,Luca Belli,Adam M. Chekroud,Emily J. Ward,Emily R. Dworkin,Emily Van Ark,Kelly M. Johnston,Will Alexander,Millard Brown,Matt Hawrilenko
### Background
现在有数百万人使用生成AI聊天机器人进行心理支持。尽管这些工具在可用性和规模方面具有巨大潜力，但心理健康领域中最紧迫的问题之一是，这些技术是否安全。最近提出了验证伦理和负责任的AI在心理健康中的评价（VERA-MH）评估，以应对急需的基于证据的自动化安全基准。本研究旨在评估VERA-MH评估在自杀风险检测和响应中的临床有效性和可靠性。
### Innovation
本研究创新性地模拟了一组由大型语言模型（LLM）驱动的用户-代理与通用AI聊天机器人的对话。专家临床医生使用评分指南独立评价这些对话中的安全和不安全的行为，以及用户-代理的现实性。研究旨在比较不同临床医生和他们的一致性，以及临床共识和LLM评估结果的一致性，从而验证VERA-MH评估的有效性和可靠性。
### Conclusion
临床医生在安全性评估方面表现出高度一致性（调整后的测验者间可靠性为0.77），为临床参考标准提供了标准。LLM评估与临床共识高度一致（调整后的测验者间可靠性为0.81），各临床条件下的可靠性也较好。用户-代理在现实性方面一般被临床医生认为是现实的。研究结果支持Clinical验证和验证VERA-MH：心理健康领域的一种开源、完全自动化的AI安全评估。进一步研究将进一步验证VERA-MH的普遍性和稳健性。
## 10. `cs.AI` - 基于学习的任务规划在主动太空垃圾清除中的鲁棒性和适应性评估 [PDF](https://arxiv.org/pdf/2602.05091), [HTML](https://arxiv.org/abs/2602.05091)
### Authors
Agni Bandyopadhyay,Günther Waxenegger-Wilfing
### Background
主动太空碎片清除任务中的自主任务规划必须平衡效率、适应性和燃料及任务持续时间的严格约束。研究者们在低地球轨道环境下对三种约束多目标碎片对接问题的规划器进行了比较：标准的掩膜Proximal Policy Optimization (PPO)策略，基于固定任务参数进行训练；掩膜PPO策略，在变化的任务约束下进行训练以提高鲁棒性；以及一种简单的Monte Carlo Tree Search (MCTS)基线。这些评估在高保真轨道模拟环境中进行，模拟了加注燃料、真实的转移动力学以及随机化的碎片场。评估在理想、燃料减少、任务时间缩短的300种测试情况下进行。
### Innovation
研究比较了三种不同的规划方法，包括掩膜PPO策略、随机化掩膜PPO策略和MCTS基线，这些方法针对低地球轨道的约束多目标碎片对接问题。研究展示了每种方法在不同条件下的表现，以及在不同约束情况下的适应能力。
### Conclusion
标准PPO策略在条件与训练相匹配时表现最佳，但在条件发生变化时表现不佳，而随机化掩膜PPO策略在保持良好初始性能的同时具有更好的适应能力。MCTS基线策略能够最好地处理约束变化，但由于在线重新规划带来了巨大的计算时间成本。研究强调了学习策略的快速性与基于搜索方法的适应性的权衡，并提示未来的研究可能从结合训练时的多样性与在线规划中受益。
## 11. `cs.AI` - CellForge: 代理设计的虚拟细胞模型 [PDF](https://arxiv.org/pdf/2508.02276), [HTML](https://arxiv.org/abs/2508.02276)
### Authors
Xiangru Tang,Zhuoyun Yu,Jiapeng Chen,Yan Cui,Daniel Shao,Weixu Wang,Fang Wu,Yuchen Zhuang,Wenqi Shi,Zhi Huang,Arman Cohan,Xihong Lin,Fabian Theis,Smita Krishnaswamy,Mark Gerstein
### Background
虚拟细胞建模旨在预测细胞对各种干扰的响应，但面临生物复杂性、多模态数据异质性和跨学科专长的挑战。
### Innovation
CellForge 是一个多智能体框架，能够自主设计和合成针对特定单细胞数据集和扰动任务定制的神经网络架构。通过智能体之间的协作推理，CellForge 发现候选架构，然后生成可执行实现。框架的核心贡献在于展示多智能体合作机制可以自主生产可执行的高质量计算方法，这种机制超越了传统的超参数调整，通过智能体的自主推理产生新的架构组件。
### Conclusion
CellForge 强调多智能体框架的科学价值：通过专门智能体之间的协作产生真正的方法创新和可执行解决方案。这代表了计算生物学自主科学方法开发范式的转变。
## 12. `cs.AI` - CoSteer：通过局部 delta 舵令实现协作解码时个性化 [PDF](https://arxiv.org/pdf/2507.04756), [HTML](https://arxiv.org/abs/2507.04756)
### Authors
Hang Lv,Sheng Liang,Hao Wang,Hongchao Gu,Yaxiong Wu,Wei Guo,Defu Lian,Yong Liu,Enhong Chen
### Background
个性化对于适应用户在文化、时间及上下文维度上不断变化的需求变得至关重要。现有方法多依赖集中式的微调或单模型静态偏好对齐，但在个人设备的资源和隐私限制下，难以同时实现实时且高质量的个性化。
### Innovation
我们提出了CoSteer，一种协作框架，通过在解码时进行适应来实现无调优的实时个性化。CoSteer 利用上下文感知和上下文无关的小模型之间logit的差异来引导基于云的大型模型，以确保个性化同时保留大型模型的能力。个性化处理在本地进行，只有最终的标记发送到云端，既保持了用户上下文又提高了系统效率。
### Conclusion
通过广泛的任务实验，我们证明了CoSteer可以通过本地方式进行高质量个性化，确保了效果和计算效率。实验结果展示其在不同模型和环境中的鲁棒性，证实了其在真实场景中的实际应用价值。
## 13. `cs.AI` - 剖析SWE-Bench领奖台：LLM和基于代理的修复系统提交者与架构概况 [PDF](https://arxiv.org/pdf/2506.17208), [HTML](https://arxiv.org/abs/2506.17208)
### Authors
Matias Martinez,Xavier Franch
### Background
自动程序修复（APR）的进步受到了人工智能尤其是大型语言模型（LLMs）和基于代理的系统发展的推动。SWE-Bench 是一項新的基准测试，专门评估基于LLMs的修复系统，使用从12个流行的开源Python仓库中挖掘的实际问题和拉取请求进行测试。SWE-Bench 公开推介板（SWE-Bench Lite和SWE-Bench Verified）已经成为跟踪进展和比较解决方案的重要平台。然而，由于提交过程不要求详细的文档，许多解决方案的架构设计和起源仍不清楚。
### Innovation
本文首次全面研究了SWE-Bench Lite（79条提交）和Verified（99条提交）领先的后续方法，分析了80种独特的提交维度，包括提交者类型、产品可用性、LLMs的使用情况和系统架构。研究发现，专有LLMs（尤其是Claude 3.5）主导地位明显，同时存在有代理和无代理的设计，提交者群体范围广泛，从个人开发者到大型科技公司。
### Conclusion
研究结果揭示了以专有LLMs为主的修复系统分布，以及从个人贡献者到企业级贡献者的多样贡献者群体，同时展示了基于代理与非代理设计的多样策略和发展趋势。
## 14. `cs.AI` - 非对比自监督学习的双视角分析 [PDF](https://arxiv.org/pdf/2507.01028), [HTML](https://arxiv.org/abs/2507.01028)
### Authors
Jean Ponce(ENS-PSL, NYU),Basile Terver(FAIR, WILLOW),Martial Hebert(CMU),Michael Arbel(Thoth)
### Background
非对比自监督学习中常用的‘停止梯度’和‘指数移动平均’迭代程序在实践中的下游应用中表现出优异性能。然而，这些方法通常被认为并没有优化原始目标或其他光滑函数，而是避开了表示崩溃。
### Innovation
本文从优化和动力系统两个角度对这些迭代程序进行了分析。通过动力系统视角，作者证明在线性情况下，不使用‘停止梯度’或‘指数移动平均’总是会导致表示崩溃。此外，作者还明确定义了这两种方法在这一线性设置下的动力系统中的等价平衡点，并证明它们的一般渐进稳定性。
### Conclusion
理论发现通过实际和合成数据的实验得到了验证。总的来说，这些方法成功地避开了表示崩溃，尽管它们不是通过优化原始目标或其他光滑函数来实现的，作者的论述并未依赖于现有的假设。
## 15. `cs.AI` - 无分割的好发音度量 [PDF](https://arxiv.org/pdf/2507.16838), [HTML](https://arxiv.org/abs/2507.16838)
### Authors
Xinwei Cao,Zijian Fan,Torbjørn Svendsen,Giampiero Salvi
### Background
现代计算机辅助语言学习（CALL）系统中的发音错误检测和诊断（MDD）是一项重要任务。多数基于音素级MDD的方法依赖于语音提前分割成音素单元，这限制了这些方法的准确性，也限制了现代CTC基自动语音识别（ASR）模型的应用。
### Innovation
研究首先提出了自我对齐的好发音度量（GOP-SA），使之能够利用CTC训练的ASR模型进行MDD。接着定义了一种更通用的无分割方法（GOP-SF），考虑语码转录的所有可能分割方式。给出了GOP-SF的理论解释和实现方法，解决了潜在的数值问题，并采用了适当的规范化方法，可以使不同时间峰值度的声学模型也能有效使用。实验结果表明，拟提出的方法在语音海洋762数据集上的发音层面表现优于现有研究。
### Conclusion
通过无分割的方法和自我对齐的好发音度量，改进了基于CTC的发音错误检测和诊断系统的准确性和实用性。GOP-SF可根据声学模型的峰值度和目标音素周围上下文量的变化，灵活调整参数，不同数据集上都取得了最优性能。
## 16. `cs.AI` - 学习总结用户信息以实现个性化的人类反馈强化学习 [PDF](https://arxiv.org/pdf/2507.13579), [HTML](https://arxiv.org/abs/2507.13579)
### Authors
Hyunji Nam,Yanming Wan,Mickel Liu,Peter Ahnn,Jianxun Lian,Natasha Jaques
### Background
随着大型语言模型（LLM）AI助手在日常使用场景中的应用扩展，个性化响应以符合不同用户偏好和目标变得越来越重要。虽然基于人类反馈的强化学习（RLHF）能够提高LLM的普遍帮助性和流畅性，但它未能考虑到用户之间的差异性，因为它用单一的奖励模型建模整个用户群体，假设每个人的偏好都相同。
### Innovation
提出了一种名为PLUS（Preference Learning Using Summarization）的新框架，使用强化学习（RL）来学习生成每个用户的偏好、特征及其过往对话的文本摘要。这些摘要条件性地影响奖励模型，使其能够为每个用户做出个性化预测。用户摘要模型和奖励模型同时进行训练，构建了一个在线协同适应循环。与标准Bradley-Terry模型相比，PLUS生成的摘要能够捕捉用户偏好方面的多样特性，奖励模型的准确性提升了11-77%。PLUS的关键优点包括：与新用户和对话主题的鲁棒性能，对比最佳个性化奖励模型技术在RLHF中的表现提高了25%；零样本个性化，与最先进的GPT-4等模型相比效果显著；从超越偏好标签的灵活用户上下文进行学习；以及用户友好的表示形式，提高多样的LLM对齐的透明度和用户控制。
### Conclusion
 PLUS框架通过利用强化学习算法来学习用户的偏好摘要，实现了奖励模型的个性化预测，提高了用户偏好多样性的捕捉能力，并且在鲁棒性和零样本个性化方面表现优异，还能够从更广泛的用户上下文中学习，并提供了用户友好的表示形式，增强了多样的LLM对齐的透明度和用户控制。
## 17. `cs.AI` - Personalized Safety Alignment for Text-to-Image Diffusion Models [PDF](https://arxiv.org/pdf/2508.01151), [HTML](https://arxiv.org/abs/2508.01151)
### Authors
Yu Lei,Jinbin Bai,Qingyu Shi,Aosong Feng,Hongcheng Gao,Xiao Zhang,Rex Ying
### Background
文本到图像的扩散模型极大地改变了视觉内容的生成方式，但其部署受到一个根本性限制的阻碍：安全机制实施了僵化且统一的标准，未能反映根据年龄、文化或个人信仰形成的多样化用户偏好。为解决这一问题，本文提出了一种名为Personalized Safety Alignment（PSA）的框架，该框架将生成性安全从静态过滤转变为用户条件下的适应性调整。此外，引入了一个名为Sage的大型数据集，该数据集涵盖了1,000个模拟用户配置文件，这些配置文件捕捉了复杂的风险，并超出了传统数据集的范围。
### Innovation
本文提出了一种名为PSA的框架，将生成性安全从静态过滤转变为用户条件下的适应性调整。PSA通过集成1,000个模拟用户配置文件，利用参数高效交叉注意适配器动态调整个体敏感性，从而实现安全和质量之间的平衡。PSA在宽松配置文件下放松过于谨慎的约束，提高视觉保真度，而在严格配置文件下则严格执行最先进的抑制措施。PSA还表现出比提示工程方法更好的指令遵守性，从而确立了个性化作为为生成AI创建适应性和用户为中心的方向的重要性。
### Conclusion
广泛的实验表明，PSA能够在校准安全和质量之间的权衡下实现安全和质量之间的平衡，并且在个人化方向上优于现有的静态基准。通过PSA，生成性AI可以更加适应用户的需求，创造更加负责任和用户中心的生成AI。相关代码、数据和模型均在https://this.is/publicly可获取。
## 18. `cs.AI` - LittleBit：通过潜在因子化实现超低位量化 [PDF](https://arxiv.org/pdf/2506.13771), [HTML](https://arxiv.org/abs/2506.13771)
### Authors
Banseok Lee,Dongkyu Kim,Youngcheon You,Youngmin Kim
### Background
大型语言模型（LLMs）的部署常常受限于内存和计算需求。量化虽然可以缓解这些问题，但在低于1位的精度范围内保持模型精度仍是一个持续的挑战。
### Innovation
本文提出了一种新的框架LittleBit，用于极端的LLM压缩。它能够在每个权重仅0.1位（BPW）的量化率下，实现约31倍的内存缩减，有效将Llama2-13B压缩到不到0.9 GB。其贡献包括双符号-值-独立分解（Dual-SVID）以进行量化感知训练（QAT）初始化，并通过残差补偿机制减少约简误差。实验表明，在亚1位领域LittleBit具有优势。代码已公开。
### Conclusion
LittleBit实现了相对于FP16 11.6倍的推理速度提升，并使强大的LLM在资源受限环境中变得实用。
## 19. `cs.AI` - STACK：对大规模语言模型防护管道的对抗性攻击 [PDF](https://arxiv.org/pdf/2506.24068), [HTML](https://arxiv.org/abs/2506.24068)
### Authors
Ian R. McKenzie,Oskar J. Hollinsworth,Tom Tseng,Xander Davies,Stephen Casper,Aaron D. Tucker,Robert Kirk,Adam Gleave
### Background
前沿的人工智能开发者正在依赖多层防护措施来防止AI系统的灾难性误用。Anthropic、OpenAI和谷歌DeepMind等公司都在使用类似的安全管道来保护他们的最新模型。然而，这些防护管道的安全性尚未得到充分评估或攻击测试。这篇论文的研究团队旨在填补这一空白。
### Innovation
1. 提出了一个新的少量示例提示的输入和输出分类器，在三种攻击和两个数据集上超过了最先进的防护模型ShieldGemma，对灾难性误用数据集ClearHarm的攻击成功率降低到0%。2. 引入了名为STAGED AttaCK (STACK) 的攻击流程，在黑盒攻击下对少量示例提示分类器管道实现了71%的攻击成功率。3. 在迁移攻击设置下评估了STACK，达到了33%的攻击成功率，证明了在无访问目标管道的情况下设计攻击的可行性。
### Conclusion
论文建议了具体的缓解措施，开发人员可以利用这些措施来防止STAG攻击。
## 20. `cs.AI` - 借助深度学习的准确且可扩展的交换相关性 [PDF](https://arxiv.org/pdf/2506.14665), [HTML](https://arxiv.org/abs/2506.14665)
### Authors
Giulia Luise,Chin-Wei Huang,Thijs Vogels,Derk P. Kooi,Sebastian Ehlert,Stephanie Lanius,Klaas J. H. Giesbertz,Amir Karton,Deniz Gunceler,Megan Stanley,Wessel P. Bruinsma,Lin Huang,Xinran Wei,José Garrido Torres,Abylay Katbashev,Rodrigo Chavez Zavaleta,Bálint Máté,Sékou-Oumar Kaba,Roberto Sordillo,Yingrong Chen,David B. Williams-Young,Christopher M. Bishop,Jan Hermann,Rianne van den Berg,Paola Gori-Giorgi
### Background
密度泛函理论(DFT)是预测分子和材料性质最常用的方法。尽管DFT原则上是对薛定谔方程的一个精确重述，但实际应用依赖于对未知交换相关(XC)泛函的近似。现有的XC泛函大多基于一系列复杂但手工设计的特征构建，虽然提高了准确性但牺牲了计算效率。目前还没有泛函能在计算效率和化学准确性之间取得平衡，使预测实验结果的误差低于1 kcal/mol。基于此，为了构建能够达到这种准确性的泛函，本文采用现代基于深度学习的方法Skala来学习数据直接生成的表示，从而避免手工设计复杂特征，同时保持类似半局域DFT的计算效率。
### Innovation
Skala是第一种通过从大数据直接学习泛函特点，而不依赖于手工设计复杂特征的深度神经网络，实现化学准确性，同时保持高效计算。通过大幅增加训练数据和针对性的高精度数据，Skala展示了更好的泛函化学性能，这将为以后基于第一性原理的模拟提供更大的预测能力。
### Conclusion
Skala通过训练大量高精度参考数据，实现了小分子解离能的化学准确性，并保持了半局域DFT的计算效率。这种方法不仅提高了现有的化学性能，而且随着训练数据的不断扩展，有望进一步增强第一性原理模拟的预测性能。
## 21. `cs.LG` - TensLoRA: 张量方法的低秩适应 [PDF](https://arxiv.org/pdf/2509.19391), [HTML](https://arxiv.org/abs/2509.19391)
### Authors
Axel Marmoret,Reda Bensaid,Jonathan Lys,Vincent Gripon,François Leduc-Primeau
### Background
LoRA是一种广泛应用于高效改编Transformer的方法，通过在注意力投影中插入可训练的低秩矩阵来实现。虽然这种方法很有效，但这些矩阵被视为每个注意力投影（查询、键和值）和每个层的独立变量。最近的扩展虽然考虑了联合、张量式的改编，但这些方法大多仅限于有限的形式，并且没有系统性的框架。
### Innovation
作者提出了TensLoRA，这是一种统一框架，将LoRA更新整合到高阶张量中，并建模了一个广泛的张量低秩改编家族。该公式化方法涵盖了现有的张量方法，还允许特定模式的压缩率，使参数预算能够根据模态和任务进行定制。
### Conclusion
实验结果表明，张量构造直接影响性能，在相似参数数量下有时比标准LoRA表现更好。
## 22. `cs.LG` - 通过随机梯度噪声结构揭示 m-锐度 [PDF](https://arxiv.org/pdf/2509.18001), [HTML](https://arxiv.org/abs/2509.18001)
### Authors
Haocheng Luo,Mehrtash Harandi,Dinh Phung,Trung Le
### Background
尖锐感知最小化（SAM）已成为提高模型泛化能力的有效方法，但其原理尚未完全明了。SAM的性能随着计算扰动的微批次大小减少而单调提升，这一现象对于分布式训练至关重要，但缺乏严格的解释。
### Innovation
研究了m-锐度，利用扩展的随机微分方程（SDE）框架和分析随机梯度噪声（SGN）来表征SAM变体（包括n-SAM和m-SAM）的动力学。研究表明，随机扰动诱导了一个隐式的基于方差的尖锐化正则化，其强度随着m的减小而增加。基于这一洞察，提出了重加权SAM（RW-SAM），采用尖锐性加权采样来模拟m-SAM的泛化优势，同时保持可并行性。
### Conclusion
全面的实验验证了我们的理论和方法。
## 23. `cs.LG` - 使用神经网络进行灵活的动物学习规则推断 [PDF](https://arxiv.org/pdf/2509.04661), [HTML](https://arxiv.org/abs/2509.04661)
### Authors
Yuhan Helena Liu,Victor Geadah,Jonathan Pillow
### Background
理解动物如何学习是神经科学的核心挑战，且在开发动物兼容或人类兼容的人工智能方面具有日益重要的意义。现有的方法往往假设学习规则具有固定的参数形式（如 Q 学习、策略梯度），这些假设可能无法准确描述动物在现实环境中的学习模式。本文通过从动物在新任务学习过程中收集的行为数据中直接推断出学习规则，填补了这一空白。
### Innovation
本文开发了一种框架，利用深度神经网络从动物的行为数据中直接推断出学习规则，同时保持了决策政策的可解释性。以回声神经网络变体为例，该框架缓解了串行假设，学习规则可以整合多个试次的信息，这有潜力更好地捕捉复杂的学习动态。实验证明该框架可以恢复真实的学习规则，并且基于深度神经网络和递归神经网络的方法比传统的强化学习方法更擅长预测未见过新任务的动物的学习轨迹。
### Conclusion
研究表明，本文提出的方法提供了从新任务学习过程中收集的行为数据中推断学习规则的灵活框架，可提高动物训练协议的效率，也为构建行为数字孪生体奠定了基础。
## 24. `cs.LG` - 采用可迁移归一化流实现的拟合抽样 [PDF](https://arxiv.org/pdf/2508.18175), [HTML](https://arxiv.org/abs/2508.18175)
### Authors
Charlie B. Tan,Majdi Hassan,Leon Klein,Saifuddin Syed,Dominique Beaini,Michael M. Bronstein,Alexander Tong,Kirill Neklyudov
### Background
在计算化学和统计推断中，高效均衡采样分子构象依然是一个核心挑战。传统方法如分子动力学或马尔可夫链蒙特卡洛(MCMC)固有地缺乏概括性；每个感兴趣的系统都需要支付完整的采样计算成本。虽然生成模型在过去表现得与传统方法相当，但它们的应用范围有限，很难跨系统迁移。
### Innovation
我们通过引入Prose，一个针对多达8个残基长度的多肽分子动力学轨迹进行训练的全部原子级可迁移归一化流，展示了深度学习在设计可扩展和可迁移采样器方面的潜力。Prose能够实现零样本的未关联提案采样，能够处理任意多肽系统，并保留归一化流的高效似然评估。通过广泛的经验评估，我们证明了Prose作为一种提案在多种采样算法中的有效性，并发现了一种基于重要性采样的微调方法，使得其性能与成熟的顺序蒙特卡洛方法相当。我们开源了Prose代码库、模型权重和训练数据集，以进一步促进对概括性采样方法和目标的研究。
### Conclusion
我们展示了一种高效的可转换归一化流Prose，能够处理任意长度的多肽系统，并通过重要性抽样的微调方法实现了与传统方法相当的性能。我们还将Prose的相关资源开源，以便推动更多研究。
## 25. `cs.LG` - 在LLM-RL算法中的熵控制研究 [PDF](https://arxiv.org/pdf/2509.03493), [HTML](https://arxiv.org/abs/2509.03493)
### Authors
Han Shen
### Background
对于深度强化学习（RL）算法，恰当的熵控制对它们的效能至关重要。常用的熵控制方法是熵正则化，这种方法被应用在多种流行的RL算法中，如PPO、SAC和A3C。尽管在机器人和游戏RL领域上熵正则化已被证明有效，但研究发现它在大型语言模型（LLM）的RL训练中给出较弱或几乎没有什么收益。因此，本文探讨了在LLM-RL环境中熵奖金的挑战。
### Innovation
本文提出了一种新的熵控制方法AEnt，它是利用了一个重新定义的裁剪熵奖金，该奖金具有自动调整的系数。裁剪熵通过重新标准化策略在特定的较小的令牌空间上进行评估，以鼓励在更紧凑的响应集中进行探索。同时，AEnt自动调整熵系数根据裁剪熵值，有效控制熵带来的偏见，同时利用熵的好处。AEnt在不同的基础模型和数据集下的数学推理任务中进行了测试，并证明了在多个基准上，AEnt能持续优于基线。
### Conclusion
本文研究了LLM-RL环境中熵奖金的问题，并提出了一种新的熵控制方法AEnt，该方法通过自动调整系数和重新定义裁剪熵来提高性能。实验结果表明AEnt在数学推理任务上表现出色，持续优于传统方法。
## 26. `cs.LG` - 辛流形卷积神经网络 [PDF](https://arxiv.org/pdf/2508.19842), [HTML](https://arxiv.org/abs/2508.19842)
### Authors
Süleyman Yıldız,Konrad Janik,Peter Benner
### Background
论文基于辛神经网络和辛分解技术，提出了一种新的辛卷积神经网络（CNN）架构。通过引入卷积层的等效数学形式，并利用辛神经网络和张量技术，确保卷积层保持辛性。此外，还引入了一种辛池化层，从而构建了完整的自动编码器。
### Innovation
提出了一种基于辛神经网络的卷积神经网络架构，通过数学等价形式和线性变换，确保卷积层的辛不变性。进一步通过引入辛池化层，构建了完整的自动编码器。实验结果表明，所提出的辛CNN在处理波动方程、非线性薛定谔方程和舍恩乔治方程时表现优于线性辛自动编码器。
### Conclusion
该研究展示了辛卷积神经网络在处理波动方程、非线性薛定谔方程和舍恩乔治方程等物理系统建模中的优势，证明了所提出的网络结构在保持辛不变性方面的有效性，并通过实验验证了其优越性。
## 27. `cs.LG` - 动态分组实现无需校准和转换的权重仅量化大语言模型 [PDF](https://arxiv.org/pdf/2509.03054), [HTML](https://arxiv.org/abs/2509.03054)
### Authors
Xinzhe Zheng,Zhen-Qun Yang,Zishan Liu,Haoran Xie,S. Joe Qin,Arlene Chen,Fangzhen Lin
### Background
大语言模型在性能上表现出色，但在受限的内存和计算资源下部署却极具挑战性。低比特后训练量化（PTQ）是一种有前景的方法，但通常依赖于校准数据、辅助变换和GPU工具，这限制了其广泛应用。
### Innovation
该研究提出了一种名为MSB（Multi Scale Binary）的无校准和无变换的PTQ方法，它可以将二值量化扩展到多比特设置。MSB通过优化一个动态分组标准来减少组内方差，从而使微尺度级别的分组在从张量级到块级配置（每行64个元素组）的情况下可以保持一致地应用，而无需校准或中间变换。
### Conclusion
在Llama 3.2 3B模型上，MSB方法在WikiText-2上的8-bit权重仅区块量化下达到了8.43的困惑度，优于全精度（7.81）和GPTQ默认设置下的12.23困惑度。总的来说，MSB为低比特PTQ提供了一种新的优化视角，简化了量化管道，去除了校准和转换步骤。
## 28. `cs.LG` - 当两个RLHF目标相同吗？ [PDF](https://arxiv.org/pdf/2509.11298), [HTML](https://arxiv.org/abs/2509.11298)
### Authors
Madhava Gaikwad
### Background
在偏好优化文献中，提出了许多目标，通常被当作独立的改进来提出。本文旨在解决这一问题，通过引入Opal算法，以确定两个偏好目标是否等价。Opal通过生成标准形式或非等价的具体证据，来确定两个偏好目标是否等价。
### Innovation
本文提出了Opal算法，这个算法能够通过生成标准形式或非等价的具体证据，来确定两个偏好目标是否等价。应用Opal后发现，许多广泛使用的优化方法其实是在优化相同的目标，而另一些则是可以证明的不同的目标，比如批标准化会导致相同的响应对根据批组成的差异而接收不同的梯度。文章识别出少数能够真正导致不同目标的结构机制，大多数差异可以看作是参数化变化的结果。
### Conclusion
通过使用Opal算法，本文揭示了广泛使用的优化方法实际上优化的往往是相同的基本目标，而另一些则是可以证明的不同的目标。这也为偏好优化领域指明了方向，进一步研究和理解这些基本目标可以更好地指导方法的发展。
## 29. `cs.LG` - 子抽样自然梯度算法的绘图和投影分析 [PDF](https://arxiv.org/pdf/2508.21022), [HTML](https://arxiv.org/abs/2508.21022)
### Authors
Gil Goldshlager,Jiang Hu,Lin Lin
### Background
Subsampled natural gradient descent (SNG) 已被用于实现高精度的科学机器学习，但现有的基于随机预条件化的标准分析方法无法提供关于真实的小样本设置的见解。
### Innovation
通过将 SNG 视为一个绘图和投影方法来克服这些限制。为此，该研究抛弃了通常用于理论推导的将梯度和预条件分离的独立 mini-batch 模式，在此基础上提出了基于平方体积采样的新代理模式，从而展示了在存在耦合的情况下，SNG 的期望方向实际上可以分解为预条件梯度下降步长。这一发现为小样本情景提供了新的见解，例如显示了 SNG 比 SGD 更有效地利用模型雅可比矩阵的特征衰减作为其优势。
### Conclusion
本研究表明，SNG 的收敛性保证在使用任何大小的单 mini-batch 时可以实现，并且收敛率可以通过与绘图和投影结构相关的量化来明确表征。此外，还提出了新的理念来解释一种流行的结构化动量方案（SPRING），证明其自然源自加速的绘图和投影方法。
## 30. `cs.LG` - 经典和切片沃士滕生成对抗网络在非高斯数据下的最优解 [PDF](https://arxiv.org/pdf/2509.06505), [HTML](https://arxiv.org/abs/2509.06505)
### Authors
Yu-Jui Huang,Hsin-Hua Shen,Yu-Chih Huang,Wan-Yi Lin,Shih-Chun Lin
### Background
生成对抗网络（GAN）通过参数化的神经网络来逼近未知分布。尽管GAN在强化学习、半监督学习以及计算机视觉等任务中广泛使用，但其参数选择通常需要进行穷举搜索，仅有少数方法能证明其为理论最优。WGAN作为GAN的一种值得关注的变体，现有的最优参数研究主要集中在线性-二次-高斯（LQG）框架中。本文聚焦于研究超越LQG设置的WGAN的最优解。
### Innovation
在非高斯数据情况下，本文为具有非线性激活函数的一维WGAN导出了闭式形式的最优参数；在高维数据情况下，采用切片沃士滕框架证明了线性生成器的渐近最优性；提出了未投影的切片WGAN，并证明其渐近最优性；相较于经典的r-PCA解决方法，本文的切片WGAN生成器能够在保持性能的同时降低复杂度。
### Conclusion
本文研究了经典和切片沃士滕生成对抗网络在非高斯数据下的最优解，在一维WGAN和高维WGAN的特定条件下，分别导出了最优参数，并提出了新的未投影切片WGAN。通过实验证明，本文的方法在与经典的r-PCA相比，具有更好的性能同时复杂度更低。
