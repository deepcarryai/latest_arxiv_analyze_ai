{"llm_update_time": "20260210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2602.06485", "html_url": "https://arxiv.org/abs/2602.06485", "title": "AgentCPM-Explore：实现边缘规模代理的远期深度探索", "title_en": "AgentCPM-Explore: Realizing Long-Horizon Deep Exploration for Edge-Scale Agents", "authors": "Haotian Chen,Xin Cong,Shengda Fan,Yuyang Fu,Ziqin Gong,Yaxi Lu,Yishan Li,Boye Niu,Chengjun Pan,Zijun Song,Huadong Wang,Yesai Wu,Yueying Wu,Zihao Xie,Yukun Yan,Zhong Zhang,Yankai Lin,Zhiyuan Liu,Maosong Sun", "background": "现有的大型语言模型（LLM）已经在解决复杂任务方面显示出巨大潜力，但这些系统主要是依赖大规模模型，边缘规模模型的能力远未得到充分探索。本文系统研究了4B参数量级的代理模型的训练问题。遇到的主要瓶颈包括监督微调过程中的灾难性遗忘、奖励信号噪声以及在长文本情景下的推理退化。", "innovation": "提出了一种名为AgentCPM-Explore的紧凑4B参数代理模型，该模型具有高知识密度和强大的探索能力。引入了一套全面的训练框架，包括参数空间模型融合、奖励信号去噪和上下文信息细化，通过深入探索，在4B及以下规模模型中达到了最先进的性能，并在多个基准测试中超越了8B及以上规模的其他顶级模型。", "conclusion": "通过充分训练，AgentCPM-Explore展示了边缘规模模型真正潜力的突破，证明了这些模型的瓶颈在于推理稳定性而非固有的能力限制。"}
{"llm_update_time": "20260210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2602.06375", "html_url": "https://arxiv.org/abs/2602.06375", "title": "Difficulty-Estimated Policy Optimization", "title_en": "Difficulty-Estimated Policy Optimization", "authors": "Yu Zhao,Fan Jiang,Tianle Liu,Bo Zeng,Yu Liu,Longyue Wang,Weihua Luo", "background": "近期，大型推理模型（LRMs）的进步，如DeepSeek-R1，强调了通过Group Relative Policy Optimization（GRPO）扩展推理时计算的潜力。然而，当遇到过于简单或过于复杂的任务时，GRPO经常会出现梯度信号衰减的问题，导致梯度信号容易受到噪声的影响，从而影响收敛稳定性。尽管DAPO等变体试图纠正梯度消失，但在低效样本上进行耗尽性展开仍然会产生巨大的计算开销。", "innovation": "本文提出了一种新的框架——Difficulty-Estimated Policy Optimization（DEPO），通过在线动态评估和筛选训练数据，确保计算资源优先用于具有高学习潜力的样本，从而提高推理模型推理效率和稳健性。实验结果表明，DEPO可以在不牺牲模型性能的情况下将展开成本降低至至多2倍。", "conclusion": "我们的方法显著降低了训练高性能推理模型的计算门槛，为推理扩展提供了一条更可持续的道路。代码和数据将在接受后提供。"}
{"llm_update_time": "20260210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2602.06286", "html_url": "https://arxiv.org/abs/2602.06286", "title": "LLMs 是否像理性代理？测量概率决策中的信念一致性", "title_en": "Do LLMs Act Like Rational Agents? Measuring Belief Coherence in Probabilistic Decision Making", "authors": "Khurram Yamin,Jingjing Tang,Santiago Cortes-Gomez,Amit Sharma,Eric Horvitz,Bryan Wilder", "background": "大型语言模型（LLMs）在高风险领域被广泛应用，这些领域依赖于对世界的不确定性以及不同结果的效用考虑，然而其决策逻辑难以解释。本文研究LLMs是否是理性的效用最大化者，并具有一致的信念和稳定偏好。通过研究诊断挑战问题中的模型行为，为LLMs的推断与理想贝叶斯效用最大化之间的关系提供了见解。文中提出了一种方法，以条件确定报告的概率为何能对应任何理性代理的真实信念，这种方法被应用于多个医疗诊断领域，并对多种LLMs进行评估。", "innovation": "提出了一个可证伪的条件，即报告的概率无法对应于任何理性代理的真实信念。利用此方法研究了多个医疗诊断领域的LLMs，并提出了在指导高风险决策中应用LLMs的意义和未来发展方向。", "conclusion": "研究显示了LLMs的推断与理想贝叶斯效用最大化的关系，并提出了可用于指导高风险决策的潜在条件，为LLMs在未来决策中的使用提供了指导意义。"}
{"llm_update_time": "20260210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2602.06394", "html_url": "https://arxiv.org/abs/2602.06394", "title": "通过质量感知分词解锁噪声现实世界语料库的预训练", "title_en": "Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization", "authors": "Arvid E. Gollwitzer,Paridhi Latawa,David de Gruijl,Deepak A. Subramanian,Adrián Noriega de la Colina", "background": "当前的分词方法在处理序列数据时不考虑信号质量，限制了其在噪声现实世界语料库中的有效性。", "innovation": "提出了QA-Token（质量感知分词），直接将数据可靠性纳入词汇表构建中。做出了三项关键贡献：（i）两级优化形式，联合优化词汇表构建和下游性能；（ii）强化学习方法，通过质量感知奖励学习合并策略，并提供收敛性保证；（iii）利用Gumbel-Softmax松弛机制进行适参数学习，实现端到端优化。", "conclusion": "实验结果表明，该方法在基因组学（变异检测F1分数提高6.7个百分点）、金融学方面均有所提升。大规模应用中，通过分词预训练语料库（包含1.7万亿碱基对），实现了最先进的病原体检测效果（MCC: 94.53），同时减少了词汇表数量15%，解锁了各类噪声的现实世界语料库供基础模型训练，且无需额外推理开销。"}
{"llm_update_time": "20260210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2602.06319", "html_url": "https://arxiv.org/abs/2602.06319", "title": "通过图算法问题揭示大型推理模型的弱点", "title_en": "Exposing Weaknesses of Large Reasoning Models through Graph Algorithm Problems", "authors": "Qifan Zhang,Jianhao Ruan,Aochuan Chen,Kang Zeng,Nuo Chen,Jing Tang,Jia Li", "background": "大型推理模型（LRMs）在快速发展，但在数学、代码和常识推理方面的现有基准仍然有限。现有的基准测试缺乏长时间段推理评估，提供的挑战不足，且难以通过编程验证答案。", "innovation": "该研究提出了GrAlgoBench，一种专用于通过图算法问题评估LRMs的基准测试。这类问题特别适合测试推理能力：需要长时间推理，便于精细控制难度水平，且可以标准化和编程化评估。研究表明，当前的LRMs存在两个主要弱点：一是随着上下文长度增加，准确率急剧下降，一旦图超过120个节点，准确率就会低于50%。二是LRMs存在过度推理现象，主要由于广泛的自我验证行为，这增加了推理过程的复杂性，却没有提高正确性。", "conclusion": "GrAlgoBench 暴露了大型推理模型在长时间推理和过度推理等方面的局限性，确立了图算法问题作为检验LRMs推理能力的严格、多维度和实际相关的测试平台。"}
{"llm_update_time": "20260210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2602.06176", "html_url": "https://arxiv.org/abs/2602.06176", "title": "大型语言模型推理失效", "title_en": "Large Language Model Reasoning Failures", "authors": "Peiyang Song,Pengrui Han,Noah Goodman", "background": "大型语言模型（LLMs）展示了显著的推理能力，并在各种任务中取得了显著成果。尽管如此，LLMs依然存在推理失败的问题，这些问题存在于看似简单的场景中。然而，目前缺乏系统性的研究和分类框架来理解这些问题及其成因。", "innovation": "本文是首个全面研究和分类LLMs推理失败的综述。作者引入了一个新的分类框架，将推理分为实体化和非实体化两种类型，并在后者中进一步细分为直观（非形式）和逻辑（形式）推理。此外，作者还根据应用领域和表现一致性，将推理失败分类为三类：架构固有的基本失败，特定应用领域内的局限性，以及会导致表现不一致的稳健性问题。对于每种推理失败，作者提供了明确定义、分析现有研究、探索根源并提出缓解策略。", "conclusion": "本综述通过统合现有孤立的研究工作，提供了一个系统性视角来审视LLMs推理中的根本弱点，为未来研究指明了方向，旨在构建更强大、更可靠和更稳健的推理能力。作者还公开了一个包含所有关于LLM推理故障研究作品的GitHub仓库，为读者提供了进入这一领域的便捷入口。"}
{"llm_update_time": "20260210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2602.06107", "html_url": "https://arxiv.org/abs/2602.06107", "title": "Jackpot: 极限演员-策略失配的最优预算拒绝采样强化学习", "title_en": "Jackpot: Optimal Budgeted Rejection Sampling for Extreme Actor-Policy Mismatch Reinforcement Learning", "authors": "Zhuoming Chen,Hongyi Liu,Yang Zhou,Haizhong Zheng,Beidi Chen", "background": "大规模语言模型（LLMs）的强化学习（RL）仍然非常昂贵，特别是因为评估（rollout）过程非常耗时。将评估生成与策略优化分离（例如，利用更高效模型进行评估）可以带来显著的效率提升，但这样做会导致严重的分布不匹配，从而不稳定学习过程。", "innovation": "Jackpot框架利用最优预算拒绝采样（OBRS）直接减少评估模型与不断演化的策略之间的差距。Jackpot结合了原理上的OBRS过程、统一的联合训练目标（同时更新策略和评估模型）以及高效的系统实现（通过top-$k$概率估计和批次层面偏差校正）。", "conclusion": "理论分析表明，当在可控的接受预算下时，OBRS将评估分布紧密地拉近目标分布。实验上，Jackpot显著提高了训练稳定性，与重要性抽样基线相比，当训练Qwen3-8B-Base时，在64批次大小和最多300个更新步骤的情况下，可以达到与在线策略RL相当的性能。综上所述，我们结果表明基于OBRS的对齐使得我们在实际和有效分离评估生成与策略优化方面更进一步。"}
{"llm_update_time": "20260210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2602.06351", "html_url": "https://arxiv.org/abs/2602.06351", "title": "Trifuse：通过多模态融合增强基于注意力的GUI语义匹配", "title_en": "Trifuse: Enhancing Attention-Based GUI Grounding via Multimodal Fusion", "authors": "Longhui Ma,Di Zhao,Siwei Wang,Zhao Lv,Miao Wang", "background": "GUI接地将自然语言指令映射到正确的界面元素，作为GUI代理的感知基础。现有的方法主要依赖于使用大规模GUI数据集微调多模态大型语言模型（MLLMs）来预测目标元素坐标，这需要大量数据并且在面对未见过的界面时泛化能力较差。最近的基于注意力机制的方法利用了MLLMs的注意力机制中的定位信号，但没有特定的任务微调，因此可靠性较低，因为缺失GUI图像中的显式和互补的空间锚点。", "innovation": "提出了一种基于注意力的接地框架Trifuse，它显式地集成了补充的空间锚点。Trifuse通过一个促使跨模态一致的C-S合并策略，整合了注意力、OCR提取的文本线索和图标级语义描述，保持了清晰的定位峰。广泛的评估表明，Trifuse在四个接地基准上取得了优异的性能，无需特定任务的微调，并显著减少了对昂贵标注数据的依赖性。此外，消融研究显示，将OCR和图表备注信息纳入可以一致性地改进基于注意力机制的接地性能，突显了其作为一个通用框架的有效性。", "conclusion": "Trifuse提供了对GUI接地性能的有效提升，无需特定任务的微调，能够显著减少对昂贵标注数据的依赖性，并且在不同的主干网络上展示了其广泛的有效性。"}
{"llm_update_time": "20260210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2602.06413", "html_url": "https://arxiv.org/abs/2602.06413", "title": "自回归推理的内在稳定性限制：长时限执行的结构性后果", "title_en": "Intrinsic Stability Limits of Autoregressive Reasoning: Structural Consequences for Long-Horizon Execution", "authors": "Hsien-Jyh Liao", "background": "大语言模型（LLMs）展示了出色的推理能力，但在长时间任务中的表现往往急剧下降，显示出超出一定规模的系统性故障。以往的解释主要归因于任务复杂性，如组合搜索爆炸或长期信用分配难题。但本文认为这些解释是不完整的：即使在没有语义歧义的线性和非分支任务中，自回归执行也受限于内在稳定性限制，而不是仅仅来自搜索或任务复杂性。", "innovation": "本文提出，长时限推理的根本限制来源于自回归生成的过程级稳定性问题，而非仅限于搜索或任务复杂性。提出了定理A，显示单一路径自回归推理决策优势随执行长度呈指数衰减，这规定了可维持的推理链的基本界限。这得出稳定长时限推理需要离散分段的结构性后果：自然诱导出有向无环图（DAGs）等图式执行结构。", "conclusion": "实验研究在合成环境和真实的TextWorld任务中均揭示了与理论预测一致的性能悬崖。本研究从动态角度揭示了长时限推理失败的本质，并提出了在纯自回归架构下维持长期一致性的新限制。此外，研究表明短期评估方法可能掩盖了结构性不稳定，这可能指示未来推理系统需要转向结构治理。"}
{"llm_update_time": "20260210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2602.06227", "html_url": "https://arxiv.org/abs/2602.06227", "title": "为HER而做: 用于强化学习的可变时序逻辑奖励规范（扩展版本）", "title_en": "Do It for HER: First-Order Temporal Logic Reward Specification in Reinforcement Learning (Extended Version)", "authors": "Pierriccardo Olivieri,Fausto Lasca,Alessandro Gianola,Matteo Papini", "background": "本文针对具有大量状态空间的马尔可夫决策过程（MDPs）提出了一个新颖的框架，用于逻辑规范非马尔可夫奖励。传统的MDP方法在处理大规模状态空间时存在局限性，往往需要手动编码复杂的逻辑表达式。为了改进这一过程，提出了线性时序逻辑模理论（LTLfMT），这是一种更强大的扩展，允许使用任何形式理论中的谓词而不仅仅是简单的布尔变量。这种增强的表达能力使得能在未结构化和异构数据域中规范复杂的任务，从而提供了一个统一且可重用的框架，避免了手动谓词编码的需求。然而，LTLfMT较标准的LTLf规范增加了理论和计算上的挑战。", "innovation": "本文引入了一种新的框架，通过利用LTLfMT来规范化非马尔可夫奖励。这种框架能够处理大规模状态空间，且具有更强的表达能力，使得能够在未结构化和异构数据域中规范复杂的任务。同时，还提出了一种基于奖励机器和回溯经验回放（HER）的方法，用于将一阶逻辑规范转换为实践应用，并解决了奖励稀疏性的问题。实验结果表明，这种方法在不连续控制设定中能够自然规范复杂的任务。", "conclusion": "本文提出的方法在处理大规模状态空间的MDPs中的非马尔可夫奖励规范方面有很大优势。通过使用LTLfMT和回溯经验回放（HER）技术，能够有效地解决奖励制造问题，并在连续控制设定中实现了复杂的任务规范。研究表明，特别定制的HER实现对于解决复杂目标的任务至关重要。"}
{"llm_update_time": "20260210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23912", "html_url": "https://arxiv.org/abs/2510.23912", "title": "键和值权重可能是你需要的：在仅编码器和仅解码器变压器中关于查询、键、值权重三元组必要性的探究", "title_en": "Key and Value Weights Are Probably All You Need: On the Necessity of the Query, Key, Value weight Triplet in Encoder-Only and Decoder-Only Transformers", "authors": "Marko Karbevski,Antonij Mijoski", "background": "本文探讨了在仅编码器和仅解码器变压器中，是否有可能减少Query，Key，Value的权重三元组。在轻微假设下，作者证明Query权重是多余的，可以被单位矩阵替代，这使得注意力参数减少25％，简化了优化过程。", "innovation": "本文的主要创新在于证明了Query权重可以被去除非必要的，并能通过单位矩阵替代来简化模型，降低了25%的参数量，同时保持性能不变。此外，作者还发现，删除Query权重可以提供隐式的正则化，同时在较低权重衰减下，训练依然稳定。", "conclusion": "研究表明，尽管去除Query权重可能看似去除了一个重要部分，但在适当的调整下，模型仍能保持性能，并且在某些情况下，通过训练稳定性保持或提升效率。研究还发现，在固定宽度下，残差连接会使MLP进入一个函数类，这为跨不同模式和更大规模的进一步研究提供了新的理论界限和动机。"}
{"llm_update_time": "20260210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.00732", "html_url": "https://arxiv.org/abs/2511.00732", "title": "FeNN-DMA: 一种基于RISC-V的SNN加速片上系统", "title_en": "FeNN-DMA: A RISC-V SoC for SNN acceleration", "authors": "Zainab Aizaz,James C. Knight,Thomas Nowotny", "background": "Spiking Neural Networks (SNNs)作为一种新型的、能效更好的人工神经网络，特别适用于时空任务如关键词识别和视频分类。然而，SNNs的算术强度远低于传统的ANNs，因此不太适合标准加速器如GPU和TPU。而Field Programmable Gate Arrays (FPGAs)则被设计用来处理内存受限的工作负载。", "innovation": "本文提出了一种全新的、完全可编程的基于RISC-V架构的System-on-Chip (FeNN-DMA)系统，专门用于在现代UltraScale+ FPGA上模拟SNNs。FeNN-DMA的资源利用率和能量需求与最先进的固定功能SNN加速器相当，但支持更复杂的神经元模型和网络拓扑结构，并且每核可模拟多达16000个神经元和2.56亿个突触。", "conclusion": "使用该系统，我们在Spiking Heidelberg Digits、Neuromorphic MNIST和Braille触觉分类任务上实现了最先进的分类精度。"}
{"llm_update_time": "20260210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.05885", "html_url": "https://arxiv.org/abs/2511.05885", "title": "在基于多模态大型语言模型的序列推荐中，一个物品值一个令牌", "title_en": "An item is worth one token in Multimodal Large Language Models-based Sequential Recommendation", "authors": "Qiyong Zhong,Jiajie Su,Ming Yang,Yunshan Ma,Xiaolin Zheng,Chaochao Chen", "background": "序列推荐（SR）基于用户的历史行为预测其未来的交互。大型语言模型（LLMs）的兴起赋予了强大的生成和推理能力，显著提升了SR的效果，而多模态大型语言模型（MLLMs）通过引入图像等非文本数据进一步拓宽了这一能力。然而，仍然存在几大重要问题：1）由于冗长且重复的描述导致的次优物品表示，影响了训练和推断的效率；2）模态相关的认知偏差，因为LLMs主要是在文本数据上进行预训练，限制了其在非文本模态数据上的有效整合和利用；3）在长时间互动序列中，顺序感知能力减弱，注意力机制难以捕捉早期交互，阻碍了对长距离依赖性的建模。", "innovation": "为了应对上述问题，该研究提出Speeder，一种基于MLLM的高效序列推荐范式，具有三个关键创新：1）多模态表示压缩（MRC），通过将物品属性压缩成简洁且富有信息量的令牌，减少了冗余和计算成本；2）模态感知逐级优化（MPO），允许渐进学习多模态表示；3）顺序位置感知增强（SPAE），提升了LLM捕捉长互动序列中相对和绝对顺序依赖性的能力。", "conclusion": "在现实世界数据集上的广泛实验表明，Speeder在有效性和效率方面均表现优异。相比原始方法，Speeder在亚马逊数据集上的训练速度提高了250%，推断时间减少了75%。"}
{"llm_update_time": "20260210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.12085", "html_url": "https://arxiv.org/abs/2511.12085", "title": "基于可解释变换器的电子邮件钓鱼分类与抗对抗鲁棒性", "title_en": "Explainable Transformer-Based Email Phishing Classification with Adversarial Robustness", "authors": "Sajad U P", "background": "近年来，网络钓鱼和其他相关网络攻击变得越来越多样且技术先进。其中，基于电子邮件的网络钓鱼仍然是最普遍且持久的威胁。这些攻击利用人类的弱点来传播恶意软件或非法获取敏感信息。虽然深度学习（特别是基于变换器的模型）在通过语言上下文理解显著增强了网络钓鱼的检测能力，但一些崭新的威胁，如由人工智能（AI）生成的网络钓鱼攻击，却在削弱检测系统的整体可靠性。因此，对抗训练作为一种应对AI生成网络钓鱼威胁的方法显示出良好的前景。", "innovation": "本文提出了一种结合方法，采用DistilBERT，这是BERT变换器模型的更小、更快、更轻的版本进行电子邮件分类。利用快速梯度方法（FGM）对抗训练来增强模型在文本对抗扰动下的鲁棒性。此外，框架还集成了LIME可解释AI技术，以增强DistilBERT架构的透明度。该框架还利用Hugging Face的Flan-T5-small语言模型为终端用户提供简易的语言安全解释。这种方法确保了精准的网络钓鱼分类，并提供了模型决策的易理解的解释。", "conclusion": "综上，这项研究提出了一种结合对抗鲁棒性和可解释性的方法，即基于DistilBERT的电子邮件网络钓鱼分类器，通过快速梯度方法对抗训练以及LIME技术的集成，该模型不仅能够进行精确的网络钓鱼分类，还能够为用户提供易于理解的决策解释。"}
{"llm_update_time": "20260210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10936", "html_url": "https://arxiv.org/abs/2511.10936", "title": "GraphToxin: 从图学习中重建完整的未学习图", "title_en": "GraphToxin: Reconstructing Full Unlearned Graphs from Graph Unlearning", "authors": "Ying Song,Balaji Palanisamy", "background": "图消除作为一种解决‘被遗忘的权利’法规的方法已经引起了关注。然而，这种方法并非毫无漏洞。图神经网络（GNN）中的保留痕迹使得被删除的数据可能会被恢复，从而威胁到图消除的预期功能。因此，我们需要针对这一问题进行新的攻击研究。这篇文章介绍了一种新型的,kěnqiú píanbian duībǐ kù,kěnshì GraphToxin，旨在从图消除中重建完整的未学习图。", "innovation": "本文提出的GraphToxin是针对图消除的首个完整的图重建攻击方法。它引入了一个新颖的曲率匹配模块，为未学习的图恢复提供精细指导。此外，该研究还扩展了GraphToxin在多种节点删除情况下的应用，包括白盒和黑盒设置，并提出了系统化的评估框架来评估攻击性能。", "conclusion": "广泛的实验表明，GraphToxin的有效性和灵活性。现有的防御机制基本无效或在某些情况下甚至增强了攻击效果。这一严重威胁隐私的攻击性凸显了更有效和更稳健的防御措施的迫切需求。"}
{"llm_update_time": "20260210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.15015", "html_url": "https://arxiv.org/abs/2511.15015", "title": "动态专家量化在可扩展的MoE推理中的应用", "title_en": "Dynamic Expert Quantization for Scalable Mixture-of-Experts Inference", "authors": "Kexin Chu,Dawei Xiang,Zixu Shen,Yiwei Yang,Zecheng Liu,Wei Zhang", "background": "Mixture-of-Experts (MoE) 已成为在保持每令牌计算量适度的同时扩大大规模语言模型 (LLM) 能力的一种实用架构。然而，将 MoE 模型部署到单个内存有限的 GPU 上仍然困难，因为专家权重占据了大部分高带宽缓存存储 (HBM) 空间。现有的专家卸载和预取系统可以减少驻留集的大小，但在激活变得密集时，它们常常在关键路径上支付专家加载成本。后训练量化（PTQ）可以在没有传输的情况下降低占位空间，但目前的管道在专家位宽设置时是离线固定的，并假设路由保持稳定，尽管 MoE 专家利用率是重尾分布的，热点集可能会随着工作负载变化。", "innovation": "DynaExq 提出了一种基于运行时感知的混合精度服务系统，用于处理在 HBM 封装下的单 GPU MoE 推理，将其视为一个在线预算有限的精度分配问题。核心思想是保留影响运行时流量的主要专家以更高精度驻留，同时对于其他专家保持低精度备选方案，这样可以减少传输数据量并避免卸载和预取在密集激活下造成的等待延迟。DynaExq 通过路由器跟踪估算长期热点，选用预算可行的 top-n 法则选择每一层的高精度驻留集，并通过稳定的专家句柄异步进行晋升和降级，确保前向传播始终在完全加载的专家版本上执行。", "conclusion": "在 Qwen3-MoE-30B/80B 和六个基准测试中，DynaExq 在与设备内存预算相当的情况下提高了 Qwen3-80B 的准确性（从 73.09% 提高到 77.57%），并在 batch size 为 32 时比卸载/预取基线实现了高达 2.73 倍的更高吞吐量。"}
{"llm_update_time": "20260210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.06701", "html_url": "https://arxiv.org/abs/2511.06701", "title": "结构化强化AI驱动发现中的统计严谨性：一种功能架构", "title_en": "Structural Enforcement of Statistical Rigor in AI-Driven Discovery: A Functional Architecture", "authors": "Karen Sargsyan", "background": "AI-Scientist系统利用大型语言模型来自动化研究，但存在通过未受控的多重测试生成虚假发现的风险。本文提出了一种功能架构，在两个层次上保证统计严谨性：一个嵌入式域特定语言（Haskell Research Monad），它通过更新错误预算来强制假设检验，以及一种声明式的支撑技术，防止LLM生成代码跨越数据泄漏边界。", "innovation": "提出了一种功能架构，该架构通过Haskell嵌入式DSL（Research Monad）和结构化防止数据泄漏的技术，确保在使用大型语言模型进行研究时统计严谨性。该架构在机器检查的Lean 4形式化验证中得到了支持，验证了LORD++在线FDR控制定理的四个充分条件，并通过SPARK/Ada工具链进一步验证了浮点实现的正确性。", "conclusion": "蒙特卡洛模拟和端到端案例研究表明，该论文提出的方案在5%的目标下，能够将FDR控制在1.1%，而未经改进的方法则将FDR提高了41%。这是首次从实分析证明到浮点实现验证在线FDR控制程序的工作流程。"}
{"llm_update_time": "20260210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.16275", "html_url": "https://arxiv.org/abs/2511.16275", "title": "SeSE：基于结构信息论的黑盒大语言模型不确定性量化", "title_en": "SeSE: Black-Box Uncertainty Quantification for Large Language Models Based on Structural Information Theory", "authors": "Xingtao Zhao,Hao Peng,Dingli Su,Xianghua Zeng,Chunyang Liu,Jinzhi Liao,Philip S. Yu", "background": "可靠不确定性量化（UQ）对于在安全关键场景中部署大型语言模型（LLMs）至关重要，因为它使模型能够在不确定时选择不作答，从而避免生成幻想，即看似合理但实际上不符合事实的回答。虽然语义不确定性量化方法已经取得了高级性能，但它们忽略了潜在的语义结构信息，这些信息可以使得不确定性估计更加精确。", "innovation": "本文提出了一种命名为SeSE的原理性的黑盒不确定性量化框架，适用于开源和闭源的大语言模型。SeSE通过对语义空间内在结构的揭示，构建了最优层次抽象，通过最小化结构熵的编码树进行量化。与现有的方法主要集中在简单的短格式生成不同，SeSE还能为长格式输出提供可解释的、粒度化的不确定性估计。理论证明SeSE可以泛化语义熵，这是LLMs不确定性量化（UQ）的黄金标准，并且在24种模型-数据集组合中，其性能优于强基准。", "conclusion": "SeSE是一种基于结构信息论的黑盒不确定性量化方法，能够提供适用于大语言模型的不确定性量化，特别是在长格式输出方面。这种方法具有广泛应用前景，尤其是在需要高可靠性的安全关键场景中。"}
{"llm_update_time": "20260210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.03298", "html_url": "https://arxiv.org/abs/2512.03298", "title": "无分布假设的自适应转换期预测：深层转换状态空间模型与置信预测的结合", "title_en": "Adaptive Regime-Switching Forecasts with Distribution-Free Uncertainty: Deep Switching State-Space Models Meet Conformal Prediction", "authors": "Echo Diyun LU,Charles Findling,Marianne Clausel,Alessandro Leite,Wei Gong,Pierric Kersaudy", "background": "时间序列分析中，不同制度之间的转换常打破时间序列的平稳性，因此评估预测的不确定性变得尤为重要，甚至比单一的点预测更为关键。现有文献通常重视点预测准确性，而本文从无分布假设的角度出发，研究自适应自转换预测中的不确定性问题，通过深度转换状态空间模型与自适应置信推断（ACI）及其聚合变体相结合的方法，提供了一种可以根据非平稳性和模型误指定情况调整的预测带。", "innovation": "本文提出了将深度转换状态空间模型与自适应置信推断（ACI）及其聚合变体结合的方法，以产生在非平稳性和模型误指定情况下的在线预测带，并且提出了一个统一的置信包装器，可在包括S4、MC- Dropout GRU、稀疏高斯过程和变化点局部模型在内的多个强大的序列基准之上工作，最终实现了接近名义覆盖率的同时还保持了竞争力的准确性和改进的带宽效率。", "conclusion": "实证研究表明，该方法在合成和真实数据集上的分布拟合预测器能够接近名义覆盖范围，同时保持竞争力的准确度和改进的带宽效率。该方法为处理制度转换导致的非平稳性提供了一种新的有效策略。"}
{"llm_update_time": "20260210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.01249", "html_url": "https://arxiv.org/abs/2512.01249", "title": "Pascal-加权遗传算法：一种二项式结构的重组框架", "title_en": "Pascal-Weighted Genetic Algorithms: A Binomially-Structured Recombination Framework", "authors": "Otman A. Basir", "background": "本文介绍了一种基于归一化帕斯卡（二项式）系数的新多亲本重组操作符家族，用于遗传算法（GAs）。不同于传统的双亲交叉操作符，帕斯卡加权重组（PWR）通过使用具有中心继承强调和畸变方差抑制的二项式形状权重，以结构化凸组合的形式形成后代。", "innovation": "开发了PWR的数学框架，推导了方差转移特性，并分析了其对模式生存的影响。PWR可以扩展到实值、二进制/逻辑值和排列表示。在四个典型基准测试上评估了所提议的方法：(i)利用ITAE指标评估PID控制器调谐，(ii)在幅度响应约束下设计FIR低通滤波器，(iii)在SINR耦合下优化无线功率调制，(iv)旅行商问题（TSP）。PWR在这些基准测试中一致地表现出更平滑的收敛性，减少了方差，且相比标准重组操作符实现了9-22%的性能提升。这种方法简洁，算法无关，且易于集成到多种GA架构中。", "conclusion": "PWR在多个基准测试中表现出更优越的性能，包括平滑的收敛性、降低的方差，以及在某些方面的显著性能提升，这种方法在多种遗传算法框架中具有良好的兼容性和广泛应用潜力。"}
